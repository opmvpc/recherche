"""
Section TF-IDF pour l'application Streamlit
Contient toutes les fonctions de rendu pour la partie TF-IDF
"""

import streamlit as st
import numpy as np
import pandas as pd
import time
from pathlib import Path

# Imports from src
from src.tfidf_engine import TFIDFEngine, preprocess_text
from src.data_loader import load_dataset
from src.visualizations import (
    plot_tf_comparison,
    plot_idf_curve,
    plot_idf_wordcloud,
    plot_tfidf_heatmap,
    plot_search_results,
    plot_documents_3d,
    plot_vocabulary_stats,
)


# ============================================================================
# HELPER FUNCTION
# ============================================================================

def render_tab_navigation(tabs_list: list, session_key: str, default_tab: str = None) -> str:
    """
    Rend une navigation par tabs avec des boutons stylÃ©s

    Args:
        tabs_list: Liste des noms de tabs
        session_key: ClÃ© de session state pour tracker la tab active
        default_tab: Tab par dÃ©faut (optionnel)

    Returns:
        Nom de la tab actuellement sÃ©lectionnÃ©e
    """
    # Initialiser avec la premiÃ¨re tab ou default
    if session_key not in st.session_state:
        st.session_state[session_key] = default_tab if default_tab else tabs_list[0]

    # Rendre les boutons
    cols = st.columns(len(tabs_list))
    for idx, (col, tab_name) in enumerate(zip(cols, tabs_list)):
        with col:
            if st.session_state[session_key] == tab_name:
                # Tab actif - afficher avec style
                st.markdown(
                    f"""
                <div style="
                    background: linear-gradient(135deg, #1f77b4 0%, #2ca02c 100%);
                    padding: 12px 20px;
                    border-radius: 8px;
                    margin-bottom: 8px;
                    color: white;
                    font-weight: bold;
                    text-align: center;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                ">
                    {tab_name}
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                # Bouton cliquable
                if st.button(
                    tab_name, key=f"{session_key}_{idx}", use_container_width=True
                ):
                    st.session_state[session_key] = tab_name
                    st.rerun()

    return st.session_state[session_key]


# ============================================================================
# TF-IDF SECTION FUNCTIONS
# ============================================================================

def render_tfidf_section(
    dataset,
    documents_texts,
    documents_titles,
    documents_categories,
    engine,
    remove_stopwords,
    show_intermediate,
    load_time,
    fit_time,
):
    """Section TF-IDF complÃ¨te avec tous les onglets"""

    st.title("ğŸ“Š TF-IDF: Term Frequency - Inverse Document Frequency")

    # Sub-navigation avec boutons stylÃ©s
    tabs_tfidf = [
        "ğŸ“– Introduction",
        "ğŸ”¢ Concepts",
        "ğŸ” Recherche",
        "ğŸ“Š Exploration",
        "ğŸ“ Pas-Ã -Pas",
        "âš¡ Performance",
    ]
    tab = render_tab_navigation(tabs_tfidf, "tfidf_current_tab")

    if tab == "ğŸ“– Introduction":
        render_tfidf_intro()
    elif tab == "ğŸ”¢ Concepts":
        render_tfidf_concepts(engine, documents_titles)
    elif tab == "ğŸ” Recherche":
        render_tfidf_search(
            engine,
            documents_texts,
            documents_titles,
            documents_categories,
            show_intermediate,
        )
    elif tab == "ğŸ“Š Exploration":
        render_tfidf_exploration(engine, documents_titles, documents_categories)
    elif tab == "ğŸ“ Pas-Ã -Pas":
        render_tfidf_stepbystep(
            documents_texts, documents_titles, documents_categories, remove_stopwords
        )
    elif tab == "âš¡ Performance":
        render_tfidf_performance(
            engine, documents_texts, load_time, fit_time, remove_stopwords
        )


def render_tfidf_intro():
    """Introduction TF-IDF enrichie avec exemples dÃ©taillÃ©s"""
    st.header("ğŸ“– Introduction: Le ProblÃ¨me de la Recherche Textuelle")

    # === SECTION 1: LE CONTEXTE ===
    st.markdown("""
    ## ğŸŒ Le Contexte: Trouver l'aiguille dans la botte de foin

    Imagine que tu cherches **"recette italienne pÃ¢tes"** parmi 10,000 documents de cuisine.
    Comment l'ordinateur peut-il trouver les documents les plus **pertinents**?

    La solution naÃ¯ve (compter les mots) Ã©choue lamentablement. Voyons pourquoi! ğŸ‘‡
    """)

    st.divider()

    # === SECTION 2: L'Ã‰CHEC DE LA RECHERCHE NAÃVE ===
    st.markdown("### âŒ ProblÃ¨me #1: La Longueur des Documents")

    col1, col2 = st.columns([3, 2])

    with col1:
        st.markdown("""
        **Approche naÃ¯ve:** Compter simplement le nombre d'occurrences du mot.

        #### ScÃ©nario Concret:

        Tu cherches **"chocolat"** dans des recettes:

        - **Doc A** (Titre: "Mousse au chocolat") - 50 mots
          - Mot "chocolat" apparaÃ®t **2 fois**
          - Proportion: **2/50 = 4%** du document
          - *C'est clairement une recette DE chocolat!*

        - **Doc B** (Titre: "Buffet complet") - 500 mots
          - Mot "chocolat" apparaÃ®t **3 fois** (mention rapide du dessert)
          - Proportion: **3/500 = 0.6%** du document
          - *Le chocolat est mentionnÃ© en passant*

        #### ğŸ’¥ Le Bug:

        L'approche naÃ¯ve dit: **Doc B est plus pertinent** (3 > 2 occurrences)

        La rÃ©alitÃ©: **Doc A est clairement meilleur!** (4% vs 0.6%)
        """)

    with col2:
        st.code(
            """
ğŸ” Recherche: "chocolat"

âŒ Approche NaÃ¯ve:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Doc A: 2 occurrences
Doc B: 3 occurrences
RÃ©sultat: B > A âŒ

âœ… Approche Intelligente:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Doc A: 4.0% du doc
Doc B: 0.6% du doc
RÃ©sultat: A > B âœ…

ğŸ’¡ TF normalise par
   la longueur!
        """,
            language="text",
        )

    st.divider()

    # === SECTION 3: MOTS COMMUNS ===
    st.markdown("### âŒ ProblÃ¨me #2: Les Mots Communs Polluent Tout")

    col1, col2 = st.columns([3, 2])

    with col1:
        st.markdown("""
        #### ScÃ©nario: Recherche "cuisine traditionnelle"

        **Sans filtrage des mots communs:**

        Top 3 rÃ©sultats naÃ¯fs:
        1. ğŸ“„ Doc avec **"la", "de", "un"** 50Ã— chacun â†’ Score Ã©norme!
        2. ğŸ“„ Doc avec **"et", "dans", "avec"** 40Ã— â†’ DeuxiÃ¨me!
        3. ğŸ“„ Doc **vraiment** sur la cuisine traditionnelle â†’ TroisiÃ¨me seulement!

        #### ğŸ’¡ Le ProblÃ¨me:

        Les mots **super communs** comme "le", "la", "de", "un" apparaissent PARTOUT.

        Ils n'apportent **AUCUNE information** sur le sujet du document!

        - "le" â†’ PrÃ©sent dans 99% des documents â†’ **Inutile!**
        - "traditionnelle" â†’ PrÃ©sent dans 2% des documents â†’ **TrÃ¨s informatif!**

        #### ğŸ’¡ La Solution:

        **IDF (Inverse Document Frequency)** pÃ©nalise les mots qui apparaissent partout.

        Plus un mot est rare dans le corpus, plus son **IDF est Ã©levÃ©**!
        """)

    with col2:
        st.code(
            """
ğŸ” "cuisine traditionnelle"

âŒ Sans IDF:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. "la" (score: 150)
2. "de" (score: 120)
3. "un" (score: 100)
...
42. "traditionnelle"
    (score: 3)

âœ… Avec IDF:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
IDF("la") = 0.01
  â†’ 150 Ã— 0.01 = 1.5

IDF("traditionnelle")
  = 3.2
  â†’ 3 Ã— 3.2 = 9.6

RÃ©sultat: "traditionnelle"
devient dominant! âœ…
        """,
            language="text",
        )

    st.divider()

    # === SECTION 4: CAS D'USAGE RÃ‰EL ===
    st.markdown("### ğŸ¯ Cas d'Usage RÃ©els de TF-IDF")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.info("""
        #### ğŸ” Moteurs de Recherche

        Google, Bing utilisaient TF-IDF avant les embeddings!

        **Exemple:**
        - RequÃªte: "python tutorial"
        - TF-IDF trouve les docs qui parlent VRAIMENT de Python
        - Pas juste ceux qui mentionnent "python" 1 fois
        """)

    with col2:
        st.success("""
        #### ğŸ“§ Filtrage de Spam

        DÃ©tecter les emails frauduleux

        **Exemple:**
        - Spam: "GAGNEZ", "GRATUIT", "URGENT"
        - IDF faible (dans tous les spams)
        - Mais TF Ã©levÃ© dans spams
        - â†’ Signature claire!
        """)

    with col3:
        st.warning("""
        #### ğŸ“Š Analyse de Documents

        Extraire les mots-clÃ©s d'un texte

        **Exemple:**
        - Article scientifique
        - TF-IDF extrait: "algorithme", "rÃ©seau", "neuronal"
        - Ignore: "est", "dans", "pour"
        - â†’ Mots-clÃ©s automatiques!
        """)

    st.divider()

    # === SECTION 5: LA SOLUTION TF-IDF ===
    st.markdown("""
    ## âœ… La Solution: TF-IDF

    TF-IDF combine **deux mesures complÃ©mentaires** pour rÃ©soudre ces problÃ¨mes:
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.info("""
        ### ğŸ“ˆ TF (Term Frequency)

        **"FrÃ©quence locale du mot dans le document"**

        **Formule:**
        ```
        TF = (nombre d'occurrences) / (total mots doc)
        ```

        **Ce qu'il fait:**
        - âœ… Normalise par la longueur du document
        - âœ… Compare des docs courts et longs Ã©quitablement
        - âœ… Mesure l'importance locale d'un mot

        **Exemple:**
        - Doc de 100 mots avec "pizza" 5Ã—
        - TF("pizza") = 5/100 = **0.05** (5%)
        """)

    with col2:
        st.success("""
        ### ğŸ“‰ IDF (Inverse Document Frequency)

        **"RaretÃ© globale du mot dans tout le corpus"**

        **Formule:**
        ```
        IDF = log(total_docs / docs_avec_mot)
        ```

        **Ce qu'il fait:**
        - âœ… PÃ©nalise les mots trÃ¨s communs
        - âœ… Boost les mots rares et informatifs
        - âœ… Mesure l'importance globale

        **Exemple:**
        - "le": dans 9,900/10,000 docs
        - IDF("le") = log(10000/9900) â‰ˆ **0.01**
        - "margherita": dans 50/10,000 docs
        - IDF("margherita") = log(10000/50) â‰ˆ **5.3**
        """)

    st.divider()

    st.markdown("""
    ## ğŸ§® TF-IDF = TF Ã— IDF

    La formule magique multiplie les deux mesures:

    ```
    TF-IDF(mot, doc) = TF(mot, doc) Ã— IDF(mot, corpus)
    ```

    #### ğŸ’¡ InterprÃ©tation:

    Un mot a un **TF-IDF Ã©levÃ©** si:
    1. Il apparaÃ®t **souvent dans CE document** (TF Ã©levÃ©) ET
    2. Il apparaÃ®t **rarement dans les autres documents** (IDF Ã©levÃ©)

    â†’ C'est un mot **discriminant** pour ce document! ğŸ¯
    """)

    # Exemple visuel
    with st.expander("ğŸ“Š Voir un Exemple Complet CalculÃ©"):
        st.markdown("""
        ### Exemple: 3 Documents sur la Cuisine

        **Corpus:**
        1. Doc A: "La pizza margherita est une pizza italienne"
        2. Doc B: "La pasta carbonara est une recette italienne"
        3. Doc C: "La cuisine italienne est dÃ©licieuse"

        **Calculs pour le mot "pizza" dans Doc A:**

        **1ï¸âƒ£ TF (Term Frequency):**
        ```
        Doc A contient 8 mots, "pizza" apparaÃ®t 2 fois
        TF("pizza", Doc A) = 2 / 8 = 0.25
        ```

        **2ï¸âƒ£ IDF (Inverse Document Frequency):**
        ```
        "pizza" apparaÃ®t dans 1 document sur 3
        IDF("pizza") = log(3 / 1) = log(3) â‰ˆ 1.10
        ```

        **3ï¸âƒ£ TF-IDF Final:**
        ```
        TF-IDF("pizza", Doc A) = 0.25 Ã— 1.10 â‰ˆ 0.275
        ```

        **Comparaison avec "la":**
        ```
        TF("la", Doc A) = 1 / 8 = 0.125
        IDF("la") = log(3 / 3) = 0  (prÃ©sent partout!)
        TF-IDF("la", Doc A) = 0.125 Ã— 0 = 0
        ```

        â†’ **"pizza" a un score Ã©levÃ©, "la" est Ã©liminÃ©!** âœ…
        """)

    st.divider()

    st.success("""
    ### ğŸ“ Dans les Prochaines Sections

    Tu vas dÃ©couvrir:
    1. **Concepts TF-IDF** - Calculs dÃ©taillÃ©s avec visualisations
    2. **Recherche Interactive** - Teste le moteur en live!
    3. **Exploration du Corpus** - Analyse les mots-clÃ©s
    4. **Exemple Pas-Ã -Pas** - DÃ©roule un calcul complet
    5. **Performance** - ComplexitÃ© et optimisations

    **â†’ Passe Ã  l'onglet suivant!** ğŸ‘‰
    """)


def render_tfidf_concepts(engine, documents_titles):
    """Concepts TF-IDF dÃ©taillÃ©s avec PÃ‰DAGOGIE MAXIMALE"""
    st.header("ğŸ”¢ Concepts TF-IDF en Profondeur")

    st.markdown("""
    TF-IDF se compose de **3 concepts fondamentaux** que nous allons explorer un par un.

    Chaque concept rÃ©sout un problÃ¨me spÃ©cifique de la recherche textuelle! ğŸ¯
    """)

    # ============================================================================
    # CONCEPT 1: TERM FREQUENCY (TF)
    # ============================================================================
    with st.expander(
        "ğŸ“ˆ **1. Term Frequency (TF)** - FrÃ©quence des Mots", expanded=True
    ):
        st.markdown("""
        ### ğŸ’¡ L'Intuition

        **"Si un mot apparaÃ®t souvent dans un document, ce document parle probablement de ce sujet"**

        ### ğŸ¤” Le ProblÃ¨me Ã  RÃ©soudre

        Imagine deux documents qui parlent de "chocolat":
        - **Doc A** (50 mots): "chocolat" apparaÃ®t **2 fois**
        - **Doc B** (500 mots): "chocolat" apparaÃ®t **3 fois**

        Sans normalisation, Doc B semble plus pertinent (3 > 2).
        **Mais!** Doc A consacre **4%** de son contenu au chocolat (2/50), tandis que Doc B seulement **0.6%** (3/500)!

        ### ğŸ“ La Formule
        """)

        st.latex(
            r"\text{TF}(mot, doc) = \frac{\text{nombre d'occurrences}}{\text{total de mots dans le doc}}"
        )

        st.markdown("""
        **Pourquoi diviser?** Pour normaliser! Un document court avec 2 occurrences peut Ãªtre plus "Ã  propos"
        du sujet qu'un document long avec 5 occurrences.

        ### ğŸ“Š Exemple Visuel sur Notre Corpus

        Voici les TF de quelques mots dans 3 documents:
        """)

        # Graphique RÃ‰DUIT (colonnes pour prendre moins d'espace!)
        col1, col2 = st.columns([2, 1])

        with col1:
            sample_indices = [0, 1, 2]
            sample_titles = [documents_titles[i] for i in sample_indices]
            fig_tf = plot_tf_comparison(engine.documents, sample_indices, sample_titles)
            st.pyplot(fig_tf)

        with col2:
            st.markdown("""
            **ğŸ” Comment lire ce graphique:**

            - **Hauteur des barres** = TF (frÃ©quence normalisÃ©e)
            - **Plus haut** = mot plus frÃ©quent dans ce doc
            - **Comparaison** entre docs pour le mÃªme mot

            **ğŸ’¡ Observation:**

            Un mot peut avoir un TF Ã©levÃ© dans un doc et faible dans un autre.

            **Exemple:** "pÃ¢tes" a un TF de 0.08 dans la recette italienne, mais 0.00 dans le film!

            â¡ï¸ Le TF capture bien le **sujet local** du document! âœ…
            """)

        st.info("""
        **âœ… Ce que TF rÃ©sout:** Compare les documents Ã©quitablement, peu importe leur longueur!

        **âš ï¸ Ce que TF ne rÃ©sout PAS:** Les mots communs ("le", "la", "de") ont aussi des TF Ã©levÃ©s...
        On verra comment IDF rÃ¨gle ce problÃ¨me! ğŸ‘‡
        """)

    # ============================================================================
    # CONCEPT 2: INVERSE DOCUMENT FREQUENCY (IDF)
    # ============================================================================
    with st.expander("ğŸ“‰ **2. Inverse Document Frequency (IDF)** - RaretÃ© des Mots"):
        st.markdown("""
        ### ğŸ’¡ L'Intuition

        **"Un mot RARE est plus INFORMATIF qu'un mot commun"**

        ### ğŸ¤” Le ProblÃ¨me Ã  RÃ©soudre

        Tous les mots ne sont PAS Ã©gaux!
        - Le mot **"le"** apparaÃ®t dans TOUS les documents â†’ **PEU informatif** ğŸ˜
        - Le mot **"carbonara"** apparaÃ®t dans 1 seul document â†’ **TRÃˆS informatif**! ğŸ¯

        ### ğŸ“ La Formule
        """)

        st.latex(r"\text{IDF}(mot) = \log\left(\frac{N}{n}\right) + 1")

        st.caption(
            "OÃ¹: N = nombre total de documents, n = nombre de documents contenant le mot"
        )

        st.markdown("""
        **Pourquoi le logarithme?** Pour compresser l'Ã©chelle! Sans log, un mot prÃ©sent dans 1 doc sur 10,000
        aurait un IDF de 10,000 - bien trop Ã©levÃ©!

        Le log transforme Ã§a en ~4, plus raisonnable. ğŸ“‰

        ### ğŸ“Š Exemple: Courbe IDF

        Voici comment l'IDF varie selon le nombre de documents contenant un mot:
        """)

        # Graphiques IDF en colonnes
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**ğŸ“ˆ Courbe IDF vs FrÃ©quence**")
            fig_idf = plot_idf_curve(
                engine.idf_vector, engine.vocabulary, engine.documents
            )
            st.pyplot(fig_idf)

            st.markdown("""
            **ğŸ” Comment lire:**
            - **Axe X** = Nombre de docs contenant le mot
            - **Axe Y** = Score IDF
            - **Courbe dÃ©croissante** = Plus un mot est frÃ©quent, plus son IDF est faible

            **ğŸ’¡ Observation:**
            - Mot dans **1 doc** â†’ IDF Ã©levÃ© (~3)
            - Mot dans **TOUS les docs** â†’ IDF proche de 0
            """)

        with col2:
            st.markdown("**â˜ï¸ WordCloud par IDF**")
            # Prendre les 200 premiers mots du vocabulaire
            idf_dict = {
                engine.vocabulary[i]: engine.idf_vector[i]
                for i in range(min(200, len(engine.vocabulary)))
            }
            fig_wc = plot_idf_wordcloud(idf_dict)
            st.pyplot(fig_wc)

            st.markdown("""
            **ğŸ” Comment lire:**
            - **Taille du mot** = IDF (raretÃ©)
            - **Gros mots** = mots RARES (informatifs!)
            - **Petits mots** = mots communs (peu informatifs)

            **ğŸ’¡ Observation:**

            Les mots spÃ©cifiques sont **gros** (ex: "carbonara", "tiramisu"), tandis que les mots gÃ©nÃ©riques sont **petits** (ex: "trÃ¨s", "bien").
            """)

        st.success("""
        **âœ… Ce que IDF rÃ©sout:** Donne plus de poids aux mots RARES (informatifs) et moins aux mots COMMUNS!

        **Exemple concret:**
        - "le" â†’ IDF = 0.05 (commun, peu informatif)
        - "carbonara" â†’ IDF = 2.5 (rare, trÃ¨s informatif!)

        â¡ï¸ Maintenant combinons TF et IDF! ğŸ¯
        """)

    # ============================================================================
    # CONCEPT 3: TF-IDF COMBINÃ‰
    # ============================================================================
    with st.expander("ğŸ¯ **3. TF-IDF CombinÃ©** - La Magie OpÃ¨re!"):
        st.markdown("""
        ### ğŸ’¡ L'IdÃ©e GÃ©niale

        **TF-IDF = Multiplie la frÃ©quence locale (TF) par la raretÃ© globale (IDF)**

        ### ğŸ“ La Formule Finale
        """)

        st.latex(
            r"\text{TF-IDF}(mot, doc) = \text{TF}(mot, doc) \times \text{IDF}(mot)"
        )

        st.markdown("""
        **Ce que Ã§a donne:**

        Les mots avec un **TF-IDF Ã©levÃ©** sont ceux qui sont:
        1. **FrÃ©quents dans LE document** (TF Ã©levÃ©) âœ…
        2. **Rares dans LES AUTRES documents** (IDF Ã©levÃ©) âœ…

        â¡ï¸ Ce sont exactement les mots qui **caractÃ©risent** ce document! ğŸ¯

        ### ğŸ“Š Heatmap TF-IDF

        Visualisation des mots les plus importants pour chaque document:
        """)

        st.info("""
        **ğŸ’¡ Avant de regarder la heatmap:**

        - **Lignes** = Documents
        - **Colonnes** = Mots (top 15)
        - **Couleur** = Score TF-IDF (rouge = Ã©levÃ©, bleu = faible)

        **Ce qu'on cherche:** Des cases **rouges** qui montrent quel mot caractÃ©rise quel document!
        """)

        # Heatmap rÃ©duite
        col1, col2 = st.columns([3, 1])

        with col1:
            fig_heatmap = plot_tfidf_heatmap(
                engine.tfidf_matrix, engine.vocabulary, documents_titles, top_words=15
            )
            st.pyplot(fig_heatmap)

        with col2:
            st.markdown("""
            **ğŸ” Comment analyser:**

            1. **Regarder les colonnes** (mots):
               - Certains mots sont rouges pour UN doc, bleus pour les autres
               - â¡ï¸ Ce mot CARACTÃ‰RISE ce doc!

            2. **Regarder les lignes** (docs):
               - Chaque doc a ses propres mots "rouges"
               - â¡ï¸ Son "empreinte" unique!

            3. **Patterns intÃ©ressants**:
               - Docs similaires ont des patterns similaires
               - Docs diffÃ©rents ont patterns diffÃ©rents

            **Exemple:**
            - Doc "PÃ¢tes Carbonara" â†’ "pÃ¢tes", "parmesan", "guanciale" en rouge
            - Doc "Interstellar" â†’ "espace", "temps", "trou" en rouge

            â¡ï¸ TF-IDF capture parfaitement le sujet de chaque doc! âœ…
            """)

        st.success("""
        **ğŸ‰ FÃ©licitations! Tu comprends TF-IDF!**

        **RÃ©cap en 3 points:**
        1. **TF** = FrÃ©quence normalisÃ©e (local au document)
        2. **IDF** = RaretÃ© (global au corpus)
        3. **TF-IDF** = TF Ã— IDF = Mots qui caractÃ©risent chaque document!

        **ğŸ¯ Utilisation:** Pour comparer une **requÃªte** avec des **documents**,
        on calcule le TF-IDF de chaque mot, puis on mesure la **similaritÃ©** (prochain concept!)
        """)

    # ============================================================================
    # CONCEPT BONUS: COSINE SIMILARITY
    # ============================================================================
    with st.expander("ğŸ“ **Bonus: SimilaritÃ© Cosinus** - Comparer les Documents"):
        st.markdown("""
        ### ğŸ’¡ Le Concept GÃ©omÃ©trique

        Une fois qu'on a les vecteurs TF-IDF, comment comparer une **requÃªte** avec des **documents**?

        **RÃ©ponse:** La SimilaritÃ© Cosinus! Elle mesure l'**angle** entre deux vecteurs.

        ### ğŸ“ La Formule
        """)

        st.latex(r"\text{cos}(\theta) = \frac{A \cdot B}{\|A\| \times \|B\|}")

        st.markdown("""
        **Composantes:**
        - **A Â· B** = Produit scalaire (dot product) des vecteurs
        - **||A||** = Norme (longueur) du vecteur A
        - **||B||** = Norme (longueur) du vecteur B

        **RÃ©sultat:** Un score entre **0** et **1**:
        - **1.0** = Vecteurs identiques (angle = 0Â°) â†’ **TrÃ¨s similaires!** ğŸ¯
        - **0.5** = Vecteurs Ã  60Â° â†’ Moyennement similaires
        - **0.0** = Vecteurs perpendiculaires (90Â°) â†’ Pas similaires du tout

        ### ğŸ¤” Pourquoi l'Angle et pas juste la Distance?

        **Exemple concret:**
        - Doc A (court): Vecteur TF-IDF [0.1, 0.2, 0.1]
        - Doc B (long): Vecteur TF-IDF [0.5, 1.0, 0.5]

        Ces vecteurs pointent dans la **mÃªme direction** (ratio 1:2:1), mais B est 5Ã— plus long!

        - **Distance euclidienne:** Grande! âŒ (suggÃ¨re qu'ils sont diffÃ©rents)
        - **Angle (cosinus):** Petit! âœ… (dÃ©tecte qu'ils parlent du mÃªme sujet)

        â¡ï¸ L'angle capture la **similitude thÃ©matique** indÃ©pendamment de la longueur! ğŸ¯
        """)

        st.info("""
        **ğŸ’¡ En pratique:**

        Pour une requÃªte "plat italien pÃ¢tes":
        1. Calculer son vecteur TF-IDF
        2. Calculer la similaritÃ© cosinus avec CHAQUE document
        3. Trier les documents par score dÃ©croissant
        4. Afficher les top rÃ©sultats!

        **C'est exactement ce que fait la section "Recherche Interactive"!** ğŸ”
        """)

    st.markdown("---")
    st.success("""
    âœ… **Section Concepts terminÃ©e!**

    Tu maÃ®trises maintenant:
    - TF (frÃ©quence normalisÃ©e)
    - IDF (raretÃ© globale)
    - TF-IDF (combinaison magique)
    - SimilaritÃ© Cosinus (comparaison)

    **ğŸ‘‰ Passe Ã  la "Recherche Interactive" pour voir TF-IDF en action!**
    """)


def render_tfidf_search(
    engine, documents_texts, documents_titles, documents_categories, show_intermediate
):
    """Recherche interactive TF-IDF avec analyses pÃ©dagogiques"""
    st.header("ğŸ” Recherche Interactive TF-IDF")

    st.markdown("""
    **Teste TF-IDF en action!** ğŸš€

    Entre une requÃªte (plusieurs mots), et on va trouver les documents les plus pertinents
    en calculant la **similaritÃ© cosinus** entre ta requÃªte et chaque document.

    **Comment Ã§a marche:**
    1. Ta requÃªte est transformÃ©e en vecteur TF-IDF
    2. On calcule la similaritÃ© avec TOUS les documents
    3. On trie par score dÃ©croissant
    4. On affiche les meilleurs rÃ©sultats! ğŸ¯
    """)

    # Utiliser un formulaire pour soumission avec Enter
    with st.form("tfidf_search_form", clear_on_submit=False):
        col1, col2 = st.columns([3, 1])

        with col1:
            query = st.text_input(
                "ğŸ” Entre ta requÃªte:",
                value="plat italien pÃ¢tes",  # Valeur par dÃ©faut!
                placeholder="Ex: plat italien, science-fiction espace, guerre mondiale...",
                key="tfidf_query_input",
                help='ğŸ’¡ **Exemples:** "plat italien pÃ¢tes fromage" | "cuisine asiatique Ã©picÃ©e crevettes" | "dessert chocolat franÃ§ais" | "poisson grillÃ© mÃ©diterranÃ©en"',
            )

        with col2:
            top_k = st.slider(
                "RÃ©sultats:",
                3,
                20,
                5,
                key="tfidf_topk_slider",
                help="Nombre de documents les plus pertinents Ã  afficher",
            )

        # Bouton de soumission (Enter fonctionne aussi!)
        submitted = st.form_submit_button("ğŸš€ Rechercher!", type="primary")

    if submitted and query:
        with st.spinner("ğŸ” Recherche en cours..."):
            results = engine.search(query, top_k=top_k)

            if len(results) == 0 or all(score == 0 for _, score in results):
                st.warning("ğŸ˜• Aucun rÃ©sultat. Essaie d'autres mots!")
            else:
                st.success(f"âœ… {len(results)} rÃ©sultats trouvÃ©s!")

                # ========= GRAPHIQUE + ANALYSE CÃ”TE Ã€ CÃ”TE =========
                st.markdown("### ğŸ“Š Visualisation des Scores")

                col_graph, col_analysis = st.columns([2, 1])

                with col_graph:
                    fig_results = plot_search_results(results, documents_titles, query)
                    st.pyplot(fig_results)

                with col_analysis:
                    st.markdown("**ğŸ” Comment lire ce graphique:**")
                    st.markdown("""
                    - **Axe X** = Score de similaritÃ© (0 Ã  1)
                    - **Axe Y** = Documents trouvÃ©s
                    - **Plus Ã  droite** = plus similaire!

                    **ğŸ’¡ InterprÃ©tation des scores:**
                    - **> 0.5** â†’ TrÃ¨s pertinent! ğŸ¯
                    - **0.3 - 0.5** â†’ Moyennement pertinent ğŸ‘Œ
                    - **< 0.3** â†’ Faiblement pertinent ğŸ˜
                    """)

                    # Analyse automatique des rÃ©sultats!
                    top_score = results[0][1]
                    score_range = results[0][1] - results[-1][1]

                    if top_score > 0.5:
                        st.success(
                            f"ğŸ¯ **Excellent!** Le top rÃ©sultat a un score de {top_score:.3f} - trÃ¨s pertinent!"
                        )
                    elif top_score > 0.3:
                        st.info(
                            f"ğŸ‘Œ **Bon!** Score de {top_score:.3f} - pertinence moyenne."
                        )
                    else:
                        st.warning(
                            f"ğŸ˜ **Moyen...** Score max de {top_score:.3f} - essaye d'autres mots?"
                        )

                    if score_range > 0.2:
                        st.markdown(
                            f"ğŸ“Š **Bonne sÃ©paration:** Les scores varient de {results[-1][1]:.3f} Ã  {results[0][1]:.3f} - TF-IDF distingue bien les docs!"
                        )
                    else:
                        st.markdown(
                            f"ğŸ“Š **Scores proches:** Ã‰cart de seulement {score_range:.3f} - les docs se ressemblent!"
                        )

                # ========= RÃ‰SULTATS DÃ‰TAILLÃ‰S =========
                st.markdown("---")
                st.markdown("### ğŸ¯ RÃ©sultats DÃ©taillÃ©s")

                for rank, (doc_idx, score) in enumerate(results[:5], 1):
                    # Badge de qualitÃ© selon le score
                    if score > 0.5:
                        badge = "ğŸ”¥ **TrÃ¨s pertinent!**"
                        badge_color = "green"
                    elif score > 0.3:
                        badge = "ğŸ‘Œ **Pertinent**"
                        badge_color = "blue"
                    else:
                        badge = "ğŸ˜ **Faiblement pertinent**"
                        badge_color = "orange"

                    with st.expander(
                        f"**#{rank}** - {documents_titles[doc_idx]} â€¢ Score: **{score:.3f}** {badge}"
                    ):
                        col1, col2 = st.columns([2, 1])

                        with col1:
                            st.caption(
                                f"**CatÃ©gorie:** {documents_categories[doc_idx]}"
                            )
                            st.write(documents_texts[doc_idx][:300] + "...")

                        with col2:
                            st.markdown("**ğŸ“Š Pourquoi ce score?**")

                            # Analyser les mots de la query prÃ©sents dans le doc
                            query_words = set(query.lower().split())
                            doc_words = set(documents_texts[doc_idx].lower().split())
                            common_words = query_words & doc_words

                            if common_words:
                                st.markdown(
                                    f"âœ… **Mots en commun:** {', '.join(list(common_words)[:5])}"
                                )
                                st.markdown(
                                    f"ğŸ“ˆ **Overlap:** {len(common_words)}/{len(query_words)} mots"
                                )
                            else:
                                st.markdown("âŒ Aucun mot en commun (synonymes?)")

                            # Optionnel: afficher les calculs dÃ©taillÃ©s
                            if show_intermediate:
                                with st.expander("ğŸ”¬ Calculs dÃ©taillÃ©s"):
                                    explanation = engine.get_explanation(query, doc_idx)
                                    st.json(explanation)

                # ========= CONSEILS PÃ‰DAGOGIQUES =========
                st.markdown("---")
                st.info("""
                **ğŸ’¡ ExpÃ©rimente!**

                - **RequÃªte courte** (1-2 mots) â†’ RÃ©sultats larges
                - **RequÃªte longue** (4-5 mots) â†’ RÃ©sultats prÃ©cis
                - **Mots rares** â†’ Meilleurs scores (IDF Ã©levÃ©!)
                - **Mots communs** â†’ Scores plus faibles

                **ğŸ¯ Astuce:** Utilise des mots **spÃ©cifiques** Ã  ce que tu cherches!
                """)


def render_tfidf_exploration(engine, documents_titles, documents_categories):
    """Exploration du corpus TF-IDF avec analyses approfondies"""
    st.header("ğŸ“Š Exploration du Corpus")

    st.markdown("""
    Cette section te permet d'explorer le **corpus dans son ensemble** et de comprendre
    ses caractÃ©ristiques globales! ğŸ”¬

    Tu verras:
    - Les statistiques du corpus
    - La distribution du vocabulaire
    - Les mots les plus informatifs (IDF Ã©levÃ©)
    - La structure des documents en 3D
    """)

    # ============================================================================
    # MÃ‰TRIQUES GLOBALES
    # ============================================================================
    st.markdown("### ğŸ“ˆ MÃ©triques du Corpus")

    col1, col2, col3, col4 = st.columns(4)

    num_docs = len(documents_titles)
    vocab_size = len(engine.vocabulary)
    avg_words = np.mean([len(doc) for doc in engine.documents])
    num_categories = len(set(documents_categories))

    col1.metric(
        "ğŸ“š Documents", num_docs, help="Nombre total de documents dans le corpus"
    )
    col2.metric(
        "ğŸ”¤ Vocabulaire",
        vocab_size,
        help="Nombre de mots uniques (aprÃ¨s preprocessing)",
    )
    col3.metric(
        "ğŸ“ Mots/Doc", f"{avg_words:.1f}", help="Longueur moyenne d'un document"
    )
    col4.metric("ğŸ·ï¸ CatÃ©gories", num_categories, help="Nombre de catÃ©gories diffÃ©rentes")

    # InterprÃ©tation automatique
    st.markdown("**ğŸ’¡ InterprÃ©tation:**")

    if vocab_size > num_docs * 10:
        st.info(
            f"ğŸ“– **Vocabulaire riche:** {vocab_size} mots pour {num_docs} docs â†’ Corpus diversifiÃ©!"
        )
    elif vocab_size > num_docs * 5:
        st.info(f"ğŸ“– **Vocabulaire normal:** Ratio vocabulaire/docs Ã©quilibrÃ©.")
    else:
        st.warning(
            f"ğŸ“– **Vocabulaire limitÃ©:** Peu de mots uniques â†’ Docs probablement similaires."
        )

    if avg_words > 100:
        st.info(
            f"ğŸ“„ **Documents longs:** Moyenne de {avg_words:.0f} mots â†’ Textes dÃ©taillÃ©s!"
        )
    elif avg_words > 50:
        st.info(f"ğŸ“„ **Documents moyens:** Longueur raisonnable pour l'analyse.")
    else:
        st.info(
            f"ğŸ“„ **Documents courts:** {avg_words:.0f} mots en moyenne â†’ Textes concis!"
        )

    st.markdown("---")

    # ============================================================================
    # DISTRIBUTION DU VOCABULAIRE
    # ============================================================================
    st.markdown("### ğŸ“Š Distribution du Vocabulaire")

    col_graph1, col_analysis1 = st.columns([2, 1])

    with col_graph1:
        st.markdown("**ğŸ“ˆ Statistiques de FrÃ©quence**")
        fig_vocab = plot_vocabulary_stats(engine.documents)
        st.pyplot(fig_vocab)

    with col_analysis1:
        st.markdown("**ğŸ” Comment lire:**")
        st.markdown("""
        Ce graphique montre la **distribution des longueurs de documents**.

        - **Axe X** = Longueur du document (nombre de mots)
        - **Axe Y** = Nombre de documents
        - **Forme de la courbe** = Distribution du corpus

        **ğŸ’¡ Ce qu'on veut:**
        - **Distribution uniforme** â†’ Corpus Ã©quilibrÃ© âœ…
        - **Pics multiples** â†’ CatÃ©gories distinctes ğŸ¯
        - **Un seul pic** â†’ Docs similaires en longueur

        **ğŸ“Š Observation:**

        Si tous les docs ont ~la mÃªme longueur, TF-IDF fonctionnera bien!
        Si les longueurs varient beaucoup, attention Ã  la normalisation!
        """)

    st.markdown("---")

    # ============================================================================
    # TOP MOTS PAR IDF
    # ============================================================================
    st.markdown("### ğŸ† Top Mots les Plus Informatifs (IDF)")

    st.markdown("""
    Voici les mots avec les **IDF les plus Ã©levÃ©s** - ce sont les mots les plus **RARES** et donc
    les plus **INFORMATIFS** du corpus! ğŸ¯
    """)

    # Extraire top 20 mots par IDF
    idf_items = [
        (engine.vocabulary[idx], engine.idf_vector[idx])
        for idx in range(len(engine.vocabulary))
    ]
    top_idf = sorted(idf_items, key=lambda x: x[1], reverse=True)[:20]

    col_graph2, col_analysis2 = st.columns([2, 1])

    with col_graph2:
        st.markdown("**ğŸ“Š Top 20 Mots par IDF**")

        # CrÃ©er un bar chart simple
        import matplotlib.pyplot as plt

        fig, ax = plt.subplots(figsize=(8, 6))
        words = [w for w, _ in top_idf]
        idfs = [idf for _, idf in top_idf]
        ax.barh(words[::-1], idfs[::-1], color="#1f77b4")
        ax.set_xlabel("Score IDF")
        ax.set_title("Mots les Plus Informatifs")
        plt.tight_layout()
        st.pyplot(fig)

    with col_analysis2:
        st.markdown("**ğŸ” Analyse:**")
        st.markdown(f"""
        **Top 3 mots:**
        1. **{top_idf[0][0]}** ({top_idf[0][1]:.2f})
        2. **{top_idf[1][0]}** ({top_idf[1][1]:.2f})
        3. **{top_idf[2][0]}** ({top_idf[2][1]:.2f})

        **ğŸ’¡ Ce que Ã§a signifie:**

        Ces mots sont **rares** dans le corpus!
        - IDF Ã©levÃ© â†’ Peu de docs contiennent ce mot
        - â¡ï¸ TrÃ¨s informatif pour caractÃ©riser un doc

        **ğŸ¯ En pratique:**

        Si ta requÃªte contient ces mots, les rÃ©sultats seront **trÃ¨s prÃ©cis**!

        Si un document contient ces mots, il se **dÃ©marque** des autres!
        """)

    st.markdown("---")

    # ============================================================================
    # PROJECTION 3D DES DOCUMENTS
    # ============================================================================
    st.markdown("### ğŸŒ Projection 3D des Documents")

    st.info("""
    **ğŸ’¡ Avant de regarder la visualisation:**

    Chaque document est reprÃ©sentÃ© par un **point dans l'espace 3D**.
    - La position est calculÃ©e avec **PCA** (rÃ©duction de dimensionalitÃ©)
    - Les couleurs = catÃ©gories
    - **Documents proches** = sujets similaires!
    - **Documents Ã©loignÃ©s** = sujets diffÃ©rents!

    **ğŸ¯ Ce qu'on cherche:**
    - Des **clusters** (groupes) par catÃ©gorie âœ…
    - Une bonne **sÃ©paration** entre catÃ©gories âœ…
    """)

    col_graph3, col_analysis3 = st.columns([3, 1])

    with col_graph3:
        fig_3d = plot_documents_3d(
            engine.tfidf_matrix, documents_titles, documents_categories
        )
        st.plotly_chart(fig_3d, use_container_width=True)

    with col_analysis3:
        st.markdown("**ğŸ” InterprÃ©tation:**")
        st.markdown("""
        **Comment analyser:**

        1. **Rotation:** Clique et fais glisser pour tourner la vue ğŸ”„

        2. **Zoom:** Scroll pour zoomer/dÃ©zoomer ğŸ”

        3. **Hover:** Survole un point pour voir le titre ğŸ‘†

        **ğŸ’¡ Patterns Ã  observer:**

        - **Clusters bien sÃ©parÃ©s** â†’ TF-IDF distingue bien les catÃ©gories! âœ…

        - **Chevauchement** â†’ Certains docs se ressemblent malgrÃ© des catÃ©gories diffÃ©rentes ğŸ¤”

        - **Points isolÃ©s** â†’ Docs uniques, diffÃ©rents des autres! ğŸŒŸ

        **ğŸ¯ UtilitÃ©:**

        Cette visualisation montre si ton corpus est bien **structurÃ©** et si TF-IDF capte les **diffÃ©rences** entre documents!
        """)

    st.markdown("---")
    st.success("""
    âœ… **Section Exploration terminÃ©e!**

    Tu as maintenant une **vue d'ensemble complÃ¨te** du corpus:
    - Ses statistiques globales
    - Ses mots les plus informatifs
    - Sa structure spatiale

    **ğŸ‘‰ Ces analyses t'aident Ã  comprendre si TF-IDF est adaptÃ© Ã  ton corpus!**
    """)


def render_tfidf_stepbystep(
    documents_texts, documents_titles, documents_categories, remove_stopwords
):
    """Exemple pas-Ã -pas TF-IDF COMPLET avec tous les calculs dÃ©taillÃ©s"""
    st.header("ğŸ“ Exemple Complet Pas-Ã -Pas")

    st.markdown("""
    Dans cette section, tu vas voir **TOUS les calculs** en dÃ©tail, Ã©tape par Ã©tape!

    On va prendre 3 documents et calculer leur similaritÃ© avec ta requÃªte. ğŸ”¬
    """)

    # === DOCUMENTS D'EXEMPLE ===
    sample_indices = list(range(min(3, len(documents_texts))))

    st.markdown("### ğŸ“š Documents utilisÃ©s pour l'exemple")

    for idx in sample_indices:
        with st.expander(
            f"ğŸ“„ Document {idx + 1}: {documents_titles[idx]}", expanded=(idx == 0)
        ):
            st.write(f"**CatÃ©gorie:** {documents_categories[idx]}")
            st.write(f"**Contenu:** {documents_texts[idx]}")
            word_count = len(documents_texts[idx].split())
            st.caption(f"ğŸ“Š Longueur: {word_count} mots")

    st.markdown("---")

    # === QUERY INPUT ===
    query = st.text_input(
        "ğŸ” Ta requÃªte de test:",
        value="plat italien fromage",
        key="tfidf_tutorial",
        help='ğŸ’¡ **Exemples:** "chocolat dessert" | "pÃ¢tes italiennes sauce" | "poisson grillÃ© citron"',
    )

    if not query:
        st.warning("â¬†ï¸ Entre une requÃªte ci-dessus pour voir les calculs!")
        return

    # === CALCULS ===
    with st.spinner("ğŸ§® Calcul en cours..."):
        sample_texts = [documents_texts[i] for i in sample_indices]
        mini_engine = TFIDFEngine(sample_texts, remove_stopwords=remove_stopwords)
        mini_engine.fit()

        query_tokens = preprocess_text(query)

        st.success(f'âœ… Calculs terminÃ©s pour la requÃªte: **"{query}"**')

    # === Ã‰TAPE 1: VOCABULAIRE ===
    st.markdown("---")
    st.markdown("## ğŸ”¢ Ã‰tape 1: Construction du Vocabulaire")

    st.markdown("""
    On commence par **extraire tous les mots uniques** de nos 3 documents.
    C'est notre **vocabulaire** (ou *vocabulary*).
    """)

    vocab_size = len(mini_engine.vocabulary)
    st.metric("ğŸ“š Taille du vocabulaire", f"{vocab_size} mots uniques")

    with st.expander("ğŸ‘€ Voir le vocabulaire complet"):
        vocab_list = sorted(list(mini_engine.vocabulary))
        st.write(", ".join(vocab_list[:100]))
        if len(vocab_list) > 100:
            st.caption(f"... et {len(vocab_list) - 100} autres mots")

    # === Ã‰TAPE 2: TERM FREQUENCY (TF) ===
    st.markdown("---")
    st.markdown("## ğŸ“Š Ã‰tape 2: Calcul des Term Frequencies (TF)")

    st.markdown("""
    **TF = Combien de fois un mot apparaÃ®t dans un document, normalisÃ© par la longueur.**

    **Formule:** `TF(mot, doc) = nb_occurrences / nb_total_mots`

    **Pourquoi normaliser?** Pour ne pas favoriser les documents longs!
    """)

    st.latex(r"\text{TF}(t, d) = \frac{\text{count}(t, d)}{|\text{words}(d)|}")

    # Calculer TF pour les mots de la query
    query_words_in_vocab = [w for w in query_tokens if w in mini_engine.vocabulary]

    if len(query_words_in_vocab) == 0:
        st.warning(
            "âš ï¸ Aucun mot de ta requÃªte n'est dans le vocabulaire! Essaie d'autres mots."
        )
        return

    st.info(
        f"ğŸ¯ **Mots de ta requÃªte dans le vocabulaire:** {', '.join(query_words_in_vocab)}"
    )

    # CrÃ©er tableau TF
    tf_data = []
    for doc_idx in sample_indices:
        row = {"Document": documents_titles[doc_idx][:30] + "..."}
        for word in query_words_in_vocab:
            word_idx = mini_engine.word_to_idx[word]  # FIX: Utiliser word_to_idx!
            tf_value = mini_engine.tf_matrix[doc_idx, word_idx]
            row[word] = f"{tf_value:.4f}"
        tf_data.append(row)

    df_tf = pd.DataFrame(tf_data)
    st.markdown("**ğŸ“Š Tableau des TF (Term Frequencies):**")
    st.dataframe(df_tf, use_container_width=True, hide_index=True)

    st.markdown("""
    **ğŸ’¡ InterprÃ©tation:**
    - Plus le TF est **Ã©levÃ©**, plus le mot est **frÃ©quent** dans le document
    - Un TF de 0.05 = le mot reprÃ©sente **5%** du document
    - Un TF de 0.00 = le mot n'apparaÃ®t **pas** dans ce document
    """)

    # === Ã‰TAPE 3: INVERSE DOCUMENT FREQUENCY (IDF) ===
    st.markdown("---")
    st.markdown("## ğŸ” Ã‰tape 3: Calcul des Inverse Document Frequencies (IDF)")

    st.markdown("""
    **IDF = Mesure de la raretÃ© d'un mot dans TOUS les documents.**

    **Formule:** `IDF(mot) = log(nb_total_docs / nb_docs_contenant_mot)`

    **Pourquoi?** Les mots **rares** sont plus **informatifs** que les mots communs!
    """)

    st.latex(r"\text{IDF}(t) = \log\left(\frac{N}{n_t}\right)")

    st.caption(
        "OÃ¹: N = nombre total de documents, n_t = nombre de documents contenant le terme t"
    )

    # Calculer IDF pour les mots de la query
    idf_data = []
    for word in query_words_in_vocab:
        word_idx = mini_engine.word_to_idx[word]  # FIX: Utiliser word_to_idx!
        idf_value = mini_engine.idf_vector[word_idx]

        # Compter dans combien de docs le mot apparaÃ®t
        docs_with_word = sum(
            1
            for doc_idx in sample_indices
            if mini_engine.tf_matrix[doc_idx, word_idx] > 0
        )

        idf_data.append(
            {
                "Mot": word,
                "Docs contenant": f"{docs_with_word}/{len(sample_indices)}",
                "IDF": f"{idf_value:.4f}",
                "RaretÃ©": "ğŸ”´ Rare"
                if docs_with_word == 1
                else "ğŸŸ¡ Moyen"
                if docs_with_word == 2
                else "ğŸŸ¢ Commun",
            }
        )

    df_idf = pd.DataFrame(idf_data)
    st.markdown("**ğŸ“Š Tableau des IDF (Inverse Document Frequencies):**")
    st.dataframe(df_idf, use_container_width=True, hide_index=True)

    st.markdown("""
    **ğŸ’¡ InterprÃ©tation:**
    - IDF **Ã©levÃ©** (ex: 0.48) = mot **RARE** (apparaÃ®t dans peu de docs) â†’ **trÃ¨s informatif**! ğŸ”´
    - IDF **moyen** (ex: 0.18) = mot **commun** dans certains docs â†’ informatif ğŸŸ¡
    - IDF **faible** (ex: 0.00) = mot dans **TOUS** les docs â†’ peu informatif ğŸŸ¢
    """)

    # === Ã‰TAPE 4: TF-IDF (MULTIPLICATION) ===
    st.markdown("---")
    st.markdown("## ğŸ¯ Ã‰tape 4: Calcul Final TF-IDF")

    st.markdown("""
    **TF-IDF = TF Ã— IDF**

    On **multiplie** la frÃ©quence locale (TF) par la raretÃ© globale (IDF)!

    **RÃ©sultat:** Les mots qui sont Ã  la fois:
    - **FrÃ©quents dans le document** (TF Ã©levÃ©)
    - **Rares dans le corpus** (IDF Ã©levÃ©)

    ... ont un **score TF-IDF Ã©levÃ©**! C'est eux qui caractÃ©risent le document! âœ¨
    """)

    st.latex(r"\text{TF-IDF}(t, d) = \text{TF}(t, d) \times \text{IDF}(t)")

    # CrÃ©er tableau TF-IDF
    tfidf_data = []
    for doc_idx in sample_indices:
        row = {"Document": documents_titles[doc_idx][:30] + "..."}
        for word in query_words_in_vocab:
            word_idx = mini_engine.word_to_idx[word]  # FIX: Utiliser word_to_idx!
            tfidf_value = mini_engine.tfidf_matrix[doc_idx, word_idx]
            row[word] = f"{tfidf_value:.4f}"
        tfidf_data.append(row)

    df_tfidf = pd.DataFrame(tfidf_data)
    st.markdown("**ğŸ“Š Tableau des TF-IDF:**")
    st.dataframe(df_tfidf, use_container_width=True, hide_index=True)

    # === Ã‰TAPE 5: VECTORISATION DE LA QUERY ===
    st.markdown("---")
    st.markdown("## ğŸ”¤ Ã‰tape 5: Vectorisation de la RequÃªte")

    st.markdown("""
    On doit aussi calculer le **vecteur TF-IDF de la requÃªte**!

    **Processus:**
    1. Calculer le TF de chaque mot dans la requÃªte
    2. Multiplier par l'IDF (dÃ©jÃ  calculÃ©)
    3. On obtient le vecteur TF-IDF de la query!
    """)

    # Calculer vecteur query
    query_vector = np.zeros(len(mini_engine.vocabulary))
    query_word_count = {}
    for word in query_tokens:
        if word in mini_engine.vocabulary:
            query_word_count[word] = query_word_count.get(word, 0) + 1

    query_tfidf_data = []
    for word in query_words_in_vocab:
        word_idx = mini_engine.word_to_idx[word]  # FIX: Utiliser word_to_idx!
        tf_query = query_word_count.get(word, 0) / len(query_tokens)
        idf = mini_engine.idf_vector[word_idx]
        tfidf_query = tf_query * idf
        query_vector[word_idx] = tfidf_query

        query_tfidf_data.append(
            {
                "Mot": word,
                "TF (requÃªte)": f"{tf_query:.4f}",
                "IDF": f"{idf:.4f}",
                "TF-IDF": f"{tfidf_query:.4f}",
            }
        )

    df_query = pd.DataFrame(query_tfidf_data)
    st.markdown("**ğŸ“Š Vecteur TF-IDF de ta requÃªte:**")
    st.dataframe(df_query, use_container_width=True, hide_index=True)

    # === Ã‰TAPE 6: SIMILARITÃ‰ COSINUS ===
    st.markdown("---")
    st.markdown("## ğŸ“ Ã‰tape 6: Calcul de la SimilaritÃ© Cosinus")

    st.markdown("""
    **Comment comparer la requÃªte avec chaque document?**

    On utilise la **similaritÃ© cosinus** = mesure l'angle entre deux vecteurs!

    **Formule:**
    """)

    st.latex(r"\text{cos}(\theta) = \frac{A \cdot B}{\|A\| \times \|B\|}")

    st.markdown("""
    **OÃ¹:**
    - `A Â· B` = **Produit scalaire** (dot product)
    - `||A||` = **Norme** du vecteur A (longueur)
    - `||B||` = **Norme** du vecteur B

    **RÃ©sultat:** Score entre 0 et 1:
    - **1.0** = vecteurs identiques (angle = 0Â°) â†’ **documents trÃ¨s similaires!** ğŸ¯
    - **0.5** = vecteurs moyennement similaires
    - **0.0** = vecteurs orthogonaux (aucun mot en commun)
    """)

    # Calculer similaritÃ©s
    results = mini_engine.search(query, top_k=len(sample_indices))

    similarity_data = []
    for doc_idx, score in results:
        doc_vector = mini_engine.tfidf_matrix[doc_idx, :]

        # Calculs dÃ©taillÃ©s
        dot_product = np.dot(query_vector, doc_vector)
        norm_query = np.linalg.norm(query_vector)
        norm_doc = np.linalg.norm(doc_vector)

        similarity_data.append(
            {
                "Rang": len(similarity_data) + 1,
                "Document": documents_titles[doc_idx][:40] + "...",
                "Dot Product": f"{dot_product:.4f}",
                "Norme Query": f"{norm_query:.4f}",
                "Norme Doc": f"{norm_doc:.4f}",
                "SimilaritÃ©": f"{score:.4f}",
                "Pertinence": "ğŸ¥‡ Excellent!"
                if score > 0.3
                else "ğŸ¥ˆ Bon"
                if score > 0.1
                else "ğŸ¥‰ Faible",
            }
        )

    df_sim = pd.DataFrame(similarity_data)
    st.markdown("**ğŸ“Š Calculs de SimilaritÃ© pour Chaque Document:**")
    st.dataframe(df_sim, use_container_width=True, hide_index=True)

    # === RÃ‰SULTAT FINAL ===
    st.markdown("---")
    st.markdown("## ğŸ† RÃ©sultat Final: Classement")

    st.markdown("""
    Les documents sont **classÃ©s par ordre dÃ©croissant** de similaritÃ© cosinus!

    Le document avec le score le plus Ã©levÃ© est le **plus pertinent** pour ta requÃªte! ğŸ¯
    """)

    # Afficher le classement final avec style
    for rank, (doc_idx, score) in enumerate(results, 1):
        if rank == 1:
            st.success(
                f"ğŸ¥‡ **#{rank}:** {documents_titles[doc_idx]} - Score: **{score:.4f}**"
            )
        elif rank == 2:
            st.info(
                f"ğŸ¥ˆ **#{rank}:** {documents_titles[doc_idx]} - Score: **{score:.4f}**"
            )
        else:
            st.warning(
                f"ğŸ¥‰ **#{rank}:** {documents_titles[doc_idx]} - Score: **{score:.4f}**"
            )

    st.markdown("---")

    st.success("""
    âœ… **FÃ©licitations!** Tu as vu TOUS les calculs de TF-IDF en dÃ©tail!

    **RÃ©cap:**
    1. âœ… Vocabulaire construit
    2. âœ… TF calculÃ©s (frÃ©quence locale)
    3. âœ… IDF calculÃ©s (raretÃ© globale)
    4. âœ… TF-IDF = TF Ã— IDF
    5. âœ… Query vectorisÃ©e
    6. âœ… SimilaritÃ© cosinus calculÃ©e
    7. âœ… Documents classÃ©s!

    **ğŸ“ Tu maÃ®trises maintenant TF-IDF!**
    """)


def render_tfidf_performance(
    engine, documents_texts, load_time, fit_time, remove_stopwords
):
    """Performances TF-IDF avec benchmarks automatiques et pÃ©dagogie"""
    st.header("âš¡ Analyse des Performances TF-IDF")

    st.markdown("""
    Cette section t'explique **comment TF-IDF performe** et **pourquoi**!

    Tu verras:
    - Les mÃ©triques de ton corpus actuel
    - La complexitÃ© algorithmique expliquÃ©e
    - Des benchmarks automatiques sur diffÃ©rents datasets
    - L'impact de la taille du corpus sur la vitesse
    """)

    # ============================================================================
    # MÃ‰TRIQUES DU CORPUS ACTUEL
    # ============================================================================
    st.markdown("### ğŸ“Š MÃ©triques du Corpus Actuel")

    n_docs = len(documents_texts)
    n_vocab = len(engine.vocabulary)
    avg_doc_len = np.mean([len(doc) for doc in engine.documents])
    total_words = sum(len(doc) for doc in engine.documents)

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ“š Documents", f"{n_docs:,}", help="Nombre de documents indexÃ©s")
    col2.metric(
        "ğŸ”¤ Vocabulaire",
        f"{n_vocab:,}",
        help="Nombre de mots uniques (aprÃ¨s preprocessing)",
    )
    col3.metric(
        "ğŸ“ Mots/Doc", f"{avg_doc_len:.0f}", help="Longueur moyenne d'un document"
    )
    col4.metric(
        "ğŸ’¾ Total Mots", f"{total_words:,}", help="Nombre total de mots dans le corpus"
    )

    st.divider()

    # ============================================================================
    # TEMPS D'EXÃ‰CUTION
    # ============================================================================
    st.markdown("### â±ï¸ Temps d'ExÃ©cution")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("**ğŸ”„ Chargement**")
        st.metric("", f"{load_time:.3f}s")
        st.caption("Temps de lecture et prÃ©traitement des donnÃ©es")

    with col2:
        st.markdown("**ğŸ§® Indexation**")
        st.metric("", f"{fit_time:.3f}s")
        st.caption("Calcul des matrices TF, IDF et TF-IDF")

    with col3:
        st.markdown("**ğŸ’¡ EfficacitÃ©**")
        docs_per_sec = (
            n_docs / (load_time + fit_time) if (load_time + fit_time) > 0 else 0
        )
        st.metric("", f"{docs_per_sec:.0f} docs/s")
        st.caption("Nombre de documents indexÃ©s par seconde")

    # InterprÃ©tation automatique
    total_time = load_time + fit_time
    if total_time < 0.1:
        st.success(
            f"ğŸš€ **Ultra rapide!** Indexation en {total_time:.3f}s - parfait pour ce corpus!"
        )
    elif total_time < 1.0:
        st.info(f"âš¡ **Rapide!** Indexation en {total_time:.3f}s - trÃ¨s bon!")
    elif total_time < 5.0:
        st.info(f"ğŸ‘Œ **Correct!** Indexation en {total_time:.3f}s - acceptable.")
    else:
        st.warning(
            f"ğŸŒ **Lent...** Indexation en {total_time:.3f}s - corpus volumineux!"
        )

    st.divider()

    # ============================================================================
    # COMPLEXITÃ‰ ALGORITHMIQUE
    # ============================================================================
    st.markdown("### ğŸ§® ComplexitÃ© Algorithmique ExpliquÃ©e")

    st.markdown("""
    **TF-IDF a une complexitÃ© algorithmique en `O(n Ã— m)` oÃ¹:**
    - **n** = nombre de documents
    - **m** = longueur moyenne des documents

    **Ce que Ã§a signifie:**
    - Si tu **doubles le nombre de documents**, le temps d'indexation **double** aussi â±ï¸
    - Si tu **doubles la longueur des documents**, le temps **double** aussi â±ï¸

    **OpÃ©rations principales:**
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **1. Preprocessing (O(n Ã— m)):**
        - Tokenization
        - Lowercasing
        - Stopwords removal
        - Vocabulaire construction

        **2. Calcul TF (O(n Ã— m)):**
        - Compter occurrences
        - Normaliser par longueur
        - Stocker dans matrice
        """)

    with col2:
        st.markdown("""
        **3. Calcul IDF (O(n Ã— v)):**
        - Compter docs contenant chaque mot
        - Appliquer log
        - Stocker dans vecteur

        **4. Calcul TF-IDF (O(n Ã— v)):**
        - Multiplication TF Ã— IDF
        - Stocker matrice finale
        """)

    # Estimation thÃ©orique
    st.info(f"""
    **ğŸ’¡ Estimation pour ton corpus:**
    - ComplexitÃ© preprocessing: O({n_docs} Ã— {avg_doc_len:.0f}) â‰ˆ {n_docs * avg_doc_len:.0f} opÃ©rations
    - ComplexitÃ© TF-IDF: O({n_docs} Ã— {n_vocab}) â‰ˆ {n_docs * n_vocab:.0f} opÃ©rations

    **Total estimÃ©:** ~{(n_docs * avg_doc_len + n_docs * n_vocab):.0f} opÃ©rations
    """)

    st.divider()

    # ============================================================================
    # BENCHMARKS AUTOMATIQUES
    # ============================================================================
    st.markdown("### ğŸ Benchmarks Automatiques")

    st.markdown("""
    **On va comparer les performances** sur diffÃ©rents datasets pour voir l'impact de la taille! ğŸ“Š
    """)

    # Checkbox pour inclure les datasets Ã©tendus
    include_extended = st.checkbox(
        "ğŸ“¦ Inclure les datasets Ã©tendus (plus long: ~2-3 minutes)",
        value=False,
        help="Teste aussi les versions Ã©tendues des datasets pour voir l'impact sur les performances",
        key="tfidf_bench_extended"
    )

    if include_extended:
        st.warning("""
        âš ï¸ **Attention:** Avec les datasets Ã©tendus, les benchmarks prendront **2-3 minutes**.

        On testera:
        - ğŸ Recettes: **50 â†’ 200** docs
        - ğŸ¬ Films: **50 â†’ 200** docs
        - ğŸ“– Livres: **100 â†’ 801** docs
        - ğŸ“š Wikipedia: **100 â†’ 1000** docs
        """)
    else:
        st.info("""
        On testera les datasets en mode normal (~30 secondes):
        - ğŸ Recettes: **50** docs
        - ğŸ¬ Films: **50** docs
        - ğŸ“– Livres: **100** docs
        - ğŸ“š Wikipedia: **100** docs
        """)

    if st.button("ğŸš€ Lancer les Benchmarks!", type="primary", key="tfidf_bench_btn"):
        spinner_text = "â±ï¸ Benchmarking en cours... (2-3 minutes)" if include_extended else "â±ï¸ Benchmarking en cours... (30 secondes)"

        with st.spinner(spinner_text):
            from src.data_loader import load_dataset
            import time

            # DÃ©finir les tests selon le mode
            if include_extended:
                benchmark_tests = [
                    {"name": "recettes", "extended": False, "label": "Recettes (50 docs)"},
                    {"name": "films", "extended": False, "label": "Films (50 docs)"},
                    {"name": "livres", "extended": False, "label": "Livres (100 docs)"},
                    {"name": "recettes", "extended": True, "label": "Recettes Ã©tendu (200 docs)"},
                    {"name": "films", "extended": True, "label": "Films Ã©tendu (200 docs)"},
                    {"name": "wikipedia", "extended": False, "label": "Wikipedia (100 docs)"},
                    {"name": "livres", "extended": True, "label": "Livres Ã©tendu (801 docs)"},
                    {"name": "wikipedia", "extended": True, "label": "Wikipedia Ã©tendu (1000 docs)"},
                ]
            else:
                # Mode rapide: seulement les datasets normaux
                benchmark_tests = [
                    {"name": "recettes", "extended": False, "label": "Recettes (50 docs)"},
                    {"name": "films", "extended": False, "label": "Films (50 docs)"},
                    {"name": "livres", "extended": False, "label": "Livres (100 docs)"},
                    {"name": "wikipedia", "extended": False, "label": "Wikipedia (100 docs)"},
                ]

            results = []

            for test in benchmark_tests:
                try:
                    # Charger dataset
                    start = time.time()
                    dataset = load_dataset(test["name"], extended=test["extended"])
                    texts = [doc["text"] for doc in dataset]
                    load_t = time.time() - start

                    # Indexer
                    start = time.time()
                    test_engine = TFIDFEngine(texts, remove_stopwords=remove_stopwords)
                    test_engine.fit()
                    fit_t = time.time() - start

                    # Recherche (query simple)
                    start = time.time()
                    test_engine.search("test recherche exemple", top_k=5)
                    search_t = time.time() - start

                    results.append(
                        {
                            "Dataset": test["label"],
                            "Docs": len(texts),
                            "Vocab": len(test_engine.vocabulary),
                            "Load (s)": f"{load_t:.3f}",
                            "Index (s)": f"{fit_t:.3f}",
                            "Search (s)": f"{search_t:.3f}",
                            "Total (s)": f"{load_t + fit_t:.3f}",
                            "_total_numeric": load_t + fit_t,
                            "_docs_numeric": len(texts),
                        }
                    )
                except Exception as e:
                    st.error(f"Erreur sur {test['label']}: {e}")
                    continue

            if results:
                # Afficher tableau
                df_results = pd.DataFrame(results)
                df_display = df_results.drop(
                    columns=["_total_numeric", "_docs_numeric"]
                )

                st.markdown("**ğŸ“Š RÃ©sultats des Benchmarks:**")
                st.dataframe(df_display, use_container_width=True, hide_index=True)

                st.markdown("---")

                # Graphique: Temps vs Nombre de docs
                st.markdown(
                    "**ğŸ“ˆ Graphique: Temps d'Indexation vs Nombre de Documents**"
                )

                col_graph, col_analysis = st.columns([2, 1])

                with col_graph:
                    import matplotlib.pyplot as plt

                    fig, ax = plt.subplots(figsize=(8, 5))

                    x = [r["_docs_numeric"] for r in results]
                    y = [r["_total_numeric"] for r in results]
                    labels = [r["Dataset"] for r in results]

                    # Scatter plot
                    ax.scatter(x, y, s=100, alpha=0.6, color="#1f77b4")

                    # Labels
                    for i, label in enumerate(labels):
                        ax.annotate(
                            label,
                            (x[i], y[i]),
                            xytext=(5, 5),
                            textcoords="offset points",
                            fontsize=8,
                        )

                    # Ligne de tendance
                    if len(x) > 1:
                        z = np.polyfit(x, y, 1)
                        p = np.poly1d(z)
                        ax.plot(x, p(x), "r--", alpha=0.8, label="Tendance linÃ©aire")
                        ax.legend()

                    ax.set_xlabel("Nombre de Documents")
                    ax.set_ylabel("Temps Total (s)")
                    ax.set_title("Performance TF-IDF: Temps vs Taille du Corpus")
                    ax.grid(True, alpha=0.3)

                    plt.tight_layout()
                    st.pyplot(fig)

                with col_analysis:
                    st.markdown("**ğŸ” Analyse:**")

                    fastest = min(results, key=lambda x: x["_total_numeric"])
                    slowest = max(results, key=lambda x: x["_total_numeric"])

                    st.markdown(f"""
                    **âš¡ Plus rapide:**
                    {fastest["Dataset"]}
                    - {fastest["Total (s)"]}s
                    - {fastest["Docs"]} docs

                    **ğŸŒ Plus lent:**
                    {slowest["Dataset"]}
                    - {slowest["Total (s)"]}s
                    - {slowest["Docs"]} docs

                    **ğŸ’¡ Observation:**

                    La ligne rouge montre la tendance **linÃ©aire** â†’ confirme la complexitÃ© O(nÃ—m)!

                    **Impact de la taille:**
                    - Passer de 50 Ã  200 docs â†’ ~4Ã— plus lent
                    - Passer de 100 Ã  1000 docs â†’ ~10Ã— plus lent

                    C'est **proportionnel** au nombre de documents!
                    """)

                st.success("""
                âœ… **Conclusion des Benchmarks:**

                TF-IDF est **rapide et scalable** pour des corpus de taille petite Ã  moyenne!

                - **50-100 docs:** Quasi instantanÃ© (< 0.1s) âš¡
                - **200 docs:** TrÃ¨s rapide (< 0.2s) ğŸš€
                - **800-1000 docs:** Rapide (< 1s) ğŸ‘Œ
                - **> 10000 docs:** Optimisations recommandÃ©es (index inversÃ©, cache, etc.)

                **ğŸ’¡ Ã€ retenir:** La croissance est **linÃ©aire** â†’ prÃ©visible et fiable!
                """)

    st.divider()

    # ============================================================================
    # OPTIMISATIONS POSSIBLES
    # ============================================================================
    st.markdown("### ğŸš€ Optimisations Possibles")

    st.markdown("""
    Si ton corpus devient **trÃ¨s gros** (> 10,000 docs), voici comment accÃ©lÃ©rer TF-IDF:
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **1. Index InversÃ©**

        Au lieu de stocker une matrice complÃ¨te (docs Ã— mots), stocke seulement les mots **prÃ©sents** dans chaque document.

        â¡ï¸ Ã‰conomise de la RAM et accÃ©lÃ¨re la recherche!

        **2. Sparse Matrices**

        Utilise `scipy.sparse` au lieu de NumPy dense.

        â¡ï¸ Matrice TF-IDF souvent > 90% de zÃ©ros!

        **3. Preprocessing Cache**

        Sauvegarde les documents preprocessÃ©s sur disque.

        â¡ï¸ Ã‰vite de retokenizer Ã  chaque run!
        """)

    with col2:
        st.markdown("""
        **4. Batch Processing**

        Traite les documents par batch de 1000.

        â¡ï¸ Ã‰vite les pics de RAM!

        **5. Parallelization**

        Utilise `multiprocessing` pour tokenizer en parallÃ¨le.

        â¡ï¸ CPU multi-core = gain de vitesse!

        **6. Approximations**

        Limite le vocabulaire aux N mots les plus frÃ©quents.

        â¡ï¸ Trade-off prÃ©cision vs vitesse!
        """)

    st.info("""
    **ğŸ’¡ Pour ton usage actuel:**

    Avec des corpus de ~1000 docs, **aucune optimisation n'est nÃ©cessaire**!

    TF-IDF est dÃ©jÃ  **rapide** et **efficace** pour cette taille. ğŸ¯
    """)


# ============================================================================
# SECTION BM25 (NOUVEAU!)
# ============================================================================
