"""
Sections Embeddings et SynthÃ¨se pour l'application
Ã€ intÃ©grer dans app.py principal
"""

import streamlit as st
import numpy as np
import pandas as pd
import time

# Imports des visualizations nÃ©cessaires
from src.visualizations import (
    plot_embedding_space_3d,
    plot_clustering_2d,
    plot_multi_technique_comparison,
    plot_hybrid_alpha_effect,
)


# ============================================================================
# CACHE FUNCTIONS POUR EMBEDDINGS
# ============================================================================


@st.cache_resource
def create_embedding_engine(
    documents_texts: list, model_name: str = "paraphrase-multilingual-MiniLM-L12-v2"
):
    """CrÃ©e et index le moteur embeddings avec cache"""
    from src.embedding_engine import EmbeddingSearch

    engine = EmbeddingSearch(model_name=model_name)
    with st.spinner("ðŸ§  Calcul des embeddings (peut prendre 1-2min)..."):
        engine.index(documents_texts, use_cache=True, show_progress=False)
    return engine


def create_hybrid_engine(
    documents_texts: list, bm25_engine, embedding_engine, alpha: float = 0.5
):
    """
    CrÃ©e le moteur hybrid (pas de cache car trÃ¨s rapide)
    """
    from src.hybrid_search import HybridSearch

    return HybridSearch(documents_texts, bm25_engine, embedding_engine, alpha=alpha)


# ============================================================================
# SECTION EMBEDDINGS COMPLÃˆTE
# ============================================================================


def render_embeddings_section(
    dataset,
    documents_texts,
    documents_titles,
    documents_categories,
    tfidf_engine,
    bm25_engine,
    remove_stopwords,
    embedding_model_name="paraphrase-multilingual-MiniLM-L12-v2",
):
    """
    Section Embeddings complÃ¨te avec tous les onglets

    Args:
        embedding_model_name: Nom du modÃ¨le HuggingFace Ã  utiliser (sÃ©lectionnÃ© dans sidebar)
    """

    st.title("ðŸ§  Embeddings Vectoriels: Recherche SÃ©mantique")

    # Afficher le modÃ¨le sÃ©lectionnÃ©
    model_label = embedding_model_name.split("/")[-1]  # Prendre juste le nom
    st.caption(f"ðŸ¤– ModÃ¨le: **{model_label}** | ðŸ’¾ ChargÃ© depuis le cache")

    # Import de la fonction de navigation stylÃ©e
    from app import render_tab_navigation

    # Sub-navigation avec beaux boutons
    tabs_list = [
        "ðŸ“– Introduction",
        "ðŸ”¢ Concepts",
        "ðŸ” Recherche",
        "ðŸ“Š Exploration",
        "ðŸŽ“ Pas-Ã -Pas",
        "âš”ï¸ Comparaison",
        "ðŸŽ¨ Hybrid",
        "âš¡ Performance",
    ]
    tab = render_tab_navigation(
        tabs_list, "embeddings_tabs", default_tab="ðŸ“– Introduction"
    )

    # CrÃ©er l'engine embeddings (avec cache - 1 SEUL tÃ©lÃ©chargement par modÃ¨le!)
    embedding_engine = create_embedding_engine(documents_texts, embedding_model_name)

    if tab == "ðŸ“– Introduction":
        render_embeddings_intro(documents_texts, tfidf_engine)
    elif tab == "ðŸ”¢ Concepts":
        render_embeddings_concepts(embedding_engine, documents_texts)
    elif tab == "ðŸ” Recherche":
        render_embeddings_search(
            embedding_engine, documents_texts, documents_titles, documents_categories
        )
    elif tab == "ðŸ“Š Exploration":
        render_embeddings_exploration(
            embedding_engine, documents_texts, documents_titles, documents_categories
        )
    elif tab == "ðŸŽ“ Pas-Ã -Pas":
        render_embeddings_stepbystep(
            embedding_engine, documents_texts, documents_titles
        )
    elif tab == "âš”ï¸ Comparaison":
        render_embeddings_comparison(
            embedding_engine,
            tfidf_engine,
            bm25_engine,
            documents_texts,
            documents_titles,
        )
    elif tab == "ðŸŽ¨ Hybrid":
        render_embeddings_hybrid(
            embedding_engine,
            bm25_engine,
            documents_texts,
            documents_titles,
            documents_categories,
        )
    elif tab == "âš¡ Performance":
        render_embeddings_performance(
            embedding_engine, documents_texts, tfidf_engine, bm25_engine
        )


def render_embeddings_intro(documents_texts, tfidf_engine):
    """Introduction & Limites des approches lexicales"""
    st.header("ðŸ“– Au-delÃ  des Mots: La Recherche SÃ©mantique")

    st.info("""
    ðŸ“Š **RÃ©capitulatif de votre parcours d'apprentissage:**

    - **TF-IDF (1970s):** Recherche par frÃ©quence des mots, pondÃ©rÃ©e par raretÃ©
    - **BM25 (1994):** TF-IDF amÃ©liorÃ© avec saturation et normalisation intelligente

    **Principe commun:** Recherche **LEXICALE** = matching de mots exacts (comptage de tokens)

    **Limite fondamentale:** Ces algorithmes ne comprennent PAS le sens des mots! ðŸ¤¯
    """)

    st.divider()

    st.markdown("### âŒ Les 4 Fails Critiques des Approches Lexicales")

    # Fail #1: Synonymes
    st.error("""
    **Fail #1: Synonymes IgnorÃ©s ðŸ˜µ**

    TF-IDF et BM25 ne comprennent PAS que des mots diffÃ©rents peuvent avoir le mÃªme sens!
    """)

    st.markdown("""
    **Exemple Concret:**

    Imaginons que tu cherches des infos sur les **voitures rapides**.
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**ðŸ”Ž Ta Query:**")
        st.code("voiture rapide", language="text")

    with col2:
        st.markdown("**ðŸ“„ Un Document Pertinent:**")
        st.code("automobile vÃ©loce", language="text")

    st.markdown("""
    **Analyse lexicale (TF-IDF/BM25):**
    - Mots query: `["voiture", "rapide"]`
    - Mots doc: `["automobile", "vÃ©loce"]`
    - **Intersection:** âˆ… (vide!)

    **Verdict lexical:** Aucun mot commun â†’ Score = 0.00 ðŸ˜­

    **Analyse sÃ©mantique (Embeddings):**
    - "voiture" â‰ˆ "automobile" (synonymes)
    - "rapide" â‰ˆ "vÃ©loce" (synonymes)

    **Verdict sÃ©mantique:** Sens identique â†’ Score = 0.94 ðŸ”¥
    """)

    col1, col2 = st.columns(2)
    with col1:
        st.metric(
            "Score TF-IDF/BM25",
            "0.00",
            delta="Aucun mot commun!",
            delta_color="inverse",
        )
    with col2:
        st.metric(
            "Score Embeddings", "0.94", delta="Sens identique!", delta_color="normal"
        )

    st.success("""
    âœ… **Pourquoi Embeddings gagne:**

    Les embeddings capturent la **proximitÃ© sÃ©mantique** entre mots.
    Dans l'espace vectoriel, "voiture" et "automobile" sont des vecteurs **TRÃˆS PROCHES**,
    parce que le modÃ¨le a appris qu'ils apparaissent dans des contextes similaires!
    """)

    st.divider()

    # Fail #2: PolysÃ©mie
    st.error("""
    **Fail #2: PolysÃ©mie (Mots Ã  Double Sens) ðŸŽðŸ’»**

    Un mÃªme mot peut avoir des sens **DIFFÃ‰RENTS** selon le contexte!
    """)

    st.markdown("""
    **DÃ©finition:**
    **PolysÃ©mie** = Un mot avec plusieurs significations

    **Exemple classique avec "Apple":**
    """)

    poly_example = pd.DataFrame(
        {
            "Document": [
                "Apple fait de bons ordinateurs et smartphones",
                "Apple est un fruit dÃ©licieux et sain",
            ],
            "Sens RÃ©el": ["ðŸ’» Entreprise tech", "ðŸŽ Fruit"],
            'Score TF-IDF (query: "Apple")': ["0.87", "0.87"],
            "Score Embeddings": ["DiffÃ©renciÃ©s!", "Selon contexte"],
        }
    )

    st.dataframe(poly_example, use_container_width=True)

    st.markdown("""
    **ProblÃ¨me avec TF-IDF/BM25:**
    - Si ta query est "Apple ordinateur", les DEUX docs matchent "Apple" Ã©galement
    - Impossible de distinguer le sens! ðŸ˜µ

    **Solution Embeddings:**
    - Contexte 1: `["Apple", "ordinateurs", "smartphones"]` â†’ Vecteur orientÃ© "tech"
    - Contexte 2: `["Apple", "fruit", "dÃ©licieux"]` â†’ Vecteur orientÃ© "nourriture"

    Les embeddings capturent le **contexte global** et gÃ©nÃ¨rent des vecteurs diffÃ©rents!

    **Exemple en franÃ§ais:**
    - "La **banque** est fermÃ©e" â†’ ðŸ¦ Institution financiÃ¨re
    - "La **banque** du fleuve" â†’ ðŸžï¸ Bord de riviÃ¨re
    """)

    st.info("""
    ðŸ’¡ **Comment Ã§a marche?**

    Le mÃ©canisme d'**Attention** (dans les Transformers) regarde les mots voisins:
    - "banque" + "fermÃ©e" â†’ ProbabilitÃ© institution financiÃ¨re: 95%
    - "banque" + "fleuve" â†’ ProbabilitÃ© bord de riviÃ¨re: 92%

    RÃ©sultat: **Embeddings diffÃ©rents** selon le contexte! âœ¨
    """)

    st.divider()

    # Fail #3: Relations Conceptuelles
    st.error("""
    **Fail #3: Relations Conceptuelles ManquÃ©es ðŸ—¼ðŸ‡«ðŸ‡·**

    Incapable de comprendre les **relations implicites** entre concepts!
    """)

    st.markdown("""
    **Exemple: Connaissance GÃ©ographique**

    **Query:** "capitale France"
    """)

    example_data = pd.DataFrame(
        {
            "Document": [
                "Paris est une belle ville avec la Tour Eiffel",
                "La France est un grand pays europÃ©en",
            ],
            "Mots Communs (Query)": ["Aucun", '"France"'],
            "Score TF-IDF/BM25": [0.00, 0.73],
            "Score Embeddings": [0.88, 0.42],
            "Pertinence RÃ©elle": ["âœ… TRÃˆS pertinent!", "âš ï¸ Peu pertinent"],
        }
    )

    st.dataframe(example_data, use_container_width=True)

    st.markdown("""
    **Analyse du Fail:**

    **TF-IDF/BM25:**
    - Doc 1 ("Paris...") â†’ Score = 0.00 (aucun mot commun!)
    - Doc 2 ("France...") â†’ Score = 0.73 (matche "France")
    - **Classement:** Doc 2 > Doc 1

    **Mais en rÃ©alitÃ©:** Doc 1 est BEAUCOUP plus pertinent! ðŸ˜±

    **Embeddings Comprend:**
    - "Paris" **EST LA** capitale de la France (relation sÃ©mantique)
    - "capitale" + "France" â†’ ProximitÃ© avec "Paris" dans l'espace vectoriel
    - **Classement:** Doc 1 > Doc 2 âœ…

    **Autres exemples de relations:**
    - "Picasso" â†” "peinture cubisme"
    - "Einstein" â†” "relativitÃ© physique"
    - "Mozart" â†” "compositeur classique"
    """)

    st.warning("""
    âš ï¸ **Limite importante:**

    Ces relations NE SONT PAS programmÃ©es! Elles sont **apprises** automatiquement
    pendant l'entraÃ®nement sur des milliards de phrases.

    Si le modÃ¨le n'a jamais vu certaines relations, il ne les connaÃ®tra pas.
    """)

    st.divider()

    # Fail #4: Paraphrases
    st.error("""
    **Fail #4: Paraphrases Non Reconnues ðŸ±ðŸ­**

    Deux phrases avec le **mÃªme sens** mais des **mots totalement diffÃ©rents**!
    """)

    phrase_a = "Le chat poursuit la souris"
    phrase_b = "Le fÃ©lin traque le rongeur"

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**Phrase A:**")
        st.info(phrase_a)
        st.caption("Mots: `['chat', 'poursuit', 'souris']`")
    with col2:
        st.markdown("**Phrase B:**")
        st.info(phrase_b)
        st.caption("Mots: `['fÃ©lin', 'traque', 'rongeur']`")

    st.markdown("""
    **Analyse Lexicale (comptage de mots):**
    - **Mots totaux:** 6 (3 par phrase)
    - **Mots communs:** 2 ("le" Ã—2) - Seulement les articles!
    - **Mots de contenu communs:** 0 ðŸ˜±
    - **Vocabulaire overlap:** 33% (2/6)

    **Scores TF-IDF/BM25:**
    - SimilaritÃ© basÃ©e uniquement sur "le" (stopword!)
    - Score rÃ©sultant: ~0.15 (trÃ¨s faible)
    - **Conclusion lexicale:** Documents NON similaires âŒ
    """)

    similarity_comparison = pd.DataFrame(
        {
            "MÃ©thode": ["TF-IDF/BM25 (lexical)", "Embeddings (sÃ©mantique)"],
            "Mots MatchÃ©s": ["2/6 (articles)", "Sens global"],
            "Score": [0.15, 0.91],
            "Verdict": ["âŒ Non similaires", "âœ… TRÃˆS similaires!"],
        }
    )

    st.dataframe(similarity_comparison, use_container_width=True)

    st.success("""
    âœ… **Pourquoi Embeddings comprend:**

    Le modÃ¨le a appris pendant son entraÃ®nement:
    - "chat" â‰ˆ "fÃ©lin" (relation animal/catÃ©gorie)
    - "poursuit" â‰ˆ "traque" (synonyme d'action)
    - "souris" â‰ˆ "rongeur" (relation animal/catÃ©gorie)

    **RÃ©sultat:** MÃªme si AUCUN mot de contenu n'est identique,
    le **sens global** est capturÃ©! ðŸŽ¯
    """)

    st.markdown("""
    **Cas d'usage rÃ©els:**
    - **Customer support:** DÃ©tecter questions similaires formulÃ©es diffÃ©remment
    - **Recherche acadÃ©mique:** Trouver papers sur le mÃªme sujet avec terminologie variÃ©e
    - **E-commerce:** Comprendre intentions d'achat malgrÃ© descriptions diffÃ©rentes
    """)

    st.divider()

    st.success("""
    ### âœ… La Solution: Embeddings Vectoriels

    **RÃ©volution Paradigm:**

    Au lieu de **compter des mots** (approche symbolique),
    on **capture le SENS** dans un espace vectoriel dense (approche gÃ©omÃ©trique)!

    **Pipeline SimplifiÃ©:**
    ```
    Texte Brut
        â†“
    Transformer Neural Network (BERT/Sentence-BERT)
        â†“
    Vecteur Dense (384 dimensions)
        â†“
    Comparaison GÃ©omÃ©trique (distance/angle)
        â†“
    Score de SimilaritÃ© SÃ©mantique
    ```

    **Le Magic Trick:** ðŸª„
    - "voiture" â†’ `[0.23, -0.81, 0.45, ...]`
    - "automobile" â†’ `[0.21, -0.79, 0.47, ...]`

    Ces deux vecteurs sont **PROCHES** dans l'espace Ã  384 dimensions!

    **Distance cosinus:** ~0.02 (trÃ¨s faible) â†’ Sens similaire! âœ…
    """)

    st.markdown("---")

    st.markdown("""
    ### ðŸš€ Passons Ã  la Suite!

    Dans les prochains onglets, tu vas apprendre:
    1. **Concepts:** Comment fonctionnent les Transformers et l'Attention
    2. **Recherche:** Tester la recherche sÃ©mantique interactive
    3. **Exploration:** Visualiser l'espace vectoriel en 3D
    4. **Pas-Ã -Pas:** Calculs dÃ©taillÃ©s d'un exemple complet
    5. **Comparaison:** Embeddings vs TF-IDF vs BM25
    6. **Hybrid:** Combiner le meilleur des deux mondes
    7. **Performance:** Optimisations et benchmarks

    Let's go! ðŸ”¥
    """)


def render_embeddings_concepts(embedding_engine, documents_texts):
    """Concepts dÃ©taillÃ©s des embeddings"""
    st.header("ðŸ”¢ Comprendre les Embeddings en Profondeur")

    with st.expander("ðŸ“Š **Sparse vs Dense: La RÃ©volution**", expanded=True):
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("### ðŸ“Š TF-IDF (Sparse)")
            st.code("""
Vocabulaire: 10,000 mots
Doc: "Le chat mange"

Vector: [0, 0, 0, ..., 0.5, 0, ..., 0.8, ...]
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           99.97% de zÃ©ros!

Dimensions: 10,000
Non-zÃ©ros: ~3 (0.03%)
            """)
            st.warning("**ProblÃ¨me:** Ã‰norme mais vide!")

        with col2:
            st.markdown("### ðŸ§  Embeddings (Dense)")
            st.code("""
Doc: "Le chat mange"

Vector: [0.234, -0.891, 0.456, ..., -0.123]
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        Toutes valeurs non-nulles!

Dimensions: 384
Non-zÃ©ros: 384 (100%)
            """)
            st.success("**Avantage:** Compact et riche!")

        st.info("""
        **ðŸ’¡ Pourquoi Dense est Mieux:**
        - Chaque dimension capture un "concept" sÃ©mantique
        - Pas de dimensions gaspillÃ©es
        - ReprÃ©sentation BEAUCOUP plus riche! âœ¨
        """)

    with st.expander("ðŸ”„ **Pipeline: De Texte Ã  Vecteur**"):
        st.markdown("""
        ### Le Parcours d'un Texte dans le RÃ©seau

        ```text
        1. Texte Brut
           "Le chat mange du poisson"

        2. Tokenization
           ["le", "chat", "mange", "du", "poisson"]

        3. Neural Network (Transformer - BERT)
           - Embedding Layer: mots â†’ vecteurs initiaux
           - Attention Layers (Ã—12): capture le contexte
           - Pooling: agrÃ©gation en UN seul vecteur

        4. Vecteur Final
           [0.234, -0.891, 0.456, ..., -0.123]  (384 dimensions)
        ```
        """)

        st.success(f"""
        **Votre modÃ¨le actuel:** `{embedding_engine.model_name}`

        - **Dimensions:** {embedding_engine.embedding_dim}
        - **Type:** Sentence-BERT multilingue
        - **EntraÃ®nÃ© sur:** Des milliards de phrases
        """)

    with st.expander("ðŸ¤” **Qu'est-ce qu'un Transformer?**"):
        st.markdown("""
        ### Architecture BERT/Sentence-BERT

        **Transformer** = Architecture de rÃ©seau de neurones rÃ©volutionnaire (2017)
        - UtilisÃ©e par GPT, BERT, ChatGPT, etc.
        - BasÃ©e sur le mÃ©canisme d'**Attention**

        ---

        ### ðŸ’¡ Le MÃ©canisme d'Attention (le CÅ“ur)

        **ProblÃ¨me Ã  rÃ©soudre:** Comment comprendre qu'un mot a des sens diffÃ©rents selon le contexte?

        **Exemple classique:** Le mot **"banque"**
        """)

        col1, col2 = st.columns(2)

        with col1:
            st.info("""
            **Phrase 1:**
            "La **banque** est fermÃ©e"

            ðŸ¦ **Contexte:** institution financiÃ¨re

            **Mots clÃ©s:**
            - "fermÃ©e" (horaires)
            - Pas de fleuve/riviÃ¨re
            """)

        with col2:
            st.success("""
            **Phrase 2:**
            "La **banque** du fleuve"

            ðŸžï¸ **Contexte:** bord de riviÃ¨re

            **Mots clÃ©s:**
            - "fleuve" (gÃ©ographie)
            - Pas d'horaires/argent
            """)

        st.markdown("""
        ### ðŸ” Comment l'Attention Fonctionne

        **MÃ©canisme:** Chaque mot "regarde" tous les autres mots pour comprendre son sens!

        **Exemple avec la phrase:** "Le chat noir mange du poisson"
        """)

        # Tableau d'attention
        attention_example = pd.DataFrame(
            {
                "Mot": ["noir"],
                'â†’ "le"': ["0.05 (faible)"],
                'â†’ "chat"': ["0.75 (FORT!)"],
                'â†’ "noir"': ["0.02 (self)"],
                'â†’ "mange"': ["0.08 (faible)"],
                'â†’ "du"': ["0.03 (faible)"],
                'â†’ "poisson"': ["0.07 (faible)"],
            }
        )

        st.dataframe(attention_example, use_container_width=True, hide_index=True)

        st.markdown("""
        **InterprÃ©tation:**
        - "noir" regarde surtout vers "chat" (0.75) â†’ Il dÃ©crit le chat!
        - Les autres mots ont peu d'attention â†’ Moins importants pour comprendre "noir"

        **Ce que le rÃ©seau apprend:**
        - "noir" est un **adjectif** qui qualifie "chat"
        - Donc le vecteur de "noir" sera influencÃ© par "chat"
        - RÃ©sultat: embeddings contextuels! ðŸŽ¯

        ---

        ### ðŸ—ï¸ Architecture ComplÃ¨te (SimplifiÃ©)

        ```
        Input: "Le chat noir"

        1. Embedding Layer
           â†“ Chaque mot â†’ vecteur initial

        2. Attention Layer #1
           â†“ Les mots se "regardent" entre eux

        3. Feed Forward
           â†“ Transformation non-linÃ©aire

        4. Attention Layer #2
           â†“ Encore plus de contexte

        ... (Ã—12 couches) ...

        12. Attention Layer #12
           â†“ ComprÃ©hension profonde

        Output: Vecteurs contextuels riches!
        ```

        **AprÃ¨s 12 couches d'attention:**
        Le rÃ©seau a une comprÃ©hension **profonde** du sens de chaque mot dans son contexte! ðŸ§ 

        **DiffÃ©rence avec Word2Vec:**
        - Word2Vec: "banque" a **toujours** le mÃªme vecteur
        - BERT: "banque" a un vecteur **diffÃ©rent** selon le contexte! âœ¨
        """)

    with st.expander("ðŸ“Š **Anatomie d'un Vecteur d'Embedding**"):
        st.markdown(f"""
        ### ðŸ”¬ Qu'y a-t-il dans un Vecteur?

        Un embedding de `{embedding_engine.embedding_dim}` dimensions, c'est quoi concrÃ¨tement?
        Prenons un exemple rÃ©el!
        """)

        # GÃ©nÃ©rer un embedding d'exemple
        sample_text = "Le chat noir mange du poisson"
        sample_embedding = embedding_engine.model.encode([sample_text])[0]

        col_graph, col_analysis = st.columns([3, 2])

        with col_graph:
            import matplotlib.pyplot as plt
            import numpy as np

            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

            # Graphique 1: Distribution des valeurs
            ax1.hist(
                sample_embedding, bins=50, color="#3498db", alpha=0.7, edgecolor="black"
            )
            ax1.axvline(x=0, color="red", linestyle="--", linewidth=2, label="ZÃ©ro")
            ax1.axvline(
                x=np.mean(sample_embedding),
                color="green",
                linestyle="--",
                linewidth=2,
                label=f"Moyenne ({np.mean(sample_embedding):.3f})",
            )
            ax1.set_xlabel("Valeur de la dimension", fontsize=11, fontweight="bold")
            ax1.set_ylabel("Nombre de dimensions", fontsize=11, fontweight="bold")
            ax1.set_title(
                f"Distribution des {embedding_engine.embedding_dim} dimensions",
                fontsize=12,
                fontweight="bold",
            )
            ax1.legend(fontsize=10)
            ax1.grid(True, alpha=0.3)

            # Graphique 2: Ã‰chantillon des premiÃ¨res dimensions
            n_show = 50
            dims = np.arange(n_show)
            values = sample_embedding[:n_show]
            colors = ["#2ecc71" if v > 0 else "#e74c3c" for v in values]

            ax2.bar(
                dims, values, color=colors, alpha=0.7, edgecolor="black", linewidth=0.5
            )
            ax2.axhline(y=0, color="black", linestyle="-", linewidth=1)
            ax2.set_xlabel("Index de la dimension", fontsize=11, fontweight="bold")
            ax2.set_ylabel("Valeur", fontsize=11, fontweight="bold")
            ax2.set_title(
                f"Valeurs des {n_show} premiÃ¨res dimensions (vert=positif, rouge=nÃ©gatif)",
                fontsize=11,
                fontweight="bold",
            )
            ax2.grid(True, alpha=0.3, axis="y")

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with col_analysis:
            st.markdown(f"""
            ### ðŸ“ˆ Analyse du Vecteur

            **Texte analysÃ©:**
            > "{sample_text}"

            **Statistiques:**
            - **Dimensions:** {embedding_engine.embedding_dim}
            - **Valeur min:** {np.min(sample_embedding):.3f}
            - **Valeur max:** {np.max(sample_embedding):.3f}
            - **Moyenne:** {np.mean(sample_embedding):.3f}
            - **Ã‰cart-type:** {np.std(sample_embedding):.3f}

            **ðŸ’¡ Observations:**

            ðŸ“Š **Graphique du haut:**
            - Distribution ~normale centrÃ©e autour de 0
            - Valeurs entre -1 et +1 (typique)
            - Pas de zÃ©ros â†’ Dense! âœ…

            ðŸ“Š **Graphique du bas:**
            - Alternance positif/nÃ©gatif
            - Chaque dimension = "concept"
            - Ex: Dim #12 = "animal"?
            - Ex: Dim #37 = "action"?

            **ðŸ§  Chaque dimension capture:**
            - Syntaxe (nom, verbe, etc.)
            - SÃ©mantique (animal, nourriture)
            - Relations (agent, patient)
            - Contexte culturel/linguistique

            C'est cette richesse qui permet la recherche sÃ©mantique! ðŸŽ¯
            """)

    with st.expander("ðŸ”— **SimilaritÃ© SÃ©mantique: Voir les Relations**"):
        st.markdown("""
        ### ðŸŽ¯ Comment les Embeddings Capturent les Relations?

        GÃ©nÃ©rons des embeddings pour plusieurs phrases et comparons-les!
        """)

        # Phrases d'exemple avec relations sÃ©mantiques
        example_phrases = [
            "Le chat mange du poisson",
            "Un chien dÃ©vore de la viande",
            "L'ordinateur calcule des nombres",
            "La voiture roule sur la route",
            "Le poisson nage dans l'eau",
            "Un fÃ©lin chasse une souris",
        ]

        # Calculer les embeddings
        embeddings_matrix = embedding_engine.model.encode(example_phrases)

        # Calculer la matrice de similaritÃ© cosinus
        from sklearn.metrics.pairwise import cosine_similarity

        similarity_matrix = cosine_similarity(embeddings_matrix)

        col_heatmap, col_explanation = st.columns([3, 2])

        with col_heatmap:
            import matplotlib.pyplot as plt

            fig, ax = plt.subplots(figsize=(10, 8))

            # Heatmap
            im = ax.imshow(
                similarity_matrix, cmap="RdYlGn", vmin=0, vmax=1, aspect="auto"
            )

            # Axes
            ax.set_xticks(np.arange(len(example_phrases)))
            ax.set_yticks(np.arange(len(example_phrases)))

            # Labels courts pour l'affichage
            short_labels = [
                "Chat/poisson",
                "Chien/viande",
                "Ordi/calcul",
                "Voiture/route",
                "Poisson/eau",
                "FÃ©lin/souris",
            ]

            ax.set_xticklabels(short_labels, rotation=45, ha="right", fontsize=9)
            ax.set_yticklabels(short_labels, fontsize=9)

            # Annotations des valeurs
            for i in range(len(example_phrases)):
                for j in range(len(example_phrases)):
                    value = similarity_matrix[i, j]
                    color = "white" if value > 0.7 else "black"
                    ax.text(
                        j,
                        i,
                        f"{value:.2f}",
                        ha="center",
                        va="center",
                        color=color,
                        fontsize=9,
                        fontweight="bold",
                    )

            ax.set_title(
                "Heatmap de SimilaritÃ© Cosinus (Embeddings)",
                fontsize=13,
                fontweight="bold",
                pad=15,
            )

            # Colorbar
            cbar = plt.colorbar(im, ax=ax)
            cbar.set_label("SimilaritÃ© (0=diffÃ©rent, 1=identique)", fontsize=10)

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with col_explanation:
            st.markdown("""
            ### ðŸ” Lecture de la Heatmap

            **Couleurs:**
            - ðŸŸ¢ **Vert foncÃ©:** TrÃ¨s similaire (~0.8-1.0)
            - ðŸŸ¡ **Jaune:** Similaire (~0.5-0.8)
            - ðŸ”´ **Rouge:** Peu similaire (~0.0-0.5)

            **ðŸ’¡ Observations ClÃ©s:**

            **Diagonale = 1.00 (vert):**
            - Chaque phrase comparÃ©e Ã  elle-mÃªme
            - SimilaritÃ© parfaite âœ…

            **Relations sÃ©mantiques dÃ©tectÃ©es:**
            """)

            # Trouver les paires les plus similaires (hors diagonale)
            similarity_no_diag = similarity_matrix.copy()
            np.fill_diagonal(similarity_no_diag, 0)

            # Top 3 paires
            flat_indices = np.argsort(similarity_no_diag.ravel())[::-1][:3]
            top_pairs = [
                (i // len(example_phrases), i % len(example_phrases))
                for i in flat_indices
            ]

            for rank, (i, j) in enumerate(top_pairs, 1):
                sim = similarity_matrix[i, j]
                st.success(f"""
                **#{rank} - SimilaritÃ©: {sim:.3f}**
                - "{example_phrases[i][:30]}..."
                - "{example_phrases[j][:30]}..."
                """)

            st.markdown("""
            **ðŸ§  Pourquoi ces relations?**

            Le modÃ¨le a appris que:
            - "chat" â‰ˆ "chien" â‰ˆ "fÃ©lin" (animaux)
            - "mange" â‰ˆ "dÃ©vore" â‰ˆ "chasse" (actions)
            - "poisson" apparaÃ®t 2Ã— (sujet et objet!)

            **âš ï¸ Notez bien:**
            - Phrases sans mots communs peuvent Ãªtre similaires!
            - C'est la **sÃ©mantique**, pas le lexique!
            """)

    with st.expander("ðŸ“š **Comment le RÃ©seau Apprend (PrÃ©-entraÃ®nement)**"):
        st.markdown("""
        ### Masked Language Modeling (MLM)

        **Objectif:** Forcer le rÃ©seau Ã  comprendre le contexte pour prÃ©dire des mots manquants.

        **TÃ¢che d'entraÃ®nement:**
        """)

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**1ï¸âƒ£ Phrase originale**")
            st.code("Le chat mange du poisson", language="text")

        with col2:
            st.markdown("**2ï¸âƒ£ Masquer un mot**")
            st.code("Le [MASK] mange du poisson", language="text")

        with col3:
            st.markdown("**3ï¸âƒ£ PrÃ©dire**")
            st.code("PrÃ©diction: chat", language="text")

        st.markdown("""
        ### ðŸ¤” Pourquoi Ã‡a Marche?

        Pour prÃ©dire correctement [MASK] = "chat", le rÃ©seau DOIT analyser:

        **Analyse syntaxique:**
        - "Le [MASK]" â†’ Probablement un **nom** (article + nom)
        - "mange" â†’ Le sujet doit Ãªtre **vivant** (pas "table", "livre")

        **Analyse sÃ©mantique:**
        - "mange du poisson" â†’ Animal qui mange du poisson
        - Options: chat, chien, ours, humain
        - Dans ce contexte: **chat** est le plus probable! ðŸŽ¯

        **Analyse contextuelle:**
        - Langue: franÃ§ais (pas "cat", "gato")
        - Registre: langue courante (pas jargon technique)

        ---

        ### ðŸ“Š Exemples d'EntraÃ®nement RÃ©els
        """)

        training_examples = pd.DataFrame(
            {
                "Phrase MaskÃ©e": [
                    "Paris est la [MASK] de la France",
                    "Einstein a dÃ©couvert la thÃ©orie de la [MASK]",
                    "Le [MASK] est un fruit rouge",
                    "J'aime coder en [MASK] pour le web",
                ],
                "PrÃ©diction": [
                    "capitale",
                    "relativitÃ©",
                    "fraise / tomate",
                    "JavaScript / Python",
                ],
                "DifficultÃ©": [
                    "â­ Facile",
                    "â­â­ Moyen",
                    "â­â­ Moyen",
                    "â­â­â­ Difficile",
                ],
            }
        )

        st.dataframe(training_examples, use_container_width=True, hide_index=True)

        st.markdown("""
        ### ðŸŽ“ Ce Que le RÃ©seau Apprend

        **AprÃ¨s des milliards d'exemples:**

        1. **Syntaxe:** Structure des phrases (sujet-verbe-complÃ©ment)
        2. **SÃ©mantique:** Relations entre concepts (capitale â†” pays)
        3. **Connaissances factuelles:** Paris est la capitale de France
        4. **Contexte:** Mots qui vont ensemble (coder â†’ JavaScript/Python)

        **RÃ©sultat:**
        Le rÃ©seau apprend des **reprÃ©sentations vectorielles riches** qui capturent le sens! âœ¨

        **Comparaison avec TF-IDF:**
        - TF-IDF: Compte les mots (aucun apprentissage)
        - BERT: Apprend le sens via des milliards d'exemples! ðŸ”¥
        """)

    with st.expander("ðŸŒˆ **Les Dimensions: Que ReprÃ©sentent-elles?**"):
        st.markdown("""
        ### L'Espace Vectoriel Ã  384 Dimensions

        **Question fondamentale:** Qu'est-ce que ces 384 nombres reprÃ©sentent? ðŸ¤”

        **RÃ©ponse courte:** Des **concepts sÃ©mantiques** appris automatiquement!

        ---

        ### ðŸŽ¨ Exemple SimplifiÃ© (Illustration)

        **Note:** Les vraies dimensions sont beaucoup plus complexes, mais voici l'intuition:
        """)

        dim_examples = pd.DataFrame(
            {
                "Dimension": [
                    "Dim 0",
                    "Dim 1",
                    "Dim 2",
                    "Dim 3",
                    "Dim 4",
                    "...",
                    "Dim 383",
                ],
                "Concept (SimplifiÃ©)": [
                    "vivant â†” non-vivant",
                    "concret â†” abstrait",
                    "positif â†” nÃ©gatif",
                    "animal â†” objet",
                    "action â†” Ã©tat",
                    "...",
                    "??? (complexe)",
                ],
                "Exemple +": [
                    "chat (+0.9)",
                    "pomme (+0.8)",
                    "heureux (+0.9)",
                    "chien (+0.85)",
                    "courir (+0.7)",
                    "...",
                    "???",
                ],
                "Exemple âˆ’": [
                    "table (âˆ’0.7)",
                    "amour (âˆ’0.6)",
                    "triste (âˆ’0.8)",
                    "voiture (âˆ’0.75)",
                    "dormir (âˆ’0.6)",
                    "...",
                    "???",
                ],
            }
        )

        st.dataframe(dim_examples, use_container_width=True, hide_index=True)

        st.markdown("""
        ### âš ï¸ Attention: Simplification!

        En rÃ©alitÃ©, **aucune dimension n'est aussi simple**.

        **Chaque dimension** capture une **combinaison complexe** de milliers de concepts:
        - Syntaxe + sÃ©mantique + contexte
        - Relations multiples simultanÃ©es
        - Interactions non-linÃ©aires

        **Exemple rÃ©el:**
        - Dimension 42 pourrait capturer: "animal domestique + affection + relation humaine"
        - Pas juste "animal" ou "domestique" sÃ©parÃ©ment

        ---

        ### ðŸ”¬ Comment les Dimensions Ã‰mergent

        **Le rÃ©seau n'est PAS programmÃ© avec ces concepts!**

        **Processus d'apprentissage:**

        1. **Initialisation:** Valeurs alÃ©atoires
        2. **EntraÃ®nement:** Millions d'exemples de texte
        3. **Ajustement:** Le rÃ©seau ajuste les poids pour mieux prÃ©dire
        4. **Ã‰mergence:** Les dimensions se spÃ©cialisent naturellement!

        **Exemple concret:**
        ```
        Le rÃ©seau voit:
        - "chat" apparaÃ®t avec "miaule", "ronronne", "souris"
        - "chien" apparaÃ®t avec "aboie", "queue", "maÃ®tre"
        - "table" apparaÃ®t avec "bois", "chaise", "manger"

        AprÃ¨s entraÃ®nement:
        - Dimension X encode "animalitÃ©" (chat et chien proche, table loin)
        - Dimension Y encode "domestique" (chat, chien, et table proche!)
        - Dimension Z encode "mobilitÃ©" (chat et chien proche, table loin)

        RÃ©sultat: "chat" et "chien" sont proches dans l'espace!
        ```

        ---

        ### ðŸŽ¯ Ce Qui Importe

        **Peu importe ce que chaque dimension reprÃ©sente individuellement!**

        **Ce qui compte:**
        - Les **relations gÃ©omÃ©triques** entre vecteurs
        - "chat" et "chien" sont **proches** (petite distance)
        - "chat" et "ordinateur" sont **Ã©loignÃ©s** (grande distance)

        **Magie des embeddings:** Les relations sÃ©mantiques Ã©mergent naturellement! ðŸª„

        **Analogie:**
        - Tu n'as pas besoin de comprendre comment fonctionne chaque neurone de ton cerveau
        - Ce qui compte c'est que tu puisses reconnaÃ®tre un chat! ðŸ±
        """)

    with st.expander("âš”ï¸ **Battle: TF-IDF vs Embeddings**"):
        st.markdown("""
        ### ðŸ¥Š Le Test Ultime: Comprendre la DiffÃ©rence

        Prenons des **paires de phrases** et comparons les similaritÃ©s selon:
        - **Approche Lexicale** (TF-IDF) â†’ Compte les mots communs
        - **Approche SÃ©mantique** (Embeddings) â†’ Comprend le sens
        """)

        # Paires de test
        test_pairs = [
            ("Un chat noir dort", "Le fÃ©lin sombre se repose", "Synonymes parfaits"),
            (
                "Je cuisine un plat italien",
                "Je prÃ©pare une recette de pÃ¢tes",
                "MÃªme sujet",
            ),
            (
                "Paris est belle",
                "La capitale franÃ§aise est magnifique",
                "RÃ©fÃ©rence identique",
            ),
            ("Le chien aboie fort", "La table est en bois", "Aucun rapport"),
            ("J'adore la programmation", "Je dÃ©teste coder", "Contraires"),
            ("Voiture rapide rouge", "Automobile vÃ©loce Ã©carlate", "Synonymes exacts"),
        ]

        # Calculer les similaritÃ©s
        results_data = []

        for phrase1, phrase2, description in test_pairs:
            # Embedding similarity
            emb1, emb2 = embedding_engine.model.encode([phrase1, phrase2])
            emb_sim = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))

            # TF-IDF similarity (approximation simple avec Jaccard sur les mots)
            words1 = set(phrase1.lower().split())
            words2 = set(phrase2.lower().split())
            if len(words1.union(words2)) > 0:
                jaccard_sim = len(words1.intersection(words2)) / len(
                    words1.union(words2)
                )
            else:
                jaccard_sim = 0.0

            results_data.append(
                {
                    "Description": description,
                    "TF-IDF (lexical)": jaccard_sim,
                    "Embeddings (sÃ©mantique)": emb_sim,
                    "DiffÃ©rence": abs(emb_sim - jaccard_sim),
                }
            )

        # Graphique comparatif
        col_graph, col_analysis = st.columns([3, 2])

        with col_graph:
            import matplotlib.pyplot as plt

            fig, ax = plt.subplots(figsize=(10, 7))

            x_pos = np.arange(len(results_data))
            width = 0.35

            tfidf_scores = [d["TF-IDF (lexical)"] for d in results_data]
            emb_scores = [d["Embeddings (sÃ©mantique)"] for d in results_data]
            labels = [d["Description"] for d in results_data]

            # Barres
            ax.barh(
                x_pos - width / 2,
                tfidf_scores,
                width,
                label="TF-IDF (lexical)",
                color="#3498db",
                alpha=0.8,
                edgecolor="black",
            )
            ax.barh(
                x_pos + width / 2,
                emb_scores,
                width,
                label="Embeddings (sÃ©mantique)",
                color="#2ecc71",
                alpha=0.8,
                edgecolor="black",
            )

            # Annotations
            for i, (tf, emb) in enumerate(zip(tfidf_scores, emb_scores)):
                ax.text(
                    tf + 0.02,
                    i - width / 2,
                    f"{tf:.2f}",
                    va="center",
                    fontsize=9,
                    fontweight="bold",
                )
                ax.text(
                    emb + 0.02,
                    i + width / 2,
                    f"{emb:.2f}",
                    va="center",
                    fontsize=9,
                    fontweight="bold",
                )

            ax.set_yticks(x_pos)
            ax.set_yticklabels(labels, fontsize=10)
            ax.set_xlabel(
                "Score de SimilaritÃ© (0=diffÃ©rent, 1=identique)",
                fontsize=11,
                fontweight="bold",
            )
            ax.set_title(
                "Comparaison: TF-IDF vs Embeddings",
                fontsize=13,
                fontweight="bold",
                pad=15,
            )
            ax.legend(fontsize=10, loc="lower right")
            ax.grid(True, alpha=0.3, axis="x")
            ax.set_xlim(0, 1.1)

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with col_analysis:
            st.markdown("""
            ### ðŸ” Analyse des RÃ©sultats

            **Paires critiques:**
            """)

            # Trouver les cas oÃ¹ embeddings >> TF-IDF
            for data in results_data:
                if data["Embeddings (sÃ©mantique)"] > data["TF-IDF (lexical)"] + 0.2:
                    st.success(f"""
                    **{data["Description"]}**
                    - TF-IDF: {data["TF-IDF (lexical)"]:.2f}
                    - Embeddings: {data["Embeddings (sÃ©mantique)"]:.2f}
                    - âœ… Embeddings gagne!
                    """)

            st.markdown("""
            ---

            **ðŸ’¡ Ce que Ã§a montre:**

            **Cas "Synonymes parfaits":**
            - Phrases signifient la MÃŠME chose
            - TF-IDF: ~0.0 (aucun mot commun!)
            - Embeddings: ~0.8 (sens identique!) âœ¨

            **Cas "Contraires":**
            - "adore" vs "dÃ©teste" â†’ opposÃ©s
            - TF-IDF: Pense que c'est similaire
            - Embeddings: DÃ©tecte l'opposition! ðŸŽ¯

            **Cas "Aucun rapport":**
            - Les deux mÃ©thodes concordent
            - Peu de mots communs = peu de sens commun

            ---

            **ðŸ† Verdict:**

            **TF-IDF:**
            - Bon pour correspondance exacte
            - Rapide et simple
            - LimitÃ© au lexique

            **Embeddings:**
            - Comprend les synonymes âœ…
            - Capture le sens profond âœ…
            - DÃ©tecte les nuances âœ…
            - **Mais:** Plus lent et complexe
            """)

        st.divider()

        st.info("""
        **ðŸŽ“ Conclusion PÃ©dagogique**

        Les embeddings ne sont PAS magiques! Ils ont simplement appris Ã :
        1. ReconnaÃ®tre que "chat" et "fÃ©lin" sont liÃ©s (via des milliards d'exemples)
        2. Placer ces mots proches dans l'espace vectoriel
        3. Ã‰tendre cette logique Ã  des phrases entiÃ¨res

        **RÃ©sultat:** Recherche sÃ©mantique = comprendre l'intention, pas juste les mots! ðŸš€
        """)


def render_embeddings_search(
    embedding_engine, documents_texts, documents_titles, documents_categories
):
    """Recherche interactive avec embeddings"""
    st.header("ðŸ” Recherche SÃ©mantique Interactive")

    st.markdown("""
    Teste la puissance de la recherche sÃ©mantique!
    Essaie des **synonymes**, des **paraphrases**, des **concepts**! ðŸš€
    """)

    # Utiliser un formulaire pour Ã©viter les problÃ¨mes de rerun
    with st.form("emb_search_form", clear_on_submit=False):
        col1, col2 = st.columns([3, 1])

        with col1:
            query = st.text_input(
                "ðŸ”Ž Ta recherche:",
                value="animal domestique fidÃ¨le",  # Valeur par dÃ©faut!
                placeholder="animal domestique, cuisine italienne, technologie moderne...",
                key="emb_query_input",
                help='ðŸ’¡ **Exemples:** "animal domestique fidÃ¨le" | "cuisine italienne traditionnelle" | "technologie moderne innovation" | "voyage aventure exotique"',
            )

        with col2:
            top_k = st.slider("RÃ©sultats:", 3, 20, 5, key="emb_topk_slider")

        # Bouton de soumission (Enter fonctionne aussi!)
        submitted = st.form_submit_button(
            "ðŸš€ Rechercher SÃ©mantiquement!", type="primary"
        )

    if submitted and query:
        with st.spinner("ðŸ§  Recherche sÃ©mantique en cours..."):
            results = embedding_engine.search(query, top_k=top_k)

            if len(results) == 0:
                st.warning("ðŸ˜• Aucun rÃ©sultat trouvÃ©!")
            else:
                st.success(f"âœ… {len(results)} rÃ©sultats trouvÃ©s!")

                # Graphique des scores
                doc_indices = [r["index"] for r in results]
                scores = [r["score"] for r in results]
                labels = [
                    documents_titles[idx][:40] + "..."
                    if len(documents_titles[idx]) > 40
                    else documents_titles[idx]
                    for idx in doc_indices
                ]

                import matplotlib.pyplot as plt

                fig, ax = plt.subplots(figsize=(12, 6))
                y_pos = np.arange(len(labels))
                bars = ax.barh(y_pos, scores, color="#1f77b4", edgecolor="black")
                ax.set_yticks(y_pos)
                ax.set_yticklabels(labels, fontsize=10)
                ax.invert_yaxis()
                ax.set_xlabel("Score de SimilaritÃ© SÃ©mantique", fontweight="bold")
                ax.set_title(
                    f'Top {len(results)} RÃ©sultats pour: "{query}"',
                    fontsize=13,
                    fontweight="bold",
                )
                ax.grid(axis="x", alpha=0.3)

                for i, (bar, score) in enumerate(zip(bars, scores)):
                    width = bar.get_width()
                    ax.text(
                        width,
                        i,
                        f" {score:.3f}",
                        va="center",
                        fontsize=10,
                        fontweight="bold",
                    )

                plt.tight_layout()
                st.pyplot(fig)

                # DÃ©tails des rÃ©sultats avec analyses enrichies
                st.markdown("### ðŸŽ¯ RÃ©sultats DÃ©taillÃ©s")

                # Analyse de distribution des scores
                scores_list = [r["score"] for r in results]
                avg_score = np.mean(scores_list)
                max_score = scores_list[0]
                min_score = scores_list[-1]
                score_range = max_score - min_score

                st.markdown(f"""
                **ðŸ“Š Analyse rapide des scores:**
                - **Meilleur:** {max_score:.3f} {"ðŸ”¥" if max_score > 0.7 else "âœ…" if max_score > 0.5 else "âš ï¸"}
                - **Moyen:** {avg_score:.3f}
                - **Pire:** {min_score:.3f}
                - **Ã‰cart:** {score_range:.3f} {"(bonne sÃ©paration!)" if score_range > 0.2 else "(scores proches)"}
                """)

                for rank, result in enumerate(results, 1):
                    doc_idx = result["index"]
                    score = result["score"]

                    # Badge selon le score
                    if score > 0.7:
                        badge = "ðŸ”¥"
                        quality = "Excellent"
                    elif score > 0.5:
                        badge = "âœ…"
                        quality = "TrÃ¨s bon"
                    elif score > 0.3:
                        badge = "ðŸ‘Œ"
                        quality = "Bon"
                    else:
                        badge = "âš ï¸"
                        quality = "Faible"

                    with st.expander(
                        f"{badge} **#{rank}** - {documents_titles[doc_idx]} â€¢ SimilaritÃ©: **{score:.3f}** ({quality})"
                    ):
                        col1, col2 = st.columns([2, 1])

                        with col1:
                            st.caption(f"ðŸ“ CatÃ©gorie: {documents_categories[doc_idx]}")
                            st.write(documents_texts[doc_idx][:400] + "...")

                        with col2:
                            st.markdown("**ðŸ“Š Analyse:**")
                            st.metric("Score", f"{score:.3f}", f"{score * 100:.1f}%")

                            # Position relative
                            position_pct = (
                                (score - min_score) / score_range
                                if score_range > 0
                                else 0
                            )
                            st.metric("Position", f"Top {position_pct * 100:.0f}%")

                            # Comparaison avec la moyenne
                            diff_avg = score - avg_score
                            st.metric("vs Moyenne", f"{diff_avg:+.3f}")

                        st.markdown("---")

                        st.info(f"""
                        **ðŸ’¡ InterprÃ©tation du score {score:.3f}:**

                        **SimilaritÃ© sÃ©mantique:** {score * 100:.1f}%

                        **Ce que Ã§a signifie:**
                        - {"> 0.7: Documents **trÃ¨s similaires**! MÃªme sujet, vocabulaire proche ðŸ”¥" if score > 0.7 else ""}
                        - {"0.5-0.7: Documents **similaires**. Sujets connexes, concepts liÃ©s âœ…" if 0.5 < score <= 0.7 else ""}
                        - {"0.3-0.5: Documents **moyennement similaires**. Quelques concepts communs ðŸ‘Œ" if 0.3 < score <= 0.5 else ""}
                        - {"< 0.3: Documents **peu similaires**. Sujets diffÃ©rents âš ï¸" if score <= 0.3 else ""}

                        **Pourquoi ce rang?**
                        - Embeddings capture le **sens global** du texte
                        - Pas besoin de mots identiques (synonymes OK!)
                        - Relations sÃ©mantiques implicites dÃ©tectÃ©es ðŸŽ¯
                        """)

                # Conseils pÃ©dagogiques
                st.markdown("---")
                st.success("""
                **ðŸ’¡ ExpÃ©rimente avec diffÃ©rentes queries!**

                **Astuce 1:** Teste des **synonymes**
                - Query: "voiture rapide" vs "automobile vÃ©loce"
                - Embeddings devrait donner des rÃ©sultats similaires! âœ…

                **Astuce 2:** Teste des **concepts**
                - Query: "capitale France" â†’ Devrait trouver "Paris"!
                - TF-IDF ne peut PAS faire Ã§a (aucun mot commun)

                **Astuce 3:** Teste des **paraphrases**
                - "recette italienne pÃ¢tes" vs "plat italien spaghetti"
                - Sens identique, mots diffÃ©rents â†’ Embeddings comprend! ðŸ”¥
                """)


def render_embeddings_exploration(
    embedding_engine, documents_texts, documents_titles, documents_categories
):
    """Exploration et visualisations de l'espace vectoriel"""
    st.header("ðŸ“Š Exploration de l'Espace Vectoriel")

    st.markdown("### ðŸŒŒ Visualisation 3D Interactive (PCA)")

    # ParamÃ¨tres visualisation
    col1, col2 = st.columns([2, 1])

    with col1:
        viz_query = st.text_input(
            "Query Ã  visualiser (optionnel):",
            placeholder="cuisine italienne",
            key="viz_query",
            help="ðŸ’¡ Si fournie, la query sera affichÃ©e sur le graphique 3D",
        )

    with col2:
        n_docs_viz = st.slider(
            "Nombre de docs:", 10, 100, min(30, len(documents_texts)), key="n_docs_viz"
        )

    if st.button("ðŸŽ¨ GÃ©nÃ©rer la visualisation 3D!", key="viz_3d_btn"):
        with st.spinner("ðŸŽ¨ GÃ©nÃ©ration de la visualisation 3D..."):
            embeddings_subset = embedding_engine.get_embeddings()[:n_docs_viz]
            labels_subset = documents_titles[:n_docs_viz]
            categories_subset = (
                documents_categories[:n_docs_viz] if documents_categories else None
            )

            if viz_query:
                query_emb = embedding_engine.get_query_embedding(viz_query)
                results = embedding_engine.search(viz_query, top_k=5)
                top_indices = [r["index"] for r in results if r["index"] < n_docs_viz]
            else:
                query_emb = None
                top_indices = None

            fig_3d = plot_embedding_space_3d(
                embeddings_subset,
                labels_subset,
                categories=categories_subset,
                query_embedding=query_emb,
                query_label=viz_query if viz_query else "Query",
                top_k_indices=top_indices,
            )

            st.plotly_chart(fig_3d, use_container_width=True)

            st.info("""
            ðŸ’¡ **InterprÃ©tation:**
            - Chaque point = un document
            - Documents similaires sont **proches** dans l'espace
            - Les couleurs reprÃ©sentent les catÃ©gories
            - La query (si fournie) est en rouge ðŸ”´
            - Les lignes vertes montrent les top rÃ©sultats
            """)

    st.divider()

    # Clustering automatique
    st.markdown("### ðŸŽ¯ Clustering Automatique des Documents")

    n_clusters = st.slider("Nombre de clusters:", 2, 10, 3, key="n_clusters")

    if st.button("ðŸ§© Calculer les clusters!", key="cluster_btn"):
        with st.spinner("ðŸ§© Clustering en cours..."):
            embeddings_all = embedding_engine.get_embeddings()

            fig_cluster = plot_clustering_2d(
                embeddings_all, documents_titles, n_clusters=n_clusters
            )
            st.pyplot(fig_cluster)

            # Afficher quelques docs par cluster
            from sklearn.cluster import KMeans

            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(embeddings_all)

            st.markdown("### ðŸ“‘ Documents par Cluster")

            for cluster_id in range(n_clusters):
                with st.expander(
                    f"ðŸŽ¨ Cluster {cluster_id + 1} ({sum(clusters == cluster_id)} documents)"
                ):
                    cluster_docs = [
                        i for i, c in enumerate(clusters) if c == cluster_id
                    ]
                    for doc_id in cluster_docs[:5]:  # Top 5
                        st.write(f"- **{documents_titles[doc_id]}**")
                        st.caption(f"  {documents_texts[doc_id][:100]}...")

    st.divider()

    # Documents similaires
    st.markdown("### ðŸ”— Explorer les SimilaritÃ©s")

    selected_doc_idx = st.selectbox(
        "Choisir un document:",
        options=range(min(50, len(documents_titles))),
        format_func=lambda i: f"{documents_titles[i][:60]}...",
        key="sim_doc_select",
    )

    if st.button("ðŸ” Trouver documents similaires!", key="find_sim_btn"):
        with st.spinner("ðŸ” Recherche de documents similaires..."):
            similar_docs = embedding_engine.find_similar(selected_doc_idx, top_k=5)

            st.markdown("**ðŸ“„ Document source:**")
            st.info(
                f"**{documents_titles[selected_doc_idx]}**\n\n{documents_texts[selected_doc_idx][:200]}..."
            )

            st.markdown("**Documents similaires:**")

            for i, sim_doc in enumerate(similar_docs, 1):
                idx = sim_doc["index"]
                score = sim_doc["score"]

                with st.container():
                    col1, col2 = st.columns([1, 4])
                    with col1:
                        st.metric(f"#{i}", f"{score:.3f}")
                    with col2:
                        st.markdown(f"**{documents_titles[idx]}**")
                        st.caption(documents_texts[idx][:150] + "...")


def render_embeddings_stepbystep(embedding_engine, documents_texts, documents_titles):
    """Exemple pas-Ã -pas complet avec PÃ‰DAGOGIE MAXIMALE"""
    st.header("ðŸŽ“ Exemple Complet: De A Ã  Z")

    st.markdown("""
    Dans cette section, on va dÃ©rouler **TOUT** le processus des embeddings sur un exemple simple.

    Tu vas voir:
    1. Comment le texte devient un vecteur (encoding)
    2. Les calculs mathÃ©matiques exacts
    3. Comment on mesure la similaritÃ©
    4. Pourquoi Ã§a marche si bien! ðŸ”

    **Objectif:** Comprendre chaque Ã©tape du pipeline embeddings! ðŸŽ¯
    """)

    # Mini corpus
    corpus_example = documents_texts[:3]
    query_example = st.text_input(
        "ðŸ”Ž Ta query:",
        value="cuisine traditionnelle",
        key="tutorial_query",
        help="ðŸ’¡ Teste avec diffÃ©rentes queries pour voir comment les calculs changent",
    )

    st.markdown("### ðŸ“ Setup")
    st.code(f"""
Corpus ({len(corpus_example)} documents):
{chr(10).join(f'  Doc {i}: "{doc[:80]}..."' for i, doc in enumerate(corpus_example))}

Query: "{query_example}"
    """)

    if query_example:
        # Ã‰tape 1: Calcul embeddings
        st.markdown("### 1ï¸âƒ£ Calcul des Embeddings")

        with st.spinner("ðŸ§  Calcul des vecteurs..."):
            query_emb = embedding_engine.get_query_embedding(query_example)
            doc_embs = embedding_engine.get_embeddings()[:3]

        st.success(f"âœ… Embeddings calculÃ©s! Dimensions: {len(query_emb)}")

        # Afficher quelques valeurs
        for i, doc in enumerate(corpus_example):
            with st.expander(f"ðŸ“„ Doc {i}: {documents_titles[i]}"):
                vec = doc_embs[i]
                st.code(f"""
Vector ({len(vec)} dimensions):
[{vec[0]:.3f}, {vec[1]:.3f}, {vec[2]:.3f}, ..., {vec[-1]:.3f}]

Premiers 10 Ã©lÃ©ments:
{vec[:10]}
                """)

        with st.expander(f"ðŸ”Ž Query: {query_example}"):
            st.code(f"""
Vector ({len(query_emb)} dimensions):
[{query_emb[0]:.3f}, {query_emb[1]:.3f}, {query_emb[2]:.3f}, ..., {query_emb[-1]:.3f}]

Premiers 10 Ã©lÃ©ments:
{query_emb[:10]}
            """)

        # Ã‰tape 2: Calcul similaritÃ©s
        st.markdown("### 2ï¸âƒ£ Calcul de SimilaritÃ© Cosinus")

        st.latex(r"\text{sim}(q, d) = \frac{q \cdot d}{||q|| \times ||d||}")

        # Calcul dÃ©taillÃ© pour Doc 0
        st.markdown("**Exemple dÃ©taillÃ© pour Doc 0:**")

        with st.expander("ðŸ“ Calculs Ã©tape par Ã©tape"):
            dot_product = np.dot(query_emb, doc_embs[0])
            norm_q = np.linalg.norm(query_emb)
            norm_d = np.linalg.norm(doc_embs[0])
            similarity = dot_product / (norm_q * norm_d)

            st.code(f"""
1. Produit scalaire (dot product):
   q Â· d = {dot_product:.6f}

2. Norme de la query:
   ||q|| = âˆš({norm_q**2:.6f}) = {norm_q:.6f}

3. Norme du document:
   ||d|| = âˆš({norm_d**2:.6f}) = {norm_d:.6f}

4. SimilaritÃ© cosinus:
   sim = {dot_product:.6f} / ({norm_q:.6f} Ã— {norm_d:.6f})
       = {dot_product:.6f} / {norm_q * norm_d:.6f}
       = {similarity:.6f}
            """)

        # Ã‰tape 3: RÃ©sultats
        st.markdown("### 3ï¸âƒ£ RÃ©sultats Finaux")

        results = embedding_engine.search(query_example, top_k=3)

        results_data = []
        for rank, result in enumerate(results, 1):
            results_data.append(
                {
                    "Rang": rank,
                    "Document": documents_titles[result["index"]][:50],
                    "Score": f"{result['score']:.4f}",
                }
            )

        results_df = pd.DataFrame(results_data)
        st.dataframe(results_df, use_container_width=True)

        st.success(f"""
        âœ… **RÃ©sultat:**

        Le document "{results_data[0]["Document"]}" est le plus similaire!

        **Pourquoi?**
        - Embeddings capture le **sens** et non les mots exacts
        - Comprend les concepts, synonymes, et relations sÃ©mantiques! ðŸŽ¯
        """)


def render_embeddings_comparison(
    embedding_engine, tfidf_engine, bm25_engine, documents_texts, documents_titles
):
    """Comparaison Embeddings vs TF-IDF vs BM25"""
    st.header("âš”ï¸ Battle Royale: Embeddings vs BM25 vs TF-IDF")

    st.markdown("""
    Compare les 3 techniques sur une mÃªme requÃªte!

    ðŸ’¡ **Astuce:** Essaie des queries avec synonymes ou concepts pour voir la diffÃ©rence!
    """)

    # Utiliser un formulaire pour Ã©viter les problÃ¨mes de rerun
    with st.form("battle_form", clear_on_submit=False):
        battle_query = st.text_input(
            "ðŸ”Ž Query de comparaison:",
            value="nourriture italienne pÃ¢tes",
            key="battle_query_input",
            help='ðŸ’¡ **Exemples:** "nourriture italienne pÃ¢tes" | "science-fiction futur" | "sport football compÃ©tition"',
        )

        top_k_battle = st.slider(
            "Nombre de rÃ©sultats:", 5, 20, 10, key="battle_topk_slider"
        )

        # Bouton de soumission (Enter fonctionne aussi!)
        battle_submitted = st.form_submit_button(
            "âš”ï¸ LANCER LA BATAILLE!", type="primary"
        )

    if battle_submitted and battle_query:
        with st.spinner("âš”ï¸ Comparaison en cours..."):
            # Lancer les 3 techniques
            results_tfidf = tfidf_engine.search(battle_query, top_k=top_k_battle)
            results_bm25 = bm25_engine.search(battle_query, top_k=top_k_battle)
            results_embeddings_raw = embedding_engine.search(
                battle_query, top_k=top_k_battle
            )

            # Convertir embeddings au format (idx, score)
            results_embeddings = [
                (r["index"], r["score"]) for r in results_embeddings_raw
            ]

            # Visualisation comparative
            results_dict = {
                "TF-IDF": results_tfidf,
                "BM25": results_bm25,
                "Embeddings": results_embeddings,
            }

            fig_comp = plot_multi_technique_comparison(
                results_dict, documents_titles, battle_query, top_k=top_k_battle
            )
            st.pyplot(fig_comp)

            # MÃ©triques de comparaison
            st.divider()
            st.markdown("### ðŸ“ˆ MÃ©triques de Comparaison")

            set_tfidf = set([idx for idx, _ in results_tfidf])
            set_bm25 = set([idx for idx, _ in results_bm25])
            set_emb = set([idx for idx, _ in results_embeddings])

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                overlap_tb = len(set_tfidf & set_bm25)
                st.metric("TF-IDF âˆ© BM25", f"{overlap_tb}/{top_k_battle}")

            with col2:
                overlap_te = len(set_tfidf & set_emb)
                st.metric("TF-IDF âˆ© Embeddings", f"{overlap_te}/{top_k_battle}")

            with col3:
                overlap_be = len(set_bm25 & set_emb)
                st.metric("BM25 âˆ© Embeddings", f"{overlap_be}/{top_k_battle}")

            with col4:
                overlap_all = len(set_tfidf & set_bm25 & set_emb)
                st.metric("Commun aux 3", f"{overlap_all}/{top_k_battle}")

            st.info("""
            ðŸ’¡ **InterprÃ©tation:**

            - **Overlap faible** entre Embeddings et TF-IDF/BM25 â†’ Embeddings trouve des rÃ©sultats **diffÃ©rents** (sÃ©mantiques)
            - **Overlap Ã©levÃ©** â†’ Les 3 techniques s'accordent sur les meilleurs rÃ©sultats
            - **Documents uniques Ã  Embeddings** â†’ Probablement trouvÃ©s par **synonymes ou concepts**!
            """)


def render_embeddings_hybrid(
    embedding_engine,
    bm25_engine,
    documents_texts,
    documents_titles,
    documents_categories,
):
    """Hybrid Search: BM25 + Embeddings"""
    st.header("ðŸŽ¨ Hybrid Search: Le Meilleur des Deux Mondes")

    st.markdown("""
    ### ðŸ¤ Combiner Lexical (BM25) et SÃ©mantique (Embeddings)

    **Principe:**
    ```python
    score_final = Î± Ã— score_bm25 + (1-Î±) Ã— score_embeddings
    ```

    OÃ¹ **Î±** contrÃ´le le poids de chaque technique!
    """)

    # CrÃ©er hybrid engine
    hybrid_engine = create_hybrid_engine(
        documents_texts, bm25_engine, embedding_engine, alpha=0.5
    )

    # Widget de tuning
    alpha = st.slider(
        "Î± (poids BM25):",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="0 = Embeddings pur | 1 = BM25 pur | 0.5 = Ã©quilibrÃ©",
        key="hybrid_alpha",
    )

    col1, col2 = st.columns(2)
    with col1:
        st.metric("Poids BM25 (lexical)", f"{alpha:.0%}")
    with col2:
        st.metric("Poids Embeddings (sÃ©mantique)", f"{(1 - alpha):.0%}")

    # Utiliser un formulaire pour Ã©viter les problÃ¨mes de rerun
    with st.form("hybrid_form", clear_on_submit=False):
        hybrid_query = st.text_input(
            "ðŸ”Ž Recherche hybrid:",
            value="cuisine traditionnelle maison",  # Valeur par dÃ©faut!
            placeholder="smartphone derniÃ¨re gÃ©nÃ©ration",
            key="hybrid_query_input",
            help='ðŸ’¡ **Exemples:** "smartphone derniÃ¨re gÃ©nÃ©ration" | "cuisine traditionnelle maison" | "voiture Ã©lectrique performante"',
        )

        top_k_hybrid = st.slider("RÃ©sultats:", 5, 20, 10, key="hybrid_topk_slider")

        # Bouton de soumission (Enter fonctionne aussi!)
        hybrid_submitted = st.form_submit_button(
            "ðŸš€ Rechercher Hybrid!", type="primary"
        )

    if hybrid_submitted and hybrid_query:
        with st.spinner("ðŸŽ¨ Recherche hybrid en cours..."):
            results_hybrid = hybrid_engine.search(
                hybrid_query, top_k=top_k_hybrid, alpha=alpha
            )

            st.success(f"âœ… {len(results_hybrid)} rÃ©sultats trouvÃ©s!")

            # Affichage des rÃ©sultats
            st.markdown("### ðŸ† RÃ©sultats Hybrid")

            for i, result in enumerate(results_hybrid, 1):
                doc_idx = result["index"]

                with st.expander(
                    f"#{i} - {documents_titles[doc_idx]} (Score: {result['combined_score']:.3f})"
                ):
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("Score BM25", f"{result['bm25_score']:.3f}")
                    with col2:
                        st.metric("Score Embeddings", f"{result['emb_score']:.3f}")
                    with col3:
                        st.metric("Score CombinÃ©", f"{result['combined_score']:.3f}")

                    st.caption(f"ðŸ“ {documents_categories[doc_idx]}")
                    st.write(documents_texts[doc_idx][:250] + "...")

            # Visualisation de l'effet de alpha
            st.divider()
            st.markdown("### ðŸ“Š Impact du ParamÃ¨tre Î±")

            # Calculer scores pour diffÃ©rents alpha
            alpha_values = np.linspace(0, 1, 21)
            sample_doc_idx = results_hybrid[0]["index"]  # Premier rÃ©sultat
            doc_scores = []

            for a in alpha_values:
                score = hybrid_engine.compute_score(
                    hybrid_query, sample_doc_idx, alpha=a
                )
                doc_scores.append(score)

            fig_alpha = plot_hybrid_alpha_effect(
                alpha_values, doc_scores, alpha, documents_titles[sample_doc_idx][:50]
            )
            st.pyplot(fig_alpha)

            st.info("""
            ðŸ’¡ **Quand ajuster Î±?**

            - **Î± â‰ˆ 0.3-0.4:** Corpus avec beaucoup de synonymes, recherche conceptuelle
            - **Î± â‰ˆ 0.5-0.6:** Ã‰quilibrÃ© (recommandÃ© par dÃ©faut) â­
            - **Î± â‰ˆ 0.7-0.8:** Noms exacts importants, codes, IDs
            """)


def render_embeddings_performance(
    embedding_engine, documents_texts, tfidf_engine, bm25_engine
):
    """Performance et optimisations des embeddings - VERSION PÃ‰DAGOGIQUE"""
    st.header("âš¡ Analyse des Performances")

    st.info("""
    **ðŸ’¡ Disclaimer Important:**

    Les embeddings sont **plus lents** que TF-IDF/BM25, MAIS offrent des rÃ©sultats **beaucoup meilleurs**!

    **Trade-off:** Vitesse vs QualitÃ©
    - TF-IDF/BM25: Rapide mais limitÃ© (lexical matching)
    - Embeddings: Plus lent mais puissant (semantic matching) ðŸŽ¯
    """)

    st.markdown("---")
    st.markdown("### â±ï¸ Comparaison des Temps de Calcul")

    # Tableau comparatif enrichi
    perf_data = {
        "OpÃ©ration": [
            "Indexation (1000 docs)",
            "Recherche (1 query)",
            "Recherche (100 queries)",
            "MÃ©moire (1000 docs)",
            "ScalabilitÃ© (10k docs)",
        ],
        "TF-IDF": ["~0.1s âš¡", "~5ms âš¡", "~0.5s âš¡", "~2 MB", "LinÃ©aire"],
        "BM25": ["~0.1s âš¡", "~5ms âš¡", "~0.5s âš¡", "~2 MB", "LinÃ©aire"],
        "Embeddings (CPU)": ["~300s ðŸŒ", "~10ms", "~1s", "~15 MB", "GPU requis!"],
        "Embeddings (GPU)": ["~30s âš¡âš¡", "~10ms", "~1s", "~15 MB", "OK jusqu'Ã  100k"],
    }

    df_perf = pd.DataFrame(perf_data)
    st.dataframe(df_perf, use_container_width=True, hide_index=True)

    st.markdown("""
    ### ðŸ“Š Observations ClÃ©s

    **Indexation (Calcul des Embeddings):**
    - **TF-IDF/BM25:** InstantanÃ© (~0.1s pour 1000 docs) âš¡
    - **Embeddings (CPU):** TRÃˆS lent (~300s pour 1000 docs) ðŸŒ
    - **Embeddings (GPU):** Acceptable (~30s pour 1000 docs) âš¡âš¡

    **âš ï¸ Pourquoi si lent?**
    - Chaque document passe par un rÃ©seau de neurones (BERT)
    - 12 couches d'attention + millions de paramÃ¨tres
    - Calculs intensifs (multiplications matricielles)

    **Recherche (Query â†’ RÃ©sultats):**
    - Toutes les mÃ©thodes sont rapides (<10ms)
    - Embeddings: juste un calcul de distance (produit scalaire)
    - Une fois indexÃ©, la recherche est instantanÃ©e! âœ…

    **MÃ©moire:**
    - TF-IDF/BM25: Matrice sparse (beaucoup de zÃ©ros)
    - Embeddings: Matrice dense (pas de zÃ©ros, plus gros)
    - Trade-off: 5-10Ã— plus de RAM pour embeddings
    """)

    st.warning("""
    âš ï¸ **Verdict: Quand utiliser Embeddings?**

    **OUI si:**
    - Tu as un GPU ou patience (indexation lente acceptable)
    - Tu veux la MEILLEURE qualitÃ© de recherche
    - Ton corpus contient synonymes/paraphrases/concepts
    - Tu indexes une fois, recherches souvent

    **NON si:**
    - Tu n'as pas de GPU ET corpus Ã©norme (>10k docs)
    - Tu rÃ©indexes frÃ©quemment (donnÃ©es changeantes)
    - TF-IDF/BM25 suffit dÃ©jÃ  (mots-clÃ©s simples)
    - Contraintes temps rÃ©el strictes

    **Compromis Hybrid:** Utilise les deux! (voir onglet "Hybrid") ðŸŽ¯
    """)

    st.divider()

    # Benchmark rÃ©el
    st.markdown("### ðŸ Benchmark RÃ©el")

    if st.button("ðŸš€ Lancer un benchmark!", key="benchmark_btn"):
        with st.spinner("â±ï¸ Benchmarking en cours..."):
            n_test_queries = 5
            test_queries = ["cuisine", "technologie", "histoire", "sport", "culture"][
                :n_test_queries
            ]

            times_search = {"TF-IDF": [], "BM25": [], "Embeddings": []}

            for query in test_queries:
                # TF-IDF
                start = time.time()
                tfidf_engine.search(query, top_k=10)
                times_search["TF-IDF"].append(time.time() - start)

                # BM25
                start = time.time()
                bm25_engine.search(query, top_k=10)
                times_search["BM25"].append(time.time() - start)

                # Embeddings
                start = time.time()
                embedding_engine.search(query, top_k=10)
                times_search["Embeddings"].append(time.time() - start)

            # RÃ©sultats
            st.markdown("### ðŸ“Š RÃ©sultats")

            avg_times = {k: np.mean(v) * 1000 for k, v in times_search.items()}  # en ms

            import matplotlib.pyplot as plt

            fig, ax = plt.subplots(figsize=(10, 6))
            techniques = list(avg_times.keys())
            times = list(avg_times.values())
            colors = ["#d62728", "#2ca02c", "#1f77b4"]
            bars = ax.bar(
                techniques, times, color=colors, edgecolor="black", linewidth=1.5
            )

            ax.set_ylabel("Temps Moyen (millisecondes)", fontsize=12, fontweight="bold")
            ax.set_title(
                f"Temps de Recherche (moyenne sur {n_test_queries} queries)",
                fontsize=14,
                fontweight="bold",
            )
            ax.grid(axis="y", alpha=0.3)

            for bar, time_val in zip(bars, times):
                height = bar.get_height()
                ax.text(
                    bar.get_x() + bar.get_width() / 2.0,
                    height,
                    f"{time_val:.1f}ms",
                    ha="center",
                    va="bottom",
                    fontsize=11,
                    fontweight="bold",
                )

            plt.tight_layout()
            st.pyplot(fig)

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("TF-IDF", f"{avg_times['TF-IDF']:.2f}ms")
            with col2:
                st.metric("BM25", f"{avg_times['BM25']:.2f}ms")
            with col3:
                st.metric(
                    "Embeddings",
                    f"{avg_times['Embeddings']:.2f}ms",
                    delta=f"+{avg_times['Embeddings'] - avg_times['BM25']:.1f}ms",
                    delta_color="inverse",
                )

    st.divider()

    # Optimisations
    st.markdown("### ðŸš€ Optimisations Possibles")

    st.markdown("""
    #### 1. **Utiliser un GPU** âš¡
    ```python
    import torch
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = SentenceTransformer('model-name', device=device)
    ```
    **Speedup:** 10-50Ã— plus rapide!

    #### 2. **Batch Processing**
    ```python
    embeddings = model.encode(documents, batch_size=32)
    ```
    **Speedup:** 2-5Ã— plus rapide

    #### 3. **Utiliser FAISS (Vector Database)**
    ```python
    import faiss
    index = faiss.IndexFlatIP(embedding_dim)
    index.add(embeddings)
    scores, indices = index.search(query_embedding, k=10)
    ```
    **Speedup:** 10-100Ã— sur gros corpus (millions de docs)

    #### 4. **ModÃ¨les Plus Petits**

    | ModÃ¨le | Dimensions | Vitesse | QualitÃ© |
    |--------|-----------|---------|---------|
    | MiniLM | 384 | âš¡âš¡âš¡ | â­â­â­ |
    | MPNet | 768 | âš¡âš¡ | â­â­â­â­ |
    | Large | 1024 | âš¡ | â­â­â­â­â­ |

    **Recommandation:** MiniLM pour la plupart des cas! ðŸŽ¯

    #### 5. **Caching Intelligent**
    ```python
    import pickle

    # Save
    with open('embeddings_cache.pkl', 'wb') as f:
        pickle.dump(embeddings, f)

    # Load (instantanÃ©!)
    with open('embeddings_cache.pkl', 'rb') as f:
        embeddings = pickle.load(f)
    ```
    """)
