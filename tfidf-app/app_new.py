"""
Explorateur de Recherche Textuelle - Application Streamlit Ã‰ducative
Application pÃ©dagogique pour enseigner TF-IDF, BM25, et autres techniques de recherche
"""

import streamlit as st
import numpy as np
import pandas as pd
import sys
import time
from pathlib import Path

# Ajouter le dossier src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from tfidf_engine import TFIDFEngine, preprocess_text, cosine_similarity
from bm25_engine import BM25Engine
from datasets import load_dataset, get_all_datasets_info
from visualizations import (
    # TF-IDF visualizations
    plot_tf_comparison,
    plot_idf_curve,
    plot_idf_wordcloud,
    plot_tfidf_heatmap,
    plot_top_words_per_doc,
    plot_similarity_heatmap,
    plot_search_results,
    plot_documents_3d,
    plot_documents_2d,
    plot_tf_vs_tfidf_comparison,
    plot_vocabulary_stats,
    # BM25 visualizations
    plot_saturation_effect,
    plot_length_normalization,
    plot_parameter_space_heatmap,
    plot_tfidf_bm25_comparison,
    plot_score_distributions
)


# Configuration de la page
st.set_page_config(
    page_title="Explorateur de Recherche Textuelle ğŸ”",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)


# Style CSS personnalisÃ©
st.markdown("""
<style>
    .main-title {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .subtitle {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .section-title {
        font-size: 2rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# FONCTIONS DE CACHE
# ============================================================================

@st.cache_data
def load_cached_dataset(dataset_name: str, sample_size: int = None, extended: bool = False):
    """Charge un dataset avec cache"""
    return load_dataset(dataset_name, sample_size=sample_size, extended=extended)


@st.cache_resource
def create_tfidf_engine(documents_texts: list, remove_stopwords: bool = True):
    """CrÃ©e et entraÃ®ne le moteur TF-IDF avec cache"""
    engine = TFIDFEngine(documents_texts, remove_stopwords=remove_stopwords)
    engine.fit()
    return engine


@st.cache_resource
def create_bm25_engine(documents_texts: list, k1: float = 1.5, b: float = 0.75, remove_stopwords: bool = True):
    """CrÃ©e le moteur BM25 avec cache"""
    return BM25Engine(documents_texts, k1=k1, b=b, remove_stopwords=remove_stopwords)


# ============================================================================
# PAGE D'ACCUEIL
# ============================================================================

def render_home():
    """Page d'accueil avec prÃ©sentation gÃ©nÃ©rale"""
    st.markdown('<h1 class="main-title">ğŸ” Explorateur de Recherche Textuelle</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">Apprends les techniques de recherche textuelle de maniÃ¨re interactive!</p>', unsafe_allow_html=True)

    st.markdown("""
    ## ğŸ¯ Bienvenue!

    Cette application pÃ©dagogique t'enseigne les diffÃ©rentes techniques de **recherche textuelle**
    utilisÃ©es dans les moteurs de recherche modernes.

    ### ğŸ“š Sections Disponibles
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        #### ğŸ“Š 1. TF-IDF
        **Term Frequency - Inverse Document Frequency**

        - âœ… Technique classique de recherche
        - ğŸ“ BasÃ©e sur frÃ©quence des mots
        - ğŸ“ Facile Ã  comprendre
        - âš¡ Rapide Ã  calculer

        **Tu apprendras:**
        - Comment calculer TF et IDF
        - Pourquoi normaliser les frÃ©quences
        - SimilaritÃ© cosinus
        - Limites de l'approche
        """)

        st.markdown("""
        #### ğŸ§  3. Embeddings (Ã€ venir)
        **ReprÃ©sentations vectorielles sÃ©mantiques**

        - ğŸš§ En construction
        - Word2Vec, GloVe
        - Transformers et BERT
        - Recherche sÃ©mantique
        """)

    with col2:
        st.markdown("""
        #### ğŸ¯ 2. BM25
        **Best Matching 25 - AmÃ©lioration de TF-IDF**

        - âœ¨ Ã‰tat de l'art en recherche textuelle
        - ğŸ“ˆ Saturation intelligente du TF
        - ğŸ›ï¸ ParamÃ¨tres ajustables (k1, b)
        - âš”ï¸ Meilleur que TF-IDF en pratique

        **Tu apprendras:**
        - ProblÃ¨mes de TF-IDF
        - Fonctionnement de BM25
        - Tuning des paramÃ¨tres
        - Comparaison avec TF-IDF
        """)

        st.markdown("""
        #### ğŸ“Š 4. SynthÃ¨se (Ã€ venir)
        **Comparaison de toutes les techniques**

        - ğŸš§ En construction
        - Benchmarks comparatifs
        - Cas d'usage recommandÃ©s
        - Guide de sÃ©lection
        """)

    st.divider()

    st.markdown("""
    ### ğŸš€ Comment Utiliser Cette App

    1. **SÃ©lectionne une section** dans la barre latÃ©rale (â†)
    2. **Choisis un dataset** (recettes, films, ou wikipedia)
    3. **Explore les concepts** avec visualisations interactives
    4. **Teste la recherche** avec tes propres requÃªtes
    5. **Compare les techniques** pour comprendre les diffÃ©rences

    ### ğŸ’¡ Conseils

    - ğŸ“– Commence par **TF-IDF** pour comprendre les bases
    - ğŸ¯ Passe ensuite Ã  **BM25** pour voir les amÃ©liorations
    - ğŸ” Utilise la **recherche interactive** pour tester
    - ğŸ“Š Consulte les **graphiques** pour visualiser
    - âš¡ VÃ©rifie les **performances** pour comprendre la complexitÃ©
    """)

    st.success("ğŸ‘‰ **Commence ton exploration en sÃ©lectionnant une section dans la sidebar!**")


# ============================================================================
# SECTION TF-IDF (contenu existant restructurÃ©)
# ============================================================================

def render_tfidf_section(dataset, documents_texts, documents_titles, documents_categories, engine,
                         remove_stopwords, show_intermediate, load_time, fit_time):
    """Section TF-IDF complÃ¨te avec tous les onglets"""

    st.title("ğŸ“Š TF-IDF: Term Frequency - Inverse Document Frequency")

    # Sub-navigation
    tab = st.radio(
        "ğŸ“ Navigation TF-IDF:",
        ["ğŸ“– Introduction", "ğŸ”¢ Concepts", "ğŸ” Recherche", "ğŸ“Š Exploration", "ğŸ“ Pas-Ã -Pas", "âš¡ Performance"],
        horizontal=True,
        key="tfidf_tabs"
    )

    if tab == "ğŸ“– Introduction":
        render_tfidf_intro()
    elif tab == "ğŸ”¢ Concepts":
        render_tfidf_concepts(engine, documents_titles)
    elif tab == "ğŸ” Recherche":
        render_tfidf_search(engine, documents_texts, documents_titles, documents_categories, show_intermediate)
    elif tab == "ğŸ“Š Exploration":
        render_tfidf_exploration(engine, documents_titles, documents_categories)
    elif tab == "ğŸ“ Pas-Ã -Pas":
        render_tfidf_stepbystep(documents_texts, documents_titles, documents_categories, remove_stopwords)
    elif tab == "âš¡ Performance":
        render_tfidf_performance(engine, documents_texts, load_time, fit_time, remove_stopwords)


def render_tfidf_intro():
    """Introduction TF-IDF"""
    st.header("ğŸ“– Le ProblÃ¨me de la Recherche Textuelle")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
        ### ğŸ¤” Pourquoi la recherche simple ne suffit pas?

        **Approche naÃ¯ve:** Compter les occurrences d'un mot.

        #### âŒ ProblÃ¨mes:

        1. **Documents longs favorisÃ©s** injustement
        2. **Mots communs** polluent les rÃ©sultats
        3. **Pas de notion de raretÃ©**
        """)

    with col2:
        st.code("""
Doc A (20 mots):
  "chat" 2Ã— â†’ 10%

Doc B (200 mots):
  "chat" 3Ã— â†’ 1.5%

NaÃ¯f: B > A (3 > 2)
Correct: A > B (10% > 1.5%)
        """)

    st.divider()

    st.markdown("""
    ### âœ… La Solution: TF-IDF

    Combine deux mesures complÃ©mentaires:
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.info("""
        **ğŸ“ˆ TF (Term Frequency)**

        FrÃ©quence locale du mot dans le document

        âœ… Normalise par longueur
        """)

    with col2:
        st.success("""
        **ğŸ“‰ IDF (Inverse Document Frequency)**

        RaretÃ© globale du mot dans le corpus

        âœ… PÃ©nalise les mots communs
        """)


def render_tfidf_concepts(engine, documents_titles):
    """Concepts TF-IDF dÃ©taillÃ©s"""
    st.header("ğŸ”¢ Concepts TF-IDF en Profondeur")

    # Contenu existant des concepts TF-IDF...
    with st.expander("ğŸ“ˆ **Term Frequency (TF)**", expanded=True):
        st.markdown("""
        ### ğŸ’¡ Intuition

        **"Si un mot apparaÃ®t souvent, le doc parle de ce sujet"**

        Mais on normalise par la longueur!
        """)

        st.latex(r"\text{TF}(mot, doc) = \frac{\text{occurrences}}{\text{total mots}}")

        sample_indices = [0, 1, 2]
        sample_titles = [documents_titles[i] for i in sample_indices]

        fig_tf = plot_tf_comparison(engine.documents, sample_indices, sample_titles)
        st.pyplot(fig_tf)

    with st.expander("ğŸ“‰ **Inverse Document Frequency (IDF)**"):
        st.markdown("""
        ### ğŸ’¡ Intuition

        **"Un mot rare est plus informatif"**
        """)

        st.latex(r"\text{IDF}(mot) = \log\left(\frac{N}{n}\right) + 1")

        fig_idf = plot_idf_curve(engine.idf_vector, engine.vocabulary, engine.documents)
        st.pyplot(fig_idf)

        idf_dict = {engine.vocabulary[i]: engine.idf_vector[i]
                   for i in range(min(100, len(engine.vocabulary)))}
        fig_wc = plot_idf_wordcloud(idf_dict)
        st.pyplot(fig_wc)

    with st.expander("ğŸ¯ **TF-IDF CombinÃ©**"):
        st.latex(r"\text{TF-IDF} = \text{TF} \times \text{IDF}")

        fig_heatmap = plot_tfidf_heatmap(engine.tfidf_matrix, engine.vocabulary, documents_titles, top_words=15)
        st.pyplot(fig_heatmap)


def render_tfidf_search(engine, documents_texts, documents_titles, documents_categories, show_intermediate):
    """Recherche interactive TF-IDF"""
    st.header("ğŸ” Recherche Interactive TF-IDF")

    col1, col2 = st.columns([3, 1])

    with col1:
        query = st.text_input("ğŸ” Entre ta requÃªte:", placeholder="Ex: recette italienne...", key="tfidf_query")

    with col2:
        top_k = st.slider("RÃ©sultats:", 3, 20, 5, key="tfidf_topk")

    if query and st.button("ğŸš€ Rechercher!", type="primary", key="tfidf_search"):
        with st.spinner("ğŸ” Recherche en cours..."):
            results = engine.search(query, top_k=top_k)

            if len(results) == 0 or all(score == 0 for _, score in results):
                st.warning("ğŸ˜• Aucun rÃ©sultat. Essaie d'autres mots!")
            else:
                st.success(f"âœ… {len(results)} rÃ©sultats trouvÃ©s!")

                fig_results = plot_search_results(results, documents_titles, query)
                st.pyplot(fig_results)

                st.markdown("### ğŸ¯ RÃ©sultats DÃ©taillÃ©s")
                for rank, (doc_idx, score) in enumerate(results[:5], 1):
                    with st.expander(f"#{rank} - {documents_titles[doc_idx]} (Score: {score:.3f})"):
                        st.caption(f"CatÃ©gorie: {documents_categories[doc_idx]}")
                        st.write(documents_texts[doc_idx][:300] + "...")


def render_tfidf_exploration(engine, documents_titles, documents_categories):
    """Exploration du corpus TF-IDF"""
    st.header("ğŸ“Š Exploration du Corpus")

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ğŸ“š Documents", len(documents_titles))
    col2.metric("ğŸ”¤ Vocabulaire", len(engine.vocabulary))
    col3.metric("ğŸ“ Mots/Doc", f"{np.mean([len(doc) for doc in engine.documents]):.1f}")
    col4.metric("ğŸ·ï¸ CatÃ©gories", len(set(documents_categories)))

    fig_vocab = plot_vocabulary_stats(engine.documents)
    st.pyplot(fig_vocab)

    fig_3d = plot_documents_3d(engine.tfidf_matrix, documents_titles, documents_categories)
    st.plotly_chart(fig_3d, use_container_width=True)


def render_tfidf_stepbystep(documents_texts, documents_titles, documents_categories, remove_stopwords):
    """Exemple pas-Ã -pas TF-IDF"""
    st.header("ğŸ“ Exemple Complet Pas-Ã -Pas")

    sample_indices = list(range(min(3, len(documents_texts))))

    for idx in sample_indices:
        with st.expander(f"ğŸ“„ Document {idx+1}: {documents_titles[idx]}"):
            st.write(documents_texts[idx])

    query = st.text_input("ğŸ” Query pour l'exemple:", value="chat poisson", key="tfidf_tutorial")

    if query:
        sample_texts = [documents_texts[i] for i in sample_indices]
        mini_engine = TFIDFEngine(sample_texts, remove_stopwords=remove_stopwords)
        mini_engine.fit()

        st.markdown("### ğŸ”¢ Ã‰tape 1: Calcul des TF")
        # ... calculs dÃ©taillÃ©s ...


def render_tfidf_performance(engine, documents_texts, load_time, fit_time, remove_stopwords):
    """Performances TF-IDF"""
    st.header("âš¡ Analyse des Performances")

    n_docs = len(documents_texts)
    n_vocab = len(engine.vocabulary)

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("â±ï¸ Chargement", f"{load_time:.3f}s")
    col2.metric("ğŸ§® EntraÃ®nement", f"{fit_time:.3f}s")
    col3.metric("ğŸ“š Documents", n_docs)
    col4.metric("ğŸ”¤ Vocabulaire", n_vocab)

    st.markdown("### ğŸ§® ComplexitÃ©: `O(n Ã— v)`")


# ============================================================================
# SECTION BM25 (NOUVEAU!)
# ============================================================================

def render_bm25_section(dataset, documents_texts, documents_titles, documents_categories,
                        tfidf_engine, remove_stopwords):
    """Section BM25 complÃ¨te"""

    st.title("ğŸ¯ BM25: Best Matching 25 - TF-IDF AmÃ©liorÃ©")

    # Sub-navigation
    tab = st.radio(
        "ğŸ“ Navigation BM25:",
        ["ğŸ“– Introduction", "ğŸ”¢ Concepts", "ğŸ” Recherche", "ğŸ“Š Exploration", "ğŸ“ Pas-Ã -Pas", "âš”ï¸ Comparaison", "âš¡ Performance"],
        horizontal=True,
        key="bm25_tabs"
    )

    if tab == "ğŸ“– Introduction":
        render_bm25_intro()
    elif tab == "ğŸ”¢ Concepts":
        render_bm25_concepts(documents_texts, remove_stopwords)
    elif tab == "ğŸ” Recherche":
        render_bm25_search(documents_texts, documents_titles, documents_categories, remove_stopwords)
    elif tab == "ğŸ“Š Exploration":
        render_bm25_exploration(documents_texts, documents_titles, remove_stopwords)
    elif tab == "ğŸ“ Pas-Ã -Pas":
        render_bm25_stepbystep(documents_texts, documents_titles, remove_stopwords)
    elif tab == "âš”ï¸ Comparaison":
        render_bm25_comparison(documents_texts, documents_titles, tfidf_engine, remove_stopwords)
    elif tab == "âš¡ Performance":
        render_bm25_performance(documents_texts, remove_stopwords)


def render_bm25_intro():
    """Introduction BM25 & ProblÃ¨mes de TF-IDF"""
    st.header("ğŸ“– BM25: La Solution aux ProblÃ¨mes de TF-IDF")

    st.markdown("""
    ### ğŸ“Š Rappel TF-IDF

    TF-IDF combine frÃ©quence locale (TF) et raretÃ© globale (IDF).
    """)

    st.latex(r"\text{TF-IDF} = \text{TF} \times \text{IDF}")

    st.divider()

    st.markdown("### âŒ Les 3 ProblÃ¨mes de TF-IDF")

    st.error("""
    **ProblÃ¨me #1: Saturation**

    TF croÃ®t linÃ©airement avec les occurrences!

    - "chat" 10Ã— â†’ score 10
    - "chat" 100Ã— â†’ score 100

    â¡ï¸ Est-ce que 100Ã— est vraiment 10Ã— plus pertinent? NON!
    """)

    # Visualisation saturation
    fig_sat = plot_saturation_effect()
    st.pyplot(fig_sat)

    st.error("""
    **ProblÃ¨me #2: Normalisation NaÃ¯ve**

    TF-IDF normalise simplement par longueur totale.

    - Doc A (20 mots): "chat" 2Ã— â†’ TF = 0.10
    - Doc B (200 mots): "chat" 10Ã— â†’ TF = 0.05

    â¡ï¸ Doc B a plus d'occurrences mais score PLUS BAS!
    """)

    st.error("""
    **ProblÃ¨me #3: Pas de ContrÃ´le**

    TF-IDF est figÃ©, aucun paramÃ¨tre ajustable!

    â¡ï¸ Impossible d'adapter selon le type de corpus.
    """)

    st.divider()

    st.success("""
    ### âœ… BM25 RÃ©sout Ces ProblÃ¨mes

    **1. Saturation du TF** via paramÃ¨tre **k1**
    - TF plafonne aprÃ¨s un certain seuil
    - Plus rÃ©aliste!

    **2. Normalisation ParamÃ©trable** via paramÃ¨tre **b**
    - ContrÃ´le la pÃ©nalitÃ© des documents longs
    - Ajustable selon le corpus!

    **3. IDF AmÃ©liorÃ©** avec smoothing
    - Ã‰vite les valeurs extrÃªmes
    - Plus stable!
    """)


def render_bm25_concepts(documents_texts, remove_stopwords):
    """Concepts BM25 dÃ©taillÃ©s"""
    st.header("ğŸ”¢ Comprendre BM25 en Profondeur")

    with st.expander("ğŸ“‰ **IDF AmÃ©liorÃ© (avec smoothing)**", expanded=True):
        st.markdown("""
        ### Formule BM25 IDF
        """)

        st.latex(r"\text{IDF}(q) = \log\left(\frac{N - n(q) + 0.5}{n(q) + 0.5}\right)")

        st.markdown("""
        - **N** = nombre total de documents
        - **n(q)** = nombre de docs contenant le mot q
        - **+0.5** = smoothing pour Ã©viter divisions par zÃ©ro

        **DiffÃ©rence avec TF-IDF:** Le smoothing rend l'IDF plus stable!
        """)

    with st.expander("ğŸ›ï¸ **Saturation du TF (ParamÃ¨tre k1)**"):
        st.markdown("""
        ### ğŸ’¡ Intuition

        AprÃ¨s X occurrences, le mot n'apporte plus d'info nouvelle.
        On veut un **PLATEAU**, pas une ligne droite!
        """)

        st.latex(r"\text{TF}_{saturated} = \frac{f \times (k1 + 1)}{f + k1}")

        st.markdown("""
        - **f** = frÃ©quence du mot
        - **k1** = contrÃ´le la vitesse de saturation

        **Valeurs typiques:**
        - k1 = 0 â†’ binaire (prÃ©sent/absent)
        - k1 = 1.2 â†’ saturation agressive
        - k1 = 1.5 â†’ **standard** â­
        - k1 = 2.0 â†’ saturation lente
        - k1 = âˆ â†’ comme TF-IDF (linÃ©aire)
        """)

        fig_sat = plot_saturation_effect(k1_values=[0.5, 1.2, 1.5, 2.0])
        st.pyplot(fig_sat)

    with st.expander("âš–ï¸ **Normalisation de Longueur (ParamÃ¨tre b)**"):
        st.markdown("""
        ### ğŸ’¡ Intuition

        Les docs longs contiennent naturellement plus de mots.
        Faut-il les pÃ©naliser? **Ã‡a dÃ©pend du corpus!**
        """)

        st.latex(r"\text{norm} = 1 - b + b \times \frac{|D|}{\text{avgdl}}")

        st.markdown("""
        - **|D|** = longueur du document
        - **avgdl** = longueur moyenne du corpus
        - **b** = intensitÃ© de la pÃ©nalitÃ©

        **Valeurs typiques:**
        - b = 0 â†’ aucune normalisation
        - b = 0.5 â†’ normalisation lÃ©gÃ¨re
        - b = 0.75 â†’ **standard** â­
        - b = 1.0 â†’ normalisation complÃ¨te
        """)

        # CrÃ©er un mini corpus pour calculer avgdl
        bm25_demo = BM25Engine(documents_texts[:10], remove_stopwords=remove_stopwords)

        fig_norm = plot_length_normalization(
            avgdl=bm25_demo.avgdl,
            doc_lengths=[50, 100, 150, 200]
        )
        st.pyplot(fig_norm)

    with st.expander("ğŸ¯ **Formule ComplÃ¨te BM25**"):
        st.markdown("""
        ### La Grande Formule
        """)

        st.latex(r"""
        \text{BM25} = \sum_{i} \text{IDF}(q_i) \times \frac{f(q_i, D) \times (k1 + 1)}{f(q_i, D) + k1 \times (1 - b + b \times \frac{|D|}{\text{avgdl}})}
        """)

        st.markdown("""
        **En franÃ§ais:**

        Pour chaque mot de la query:
        1. Prendre son **IDF** (raretÃ©)
        2. Multiplier par son **TF saturÃ©** et normalisÃ©
        3. Additionner tous les scores
        """)


def render_bm25_search(documents_texts, documents_titles, documents_categories, remove_stopwords):
    """Recherche interactive BM25"""
    st.header("ğŸ” Recherche Interactive BM25")

    st.markdown("""
    Teste BM25 avec tes propres paramÃ¨tres!
    """)

    # ParamÃ¨tres BM25
    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        query = st.text_input("ğŸ” Votre recherche:", placeholder="Ex: recette italienne...", key="bm25_query")

    with col2:
        k1 = st.slider(
            "k1 (saturation)",
            min_value=0.0,
            max_value=3.0,
            value=1.5,
            step=0.1,
            help="ContrÃ´le la saturation du TF. Standard = 1.5",
            key="bm25_k1"
        )

    with col3:
        b = st.slider(
            "b (normalisation)",
            min_value=0.0,
            max_value=1.0,
            value=0.75,
            step=0.05,
            help="ContrÃ´le la pÃ©nalitÃ© de longueur. Standard = 0.75",
            key="bm25_b"
        )

    top_k = st.slider("Nombre de rÃ©sultats:", 3, 20, 5, key="bm25_topk")

    if query and st.button("ğŸš€ Rechercher avec BM25!", type="primary", key="bm25_search_btn"):
        with st.spinner("ğŸ” Recherche BM25 en cours..."):
            # CrÃ©er engine BM25 avec les paramÃ¨tres
            bm25_engine = BM25Engine(documents_texts, k1=k1, b=b, remove_stopwords=remove_stopwords)

            results = bm25_engine.search(query, top_k=top_k)

            if len(results) == 0 or all(score == 0 for _, score in results):
                st.warning("ğŸ˜• Aucun rÃ©sultat. Essaie d'autres mots!")
            else:
                st.success(f"âœ… {len(results)} rÃ©sultats BM25 trouvÃ©s!")

                fig_results = plot_search_results(results, documents_titles, query)
                st.pyplot(fig_results)

                st.markdown("### ğŸ¯ RÃ©sultats DÃ©taillÃ©s")
                for rank, (doc_idx, score) in enumerate(results[:5], 1):
                    with st.expander(f"#{rank} - {documents_titles[doc_idx]} (BM25: {score:.3f})"):
                        st.caption(f"CatÃ©gorie: {documents_categories[doc_idx]}")
                        st.write(documents_texts[doc_idx][:300] + "...")

                        if st.checkbox(f"ğŸ“Š Voir calcul dÃ©taillÃ© #{rank}", key=f"bm25_explain_{rank}"):
                            explanation = bm25_engine.explain(query, doc_idx)

                            st.json({
                                'avgdl': f"{explanation['avgdl']:.1f} mots",
                                'doc_length': f"{explanation['doc_length']} mots",
                                'norm_factor': f"{explanation['norm_factor']:.3f}",
                                'total_score': f"{explanation['total_score']:.4f}"
                            })


def render_bm25_exploration(documents_texts, documents_titles, remove_stopwords):
    """Exploration & Tuning BM25"""
    st.header("ğŸ“Š Exploration & Tuning des ParamÃ¨tres")

    st.markdown("""
    ### ğŸ›ï¸ Laboratoire de Tuning BM25

    Explore l'impact des paramÃ¨tres k1 et b sur les scores!
    """)

    # SÃ©lection document
    doc_idx = st.selectbox(
        "Choisis un document:",
        range(min(20, len(documents_titles))),
        format_func=lambda x: documents_titles[x]
    )

    test_query = st.text_input("Query de test:", value="recette cuisine", key="bm25_tuning_query")

    if test_query:
        with st.spinner("ğŸ§ª GÃ©nÃ©ration de la heatmap..."):
            bm25_engine = BM25Engine(documents_texts, remove_stopwords=remove_stopwords)

            fig_heatmap = plot_parameter_space_heatmap(
                bm25_engine,
                test_query,
                doc_idx,
                k1_range=(0.5, 3.0),
                b_range=(0.0, 1.0),
                resolution=15
            )

            st.plotly_chart(fig_heatmap, use_container_width=True)

            st.info("""
            ğŸ’¡ **InterprÃ©tation:**
            - Zones **rouges** = scores Ã©levÃ©s
            - â­ **Ã‰toile blanche** = paramÃ¨tres standard (k1=1.5, b=0.75)
            - Explore l'espace pour voir l'impact!
            """)


def render_bm25_stepbystep(documents_texts, documents_titles, remove_stopwords):
    """Exemple pas-Ã -pas BM25"""
    st.header("ğŸ“ Exemple Complet Pas-Ã -Pas BM25")

    st.markdown("""
    Suivons **tout le processus** de calcul BM25 Ã©tape par Ã©tape!
    """)

    sample_indices = list(range(min(3, len(documents_texts))))

    for idx in sample_indices:
        with st.expander(f"ğŸ“„ Document {idx+1}: {documents_titles[idx]}"):
            st.write(documents_texts[idx])

    query = st.text_input("ğŸ” Query:", value="chat poisson", key="bm25_tutorial")

    if query:
        st.markdown("### ParamÃ¨tres")
        col1, col2 = st.columns(2)
        with col1:
            k1_tutorial = st.number_input("k1:", value=1.5, key="bm25_tutorial_k1")
        with col2:
            b_tutorial = st.number_input("b:", value=0.75, key="bm25_tutorial_b")

        sample_texts = [documents_texts[i] for i in sample_indices]
        mini_bm25 = BM25Engine(sample_texts, k1=k1_tutorial, b=b_tutorial, remove_stopwords=remove_stopwords)

        st.markdown(f"""
        ### ğŸ“Š Statistiques du Mini-Corpus

        - **Nombre de documents:** {mini_bm25.N}
        - **Longueur moyenne (avgdl):** {mini_bm25.avgdl:.1f} mots
        - **Vocabulaire:** {len(mini_bm25.vocabulary)} mots uniques
        """)

        # Calculs dÃ©taillÃ©s...
        results = mini_bm25.search(query, top_k=3)

        st.markdown("### ğŸ¯ RÃ©sultats Finaux")
        for rank, (doc_idx, score) in enumerate(results, 1):
            st.write(f"**#{rank}** - {documents_titles[sample_indices[doc_idx]]} : **{score:.4f}**")


def render_bm25_comparison(documents_texts, documents_titles, tfidf_engine, remove_stopwords):
    """Comparaison TF-IDF vs BM25 (SECTION CRITIQUE!)"""
    st.header("âš”ï¸ Comparaison TF-IDF vs BM25")

    st.markdown("""
    ### ğŸ”¥ Le Face-Ã -Face!

    Compare les deux algorithmes sur une mÃªme requÃªte.
    """)

    query_compare = st.text_input(
        "ğŸ” RequÃªte de comparaison:",
        value="recette italienne pÃ¢tes",
        key="compare_query"
    )

    top_k_compare = st.slider("Nombre de rÃ©sultats:", 5, 20, 10, key="compare_topk")

    if query_compare and st.button("âš”ï¸ Comparer!", type="primary", key="compare_btn"):
        with st.spinner("âš”ï¸ Comparaison en cours..."):
            # TF-IDF
            tfidf_results = tfidf_engine.search(query_compare, top_k=top_k_compare)

            # BM25
            bm25_engine = BM25Engine(documents_texts, k1=1.5, b=0.75, remove_stopwords=remove_stopwords)
            bm25_results = bm25_engine.search(query_compare, top_k=top_k_compare)

            # Visualisation comparative
            fig_comp = plot_tfidf_bm25_comparison(
                tfidf_results,
                bm25_results,
                documents_titles,
                query_compare,
                top_k=top_k_compare
            )
            st.pyplot(fig_comp)

            # MÃ©triques de comparaison
            st.divider()

            col1, col2, col3 = st.columns(3)

            tfidf_indices = set([idx for idx, _ in tfidf_results])
            bm25_indices = set([idx for idx, _ in bm25_results])
            overlap = len(tfidf_indices.intersection(bm25_indices))

            col1.metric("ğŸ“Š Overlap", f"{overlap}/{top_k_compare}")
            col2.metric("ğŸ”´ TF-IDF Unique", len(tfidf_indices - bm25_indices))
            col3.metric("ğŸŸ¢ BM25 Unique", len(bm25_indices - tfidf_indices))

            # Distributions
            st.markdown("### ğŸ“ˆ Distribution des Scores")

            all_tfidf_scores = [score for _, score in tfidf_results]
            all_bm25_scores = [score for _, score in bm25_results]

            fig_dist = plot_score_distributions(all_tfidf_scores, all_bm25_scores)
            st.pyplot(fig_dist)

            st.success("""
            âœ… **Observation:** BM25 a gÃ©nÃ©ralement une meilleure sÃ©paration des scores
            grÃ¢ce Ã  la saturation intelligente!
            """)


def render_bm25_performance(documents_texts, remove_stopwords):
    """Performance BM25"""
    st.header("âš¡ Analyse des Performances BM25")

    st.markdown("""
    ### ğŸ§® ComplexitÃ© Algorithmique

    **Bonne nouvelle:** BM25 a la **mÃªme complexitÃ©** que TF-IDF!
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.info("""
        **TF-IDF:**
        - Preprocessing: O(n Ã— m)
        - Search: O(n Ã— v)
        - **Total: O(n Ã— m + n Ã— v)**
        """)

    with col2:
        st.success("""
        **BM25:**
        - Preprocessing: O(n Ã— m)
        - Search: O(n Ã— v)
        - **Total: O(n Ã— m + n Ã— v)**

        âœ… Identique!
        """)

    st.markdown("""
    ### ğŸ’¡ Pourquoi MÃªme ComplexitÃ©?

    La saturation et normalisation BM25 sont juste des **multiplications**!

    - Calcul de `norm_factor`: O(1)
    - Formule BM25 par terme: O(1)

    â¡ï¸ **BM25 n'est PAS plus lent que TF-IDF!**
    """)

    # Benchmark
    if st.checkbox("ğŸ§ª Faire un benchmark rÃ©el?"):
        with st.spinner("â±ï¸ Benchmarking..."):
            # TF-IDF
            start = time.time()
            tfidf_engine = TFIDFEngine(documents_texts[:100], remove_stopwords=remove_stopwords)
            tfidf_engine.fit()
            tfidf_time = time.time() - start

            # BM25
            start = time.time()
            bm25_engine = BM25Engine(documents_texts[:100], remove_stopwords=remove_stopwords)
            bm25_time = time.time() - start

            col1, col2, col3 = st.columns(3)
            col1.metric("â±ï¸ TF-IDF", f"{tfidf_time:.4f}s")
            col2.metric("â±ï¸ BM25", f"{bm25_time:.4f}s")
            col3.metric("ğŸ“Š DiffÃ©rence", f"{abs(bm25_time - tfidf_time):.4f}s")

            st.success("âœ… Les deux algos sont aussi rapides! BM25 apporte juste de meilleurs rÃ©sultats!")


# ============================================================================
# PLACEHOLDERS SECTIONS FUTURES
# ============================================================================

def render_embeddings_placeholder():
    """Placeholder Embeddings"""
    st.title("ğŸ§  Embeddings Vectoriels")

    st.info("""
    ### ğŸš§ Section en Construction

    Cette section couvrira:

    - **Word2Vec** : ReprÃ©sentations vectorielles de mots
    - **GloVe** : Global Vectors for Word Representation
    - **FastText** : Embeddings avec sous-mots
    - **BERT & Transformers** : ReprÃ©sentations contextuelles
    - **Recherche sÃ©mantique** : Au-delÃ  des mots-clÃ©s

    **Ã€ venir prochainement!** ğŸš€
    """)


def render_synthesis_placeholder():
    """Placeholder SynthÃ¨se"""
    st.title("ğŸ“Š SynthÃ¨se Comparative")

    st.info("""
    ### ğŸš§ Section en Construction

    Cette section proposera:

    - **Benchmarks comparatifs** de toutes les techniques
    - **Guide de sÃ©lection** : Quelle technique pour quel use case?
    - **Tableau rÃ©capitulatif** avec avantages/inconvÃ©nients
    - **Performances comparÃ©es** sur diffÃ©rents corpus
    - **Recommandations pratiques** pour la production

    **Ã€ venir prochainement!** ğŸš€
    """)


# ============================================================================
# MAIN APP
# ============================================================================

def main():
    # === SIDEBAR NAVIGATION ===
    with st.sidebar:
        st.title("ğŸ” Explorateur")
        st.caption("Recherche Textuelle")

        # Navigation principale
        section = st.radio(
            "ğŸ“š Navigation:",
            ["ğŸ  Accueil", "ğŸ“Š TF-IDF", "ğŸ¯ BM25", "ğŸ§  Embeddings", "ğŸ“Š SynthÃ¨se"],
            key="main_nav"
        )

        st.divider()

        # Configuration globale (si pas sur accueil)
        if section != "ğŸ  Accueil":
            st.markdown("### âš™ï¸ Configuration")

            # SÃ©lection dataset
            datasets_info = get_all_datasets_info()
            dataset_names = [info['name'] for info in datasets_info]
            dataset_labels = {
                'recettes': 'ğŸ Recettes',
                'films': 'ğŸ¬ Films',
                'wikipedia': 'ğŸ“š Wikipedia'
            }

            selected_dataset = st.selectbox(
                "Dataset:",
                dataset_names,
                format_func=lambda x: dataset_labels.get(x, x),
                key="dataset_select"
            )

            # Taille dataset
            use_extended = st.checkbox(
                "ğŸ“¦ Dataset Ã©tendu",
                value=False,
                help="Plus de documents pour tester performances",
                key="extended_check"
            )

            # Info dataset
            dataset_info = next(info for info in datasets_info if info['name'] == selected_dataset)
            extended_sizes = {'recettes': 80, 'films': 70, 'wikipedia': 220}
            estimated_docs = extended_sizes.get(selected_dataset, 30) if use_extended else dataset_info['nb_docs']

            st.info(f"ğŸ“Š ~{estimated_docs} documents{' (Ã©tendu)' if use_extended else ''}")

            # ParamÃ¨tres avancÃ©s
            with st.expander("ğŸ”§ AvancÃ©s"):
                remove_stopwords = st.checkbox("Supprimer stopwords", value=True, key="stopwords_check")
                show_intermediate = st.checkbox("Calculs intermÃ©diaires", value=False, key="intermediate_check")

        st.divider()
        st.caption("ğŸ’¡ Explore les sections pour apprendre!")

    # === ROUTING ===

    if section == "ğŸ  Accueil":
        render_home()

    elif section in ["ğŸ“Š TF-IDF", "ğŸ¯ BM25"]:
        # Charger le dataset
        with st.spinner("ğŸ”„ Chargement du dataset..."):
            start_load = time.time()
            dataset = load_cached_dataset(selected_dataset, extended=use_extended)
            load_time = time.time() - start_load

            documents_texts = [doc['text'] for doc in dataset]
            documents_titles = [doc['title'] for doc in dataset]
            documents_categories = [doc['category'] for doc in dataset]

        # CrÃ©er les engines
        if section == "ğŸ“Š TF-IDF" or section == "ğŸ¯ BM25":
            with st.spinner("ğŸ§® PrÃ©paration des moteurs de recherche..."):
                start_fit = time.time()
                tfidf_engine = create_tfidf_engine(documents_texts, remove_stopwords=remove_stopwords)
                fit_time = time.time() - start_fit

        # Render la section appropriÃ©e
        if section == "ğŸ“Š TF-IDF":
            render_tfidf_section(
                dataset, documents_texts, documents_titles, documents_categories,
                tfidf_engine, remove_stopwords, show_intermediate, load_time, fit_time
            )

        elif section == "ğŸ¯ BM25":
            render_bm25_section(
                dataset, documents_texts, documents_titles, documents_categories,
                tfidf_engine, remove_stopwords
            )

    elif section == "ğŸ§  Embeddings":
        render_embeddings_placeholder()

    elif section == "ğŸ“Š SynthÃ¨se":
        render_synthesis_placeholder()

    # === FOOTER ===
    st.divider()
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 1rem 0;">
        <p>CrÃ©Ã© avec â¤ï¸ pour l'apprentissage de la recherche textuelle</p>
        <p style="font-size: 0.9rem;">ğŸ“š TF-IDF â€¢ ğŸ¯ BM25 â€¢ ğŸ§  Embeddings (Ã  venir)</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()

