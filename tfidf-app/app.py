"""
Explorateur de Recherche Textuelle - Application Streamlit Ã‰ducative
Application pÃ©dagogique pour enseigner TF-IDF, BM25, et autres techniques de recherche
"""

import streamlit as st
import numpy as np
import pandas as pd
import sys
import time
from pathlib import Path

# Ajouter le dossier src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from tfidf_engine import TFIDFEngine
from bm25_engine import BM25Engine
from data_loader import load_dataset

# Imports optionnels pour Embeddings (nÃ©cessite sentence-transformers)
try:
    EMBEDDINGS_AVAILABLE = True

    # Import des sections Embeddings et SynthÃ¨se (si dÃ©pendances disponibles)
    from app_embeddings_sections import (
        render_embeddings_section,
    )
    from app_synthesis_sections import render_synthesis_section
except ImportError:
    EMBEDDINGS_AVAILABLE = False
    # Le warning sera affichÃ© dans la sidebar

# Import des sections TF-IDF et BM25 (toujours disponibles)
from app_tfidf_sections import (
    render_tfidf_section,
)
from app_bm25_sections import (
    render_bm25_section,
)


# Configuration de la page
st.set_page_config(
    page_title="Explorateur de Recherche Textuelle ğŸ”",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded",
)


# Style CSS personnalisÃ©
st.markdown(
    """
<style>
    .main-title {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .subtitle {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .section-title {
        font-size: 2rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
</style>
""",
    unsafe_allow_html=True,
)


# ============================================================================
# FONCTIONS DE CACHE
# ============================================================================


@st.cache_data(show_spinner="Chargement du dataset...")
def load_cached_dataset(
    dataset_name: str,
    sample_size: int = None,
    extended: bool = False,
    _version: int = 3,
):
    """Charge un dataset avec cache (version 3 - tailles corrigÃ©es)"""
    return load_dataset(dataset_name, sample_size=sample_size, extended=extended)


@st.cache_resource
def create_tfidf_engine(documents_texts: list, remove_stopwords: bool = True):
    """CrÃ©e et entraÃ®ne le moteur TF-IDF avec cache"""
    engine = TFIDFEngine(documents_texts, remove_stopwords=remove_stopwords)
    engine.fit()
    return engine


@st.cache_resource
def create_bm25_engine(
    documents_texts: list,
    k1: float = 1.5,
    b: float = 0.75,
    remove_stopwords: bool = True,
):
    """CrÃ©e le moteur BM25 avec cache"""
    return BM25Engine(documents_texts, k1=k1, b=b, remove_stopwords=remove_stopwords)


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================


def render_tab_navigation(
    tabs_list: list, session_key: str, default_tab: str = None
) -> str:
    """
    Rend une navigation par tabs avec des boutons stylÃ©s

    Args:
        tabs_list: Liste des noms de tabs
        session_key: ClÃ© pour le session_state
        default_tab: Tab par dÃ©faut (premier si None)

    Returns:
        Le tab actuellement sÃ©lectionnÃ©
    """
    # Initialiser le state si nÃ©cessaire
    if session_key not in st.session_state:
        st.session_state[session_key] = default_tab or tabs_list[0]

    # CrÃ©er des colonnes pour les boutons horizontaux
    cols = st.columns(len(tabs_list))

    for idx, (col, tab_name) in enumerate(zip(cols, tabs_list)):
        with col:
            if st.session_state[session_key] == tab_name:
                # Tab actif - afficher avec style
                st.markdown(
                    f"""
                <div style="
                    background: linear-gradient(135deg, #1f77b4 0%, #2ca02c 100%);
                    padding: 10px 5px;
                    border-radius: 6px;
                    color: white;
                    font-weight: bold;
                    text-align: center;
                    font-size: 0.9rem;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.15);
                    margin-bottom: 10px;
                ">
                    {tab_name}
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                # Bouton cliquable
                if st.button(
                    tab_name, key=f"{session_key}_{idx}", use_container_width=True
                ):
                    st.session_state[session_key] = tab_name
                    st.rerun()

    st.markdown("<br>", unsafe_allow_html=True)
    return st.session_state[session_key]


def get_example_queries(dataset_name: str) -> dict:
    """
    Retourne des exemples de queries et placeholders pour chaque dataset

    Args:
        dataset_name: Nom du dataset ('recettes', 'films', 'wikipedia')

    Returns:
        Dict avec 'placeholder' et 'queries' (liste d'exemples)
    """
    examples = {
        "recettes": {
            "placeholder": "Ex: plat italien, cuisine Ã©picÃ©e, dessert chocolat...",
            "queries": [
                "plat italien pÃ¢tes fromage",
                "cuisine asiatique Ã©picÃ©e crevettes",
                "dessert chocolat franÃ§ais",
                "poisson grillÃ© mÃ©diterranÃ©en",
            ],
        },
        "films": {
            "placeholder": "Ex: science-fiction espace, comÃ©die romantique...",
            "queries": [
                "science-fiction espace vaisseau",
                "comÃ©die romantique amour couple",
                "super-hÃ©ros action marvel",
                "film horreur suspense peur",
            ],
        },
        "wikipedia": {
            "placeholder": "Ex: guerre mondiale, intelligence artificielle...",
            "queries": [
                "guerre mondiale conflit armÃ©e",
                "intelligence artificielle machine learning",
                "football coupe monde champion",
                "physique quantique atome particule",
            ],
        },
    }
    return examples.get(dataset_name, examples["recettes"])


# ============================================================================
# PAGE D'ACCUEIL
# ============================================================================


def render_datasets_section(dataset_name: str, use_extended: bool):
    """Section d'exploration des datasets (DÃ‰BOGAGE!)"""
    st.markdown(
        '<h1 class="main-title">ğŸ“¦ Explorateur de Datasets</h1>', unsafe_allow_html=True
    )
    st.markdown(
        '<p class="subtitle">Explore et vÃ©rifie les donnÃ©es chargÃ©es!</p>',
        unsafe_allow_html=True,
    )

    # Charger le dataset
    with st.spinner("ğŸ”„ Chargement du dataset..."):
        dataset = load_cached_dataset(dataset_name, extended=use_extended)

    # === INFOS DATASET ===
    st.header("ğŸ“Š Informations du Dataset")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ“š Nombre de documents", len(dataset))
    with col2:
        categories = list(set(doc.get("category", "N/A") for doc in dataset))
        st.metric("ğŸ·ï¸ CatÃ©gories", len(categories))
    with col3:
        avg_length = np.mean([len(doc["text"].split()) for doc in dataset])
        st.metric("ğŸ“ Longueur moyenne", f"{avg_length:.0f} mots")
    with col4:
        total_words = sum([len(doc["text"].split()) for doc in dataset])
        st.metric("ğŸ’¬ Total de mots", f"{total_words:,}")

    # Source des donnÃ©es
    st.markdown("---")
    st.subheader("ğŸ” Source des DonnÃ©es")

    # RÃ©cupÃ©rer les infos du dataset
    from src.data_loader import get_dataset_info

    dataset_info = get_dataset_info(dataset_name)

    st.success(f"âœ… **ChargÃ© depuis:** {dataset_info['source']}")

    st.info(f"""
    **Dataset actuel:** `{dataset_name}`
    **Taille:** `{"Extended" if use_extended else "Normal"}`
    **Documents chargÃ©s:** `{len(dataset)}`
    **Fichier:** `{dataset_info["file"]}`
    """)

    st.markdown("---")

    # === LISTE DES DOCUMENTS (PAGINÃ‰E) ===
    st.header("ğŸ“‹ Liste des Documents")

    # Recherche/Filtrage
    col1, col2, col3 = st.columns([3, 1, 1])
    with col1:
        search_text = st.text_input(
            "ğŸ” Rechercher dans les titres:",
            placeholder="Ex: pizza, science-fiction, guerre...",
            help="Filtre les documents dont le titre contient ce texte",
        )
    with col2:
        selected_category = st.selectbox(
            "ğŸ·ï¸ CatÃ©gorie:", ["Toutes"] + sorted(categories)
        )
    with col3:
        page_size = st.selectbox(
            "ğŸ“„ Par page:",
            options=[10, 25, 50, 100],
            index=1,
            help="Nombre de documents par page",
        )

    # Filtrer les documents
    filtered_docs = dataset
    if search_text:
        filtered_docs = [
            doc for doc in filtered_docs if search_text.lower() in doc["title"].lower()
        ]
    if selected_category != "Toutes":
        filtered_docs = [
            doc
            for doc in filtered_docs
            if doc.get("category", "N/A") == selected_category
        ]

    # Initialiser la pagination
    if "dataset_page" not in st.session_state:
        st.session_state.dataset_page = 0

    total_docs = len(filtered_docs)
    total_pages = max(1, (total_docs + page_size - 1) // page_size)

    # S'assurer que la page est valide
    if st.session_state.dataset_page >= total_pages:
        st.session_state.dataset_page = max(0, total_pages - 1)

    # Calculer les indices de la page
    start_idx = st.session_state.dataset_page * page_size
    end_idx = min(start_idx + page_size, total_docs)
    current_page_docs = filtered_docs[start_idx:end_idx]

    # Afficher les infos de pagination
    st.caption(
        f"ğŸ“Š Affichage {start_idx + 1}-{end_idx} sur {total_docs} documents â€¢ Page {st.session_state.dataset_page + 1}/{total_pages}"
    )

    if total_docs == 0:
        st.warning("ğŸ˜• Aucun document trouvÃ© avec ces filtres!")
    else:
        # CrÃ©er le DataFrame pour affichage
        table_data = []
        for i, doc in enumerate(current_page_docs):
            table_data.append(
                {
                    "#": start_idx + i + 1,
                    "Titre": doc["title"][:80]
                    + ("..." if len(doc["title"]) > 80 else ""),
                    "CatÃ©gorie": doc.get("category", "N/A"),
                    "Mots": len(doc["text"].split()),
                    "_full_doc": doc,  # Stocker le doc complet (cachÃ©)
                }
            )

        df = pd.DataFrame(table_data)

        # Afficher le tableau interactif (sans la colonne _full_doc)
        df_display = df.drop(columns=["_full_doc"])

        st.info("ğŸ’¡ **Clique sur une ligne du tableau pour voir les dÃ©tails!**", icon="ğŸ’¡")

        # Tableau interactif avec sÃ©lection
        event = st.dataframe(
            df_display,
            use_container_width=True,
            hide_index=True,
            height=400,
            on_select="rerun",
            selection_mode="single-row",
            key=f"dataset_table_page_{st.session_state.dataset_page}"
        )

        # ContrÃ´les de pagination
        col_prev, col_info, col_next = st.columns([1, 2, 1])

        with col_prev:
            if st.button(
                "â¬…ï¸ PrÃ©cÃ©dent",
                disabled=(st.session_state.dataset_page == 0),
                use_container_width=True,
            ):
                st.session_state.dataset_page -= 1
                st.rerun()

        with col_info:
            st.markdown(
                f"<div style='text-align: center; padding-top: 8px;'>Page {st.session_state.dataset_page + 1} / {total_pages}</div>",
                unsafe_allow_html=True,
            )

        with col_next:
            if st.button(
                "Suivant â¡ï¸",
                disabled=(st.session_state.dataset_page >= total_pages - 1),
                use_container_width=True,
            ):
                st.session_state.dataset_page += 1
                st.rerun()

        st.markdown("---")

        # DÃ©tection de la sÃ©lection via le clic sur une ligne
        selected_doc_idx = None
        if event.selection and "rows" in event.selection and len(event.selection["rows"]) > 0:
            selected_doc_idx = event.selection["rows"][0]

        # Afficher les dÃ©tails si une ligne est sÃ©lectionnÃ©e
        if selected_doc_idx is not None:
            doc = current_page_docs[selected_doc_idx]

            st.markdown("---")
            st.subheader("ğŸ“„ DÃ©tails du Document")

            # Infos dans des colonnes
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ“ Titre", "")
                st.write(f"**{doc['title']}**")
            with col2:
                st.metric("ğŸ·ï¸ CatÃ©gorie", doc.get("category", "N/A"))
            with col3:
                word_count = len(doc["text"].split())
                st.metric("ğŸ“Š Longueur", f"{word_count} mots")

            # Contenu complet
            st.markdown("**ğŸ“– Contenu complet:**")
            st.text_area(
                "Texte du document",
                value=doc["text"],
                height=300,
                label_visibility="collapsed",
            )

            # Statistiques du texte
            with st.expander("ğŸ“Š Statistiques dÃ©taillÃ©es"):
                tokens = doc["text"].lower().split()
                unique_tokens = set(tokens)

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Mots totaux", len(tokens))
                with col2:
                    st.metric("Mots uniques", len(unique_tokens))
                with col3:
                    diversity = (
                        len(unique_tokens) / len(tokens) if len(tokens) > 0 else 0
                    )
                    st.metric("DiversitÃ© lexicale", f"{diversity:.2%}")

                # Mots les plus frÃ©quents
                from collections import Counter

                word_freq = Counter(tokens)
                most_common = word_freq.most_common(10)

                st.markdown("**ğŸ”¤ Top 10 mots les plus frÃ©quents:**")
                df = pd.DataFrame(most_common, columns=["Mot", "FrÃ©quence"])
                st.dataframe(df, use_container_width=True, hide_index=True)


def render_home():
    """Page d'accueil avec prÃ©sentation gÃ©nÃ©rale"""
    st.markdown(
        '<h1 class="main-title">ğŸ” Explorateur de Recherche Textuelle</h1>',
        unsafe_allow_html=True,
    )
    st.markdown(
        '<p class="subtitle">MaÃ®trise les techniques de recherche textuelle de A Ã  Z!</p>',
        unsafe_allow_html=True,
    )

    # === INTRO COURTE ===
    st.info("""
    **ğŸ¯ Mission:** Apprendre comment les moteurs de recherche trouvent les meilleurs rÃ©sultats parmi des milliers de documents.

    **Exemple:** Tu cherches _"dessert au chocolat"_ â†’ Comment l'algorithme classe-t-il 10,000 recettes? ğŸ°
    """)

    st.markdown("---")

    # === PARCOURS (SIMPLIFIÃ‰) ===
    st.markdown("## ğŸ“š Parcours d'Apprentissage")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        ### ğŸ“Š TF-IDF
        **Les Fondamentaux**

        ğŸŸ¢ DÃ©butant â€¢ 15 min

        La technique **classique** pour pondÃ©rer l'importance des mots.

        âœ… FrÃ©quences normalisÃ©es
        âœ… Mots rares = plus importants
        âœ… SimilaritÃ© cosinus
        """)

    with col2:
        st.markdown("""
        ### ğŸ¯ BM25
        **L'AmÃ©lioration**

        ğŸŸ¡ IntermÃ©diaire â€¢ 20 min

        Version **amÃ©liorÃ©e** utilisÃ©e par les moteurs pro.

        âœ… Saturation intelligente
        âœ… ParamÃ¨tres ajustables
        âœ… Meilleurs rÃ©sultats
        """)

    with col3:
        if EMBEDDINGS_AVAILABLE:
            st.markdown("""
            ### ğŸ§  Embeddings
            **IA & SÃ©mantique**

            ğŸ”´ AvancÃ© â€¢ 30 min

            Recherche **moderne** par rÃ©seaux de neurones.

            âœ… Comprend le sens
            âœ… Trouve des synonymes
            âœ… Hybrid search
            """)
        else:
            st.markdown("""
            ### ğŸ§  Embeddings ğŸ”’
            **IA & SÃ©mantique**

            ğŸ”´ AvancÃ©

            Installe les dÃ©pendances:
            ```bash
            pip install sentence-transformers
            ```
            """)

    st.success("ğŸ’¡ **RecommandÃ©:** Suis l'ordre TF-IDF â†’ BM25 â†’ Embeddings â†’ SynthÃ¨se")

    st.markdown("---")

    # === DATASETS (SIMPLIFIÃ‰ + Ã€ JOUR) ===
    st.markdown("## ğŸ“¦ Datasets Disponibles")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.markdown("""
        ### ğŸ Recettes
        **50 â†’ 200 docs**

        Cuisine franÃ§aise, italienne, asiatique, mexicaine
        """)

    with col2:
        st.markdown("""
        ### ğŸ¬ Films
        **50 â†’ 200 docs**

        Synopsis de films variÃ©s (action, comÃ©die, SF)
        """)

    with col3:
        st.markdown("""
        ### ğŸ“– Livres
        **100 â†’ 801 docs**

        RÃ©sumÃ©s de livres franÃ§ais (classiques & modernes)
        """)

    with col4:
        st.markdown("""
        ### ğŸ“š Wikipedia
        **100 â†’ 1K docs**

        Articles FR sur tech, histoire, science, sport
        """)

    st.markdown("---")

    # === GUIDE RAPIDE ===
    st.markdown("## ğŸš€ DÃ©marrage Rapide")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **ğŸ“ Navigation**
        - Sidebar (â†) â†’ Choix section & dataset
        - Onglets â†’ Intro, Concepts, Recherche, etc.
        - Benchmarks â†’ Compare les performances
        """)

    with col2:
        st.markdown("""
        **ğŸ“ Parcours Complet**
        1. ğŸ“Š TF-IDF (15 min)
        2. ğŸ¯ BM25 (20 min)
        3. ğŸ§  Embeddings (30 min)
        4. ğŸ“ˆ SynthÃ¨se (10 min)

        **Total:** ~75 min ğŸš€
        """)


# ============================================================================
# MAIN APP
# ============================================================================


def main():
    # === SIDEBAR NAVIGATION ===
    with st.sidebar:
        st.title("ğŸ” Explorateur")
        st.caption("Recherche Textuelle")

        st.markdown("### ğŸ“š Navigation")

        # Navigation avec boutons stylÃ©s
        if "current_section" not in st.session_state:
            st.session_state.current_section = "ğŸ  Accueil"

        # Sections disponibles (dÃ©sactiver Embeddings/SynthÃ¨se si pas installÃ©s)
        sections = ["ğŸ  Accueil", "ğŸ“¦ Datasets", "ğŸ“Š TF-IDF", "ğŸ¯ BM25"]
        if EMBEDDINGS_AVAILABLE:
            sections.extend(["ğŸ§  Embeddings", "ğŸ“Š SynthÃ¨se"])
        else:
            sections.extend(["ğŸ§  Embeddings ğŸ”’", "ğŸ“Š SynthÃ¨se ğŸ”’"])

        for section_name in sections:
            # Style diffÃ©rent pour la section active
            if st.session_state.current_section == section_name:
                # Bouton actif (style diffÃ©rent)
                st.markdown(
                    f"""
                <div style="background: linear-gradient(90deg, #1f77b4 0%, #2ca02c 100%); padding: 12px 20px; border-radius: 8px; margin-bottom: 8px; color: white; font-weight: bold; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    {section_name}
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                # Bouton cliquable
                if st.button(
                    section_name, key=f"nav_{section_name}", use_container_width=True
                ):
                    st.session_state.current_section = section_name
                    st.rerun()

        section = st.session_state.current_section

        st.divider()

        # Configuration globale (si pas sur accueil)
        if section != "ğŸ  Accueil":
            st.markdown("### âš™ï¸ Configuration")

            # SÃ©lection dataset
            dataset_names = [
                "recettes",
                "films",
                "wikipedia",
                "livres",
            ]  # Noms techniques
            dataset_labels = {
                "recettes": "ğŸ Recettes",
                "films": "ğŸ¬ Films",
                "wikipedia": "ğŸ“š Wikipedia",
                "livres": "ğŸ“– Livres",
            }

            selected_dataset = st.selectbox(
                "Dataset:",
                dataset_names,
                format_func=lambda x: dataset_labels.get(x, x),
                key="dataset_select",
            )

            # Taille dataset
            use_extended = st.checkbox(
                "ğŸ“¦ Dataset Ã©tendu",
                value=False,
                help="Plus de documents pour tester performances",
                key="extended_check",
            )

            # Afficher la VRAIE taille du dataset sÃ©lectionnÃ©!
            try:
                # Utiliser get_dataset_info pour avoir les infos
                from src.data_loader import get_dataset_info

                dataset_info = get_dataset_info(selected_dataset)

                if use_extended:
                    estimated_docs = (
                        f"{dataset_info['size_extended']:,}"
                        if isinstance(dataset_info["size_extended"], int)
                        else dataset_info["size_extended"]
                    )
                    size_label = "(Ã©tendu)"
                else:
                    estimated_docs = f"{dataset_info['size_normal']:,}"
                    size_label = ""

                st.info(f"ğŸ“Š **{estimated_docs} documents** {size_label}")

            except Exception:
                # Fallback en cas d'erreur
                estimated_docs = "~1,000" if use_extended else "~50"
                st.info(f"ğŸ“Š {estimated_docs} documents")

            # ParamÃ¨tres avancÃ©s
            with st.expander("ğŸ”§ AvancÃ©s"):
                remove_stopwords = st.checkbox(
                    "Supprimer stopwords", value=True, key="stopwords_check"
                )
                show_intermediate = st.checkbox(
                    "Calculs intermÃ©diaires", value=False, key="intermediate_check"
                )

                # Menu de sÃ©lection du modÃ¨le d'embeddings (si disponible)
                if EMBEDDINGS_AVAILABLE:
                    st.markdown("**ğŸ§  ModÃ¨le Embeddings**")

                    # DÃ©finir les modÃ¨les disponibles avec infos
                    embedding_models = {
                        "MiniLM-L6 (Petit, Rapide)": {
                            "name": "paraphrase-multilingual-MiniLM-L6-v2",
                            "size": "~80 MB",
                            "speed": "âš¡âš¡âš¡",
                            "quality": "â­â­",
                        },
                        "MiniLM-L12 (Standard, RecommandÃ©)": {
                            "name": "paraphrase-multilingual-MiniLM-L12-v2",
                            "size": "~120 MB",
                            "speed": "âš¡âš¡",
                            "quality": "â­â­â­",
                        },
                        "MPNet (Grand, Meilleur)": {
                            "name": "paraphrase-multilingual-mpnet-base-v2",
                            "size": "~420 MB",
                            "speed": "âš¡",
                            "quality": "â­â­â­â­",
                        },
                    }

                    selected_model_label = st.selectbox(
                        "Choisir un modÃ¨le:",
                        list(embedding_models.keys()),
                        index=1,  # Par dÃ©faut: MiniLM-L12 (recommandÃ©)
                        key="embedding_model_select",
                        help="Petit = rapide mais moins prÃ©cis | Grand = lent mais meilleur",
                    )

                    embedding_model_name = embedding_models[selected_model_label][
                        "name"
                    ]
                    model_info = embedding_models[selected_model_label]

                    # Afficher les infos du modÃ¨le sÃ©lectionnÃ©
                    st.caption(
                        f"ğŸ“¦ Taille: {model_info['size']} | Vitesse: {model_info['speed']} | QualitÃ©: {model_info['quality']}"
                    )
                    st.caption("ğŸ’¾ Le modÃ¨le est tÃ©lÃ©chargÃ© UNE FOIS et mis en cache!")
                else:
                    embedding_model_name = "paraphrase-multilingual-MiniLM-L12-v2"  # DÃ©faut si pas disponible

        st.divider()

        # Warning si embeddings pas disponibles
        if not EMBEDDINGS_AVAILABLE:
            st.warning("âš ï¸ Embeddings non installÃ©s. Sections verrouillÃ©es ğŸ”’", icon="âš ï¸")

        st.caption("ğŸ’¡ Explore les sections pour apprendre!")

    # === ROUTING ===

    if section == "ğŸ  Accueil":
        render_home()

    elif section == "ğŸ“¦ Datasets":
        # Section d'exploration des datasets
        render_datasets_section(selected_dataset, use_extended)

    elif section in ["ğŸ“Š TF-IDF", "ğŸ¯ BM25"]:
        # Charger le dataset
        with st.spinner("ğŸ”„ Chargement du dataset..."):
            start_load = time.time()
            dataset = load_cached_dataset(selected_dataset, extended=use_extended)
            load_time = time.time() - start_load

            documents_texts = [doc["text"] for doc in dataset]
            documents_titles = [doc["title"] for doc in dataset]
            documents_categories = [doc["category"] for doc in dataset]

        # CrÃ©er les engines
        if section == "ğŸ“Š TF-IDF" or section == "ğŸ¯ BM25":
            with st.spinner("ğŸ§® PrÃ©paration des moteurs de recherche..."):
                start_fit = time.time()
                tfidf_engine = create_tfidf_engine(
                    documents_texts, remove_stopwords=remove_stopwords
                )
                fit_time = time.time() - start_fit

        # Render la section appropriÃ©e
        if section == "ğŸ“Š TF-IDF":
            render_tfidf_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                remove_stopwords,
                show_intermediate,
                load_time,
                fit_time,
            )

        elif section == "ğŸ¯ BM25":
            render_bm25_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                remove_stopwords,
            )

    elif section == "ğŸ§  Embeddings" or section == "ğŸ§  Embeddings ğŸ”’":
        if EMBEDDINGS_AVAILABLE:
            # Charger dataset et engines comme pour BM25
            with st.spinner("ğŸ”„ Chargement du dataset..."):
                dataset = load_cached_dataset(selected_dataset, extended=use_extended)
                documents_texts = [doc["text"] for doc in dataset]
                documents_titles = [doc["title"] for doc in dataset]
                documents_categories = [doc.get("category", "Autre") for doc in dataset]

            # CrÃ©er TF-IDF et BM25 engines (pour comparaison)
            with st.spinner("âš™ï¸ Initialisation des moteurs de recherche..."):
                tfidf_engine = create_tfidf_engine(documents_texts, remove_stopwords)
                bm25_engine = create_bm25_engine(documents_texts, remove_stopwords)

            # Appeler la vraie section Embeddings avec le modÃ¨le sÃ©lectionnÃ©
            render_embeddings_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                bm25_engine,
                remove_stopwords,
                embedding_model_name=embedding_model_name,  # NOUVEAU: modÃ¨le sÃ©lectionnÃ©!
            )
        else:
            st.title("ğŸ§  Embeddings Vectoriels ğŸ”’")
            st.error("""
            ### âš ï¸ Module Non Disponible

            Les embeddings nÃ©cessitent **sentence-transformers** et **PyTorch**.

            **Pour installer:**
            ```bash
            pip install sentence-transformers torch transformers
            ```

            **Note:** L'installation peut prendre 5-10 minutes (plusieurs GB Ã  tÃ©lÃ©charger).

            **En attendant**, tu peux utiliser **TF-IDF** et **BM25** qui sont 100% fonctionnels! ğŸš€
            """)

    elif section == "ğŸ“Š SynthÃ¨se" or section == "ğŸ“Š SynthÃ¨se ğŸ”’":
        if EMBEDDINGS_AVAILABLE:
            # Charger dataset et tous les engines
            with st.spinner("ğŸ”„ Chargement du dataset..."):
                dataset = load_cached_dataset(selected_dataset, extended=use_extended)
                documents_texts = [doc["text"] for doc in dataset]
                documents_titles = [doc["title"] for doc in dataset]
                documents_categories = [doc.get("category", "Autre") for doc in dataset]

            # CrÃ©er TOUS les engines pour la synthÃ¨se
            with st.spinner("âš™ï¸ Initialisation de tous les moteurs..."):
                tfidf_engine = create_tfidf_engine(documents_texts, remove_stopwords)
                bm25_engine = create_bm25_engine(documents_texts, remove_stopwords)
                # L'embedding engine sera crÃ©Ã© dans render_synthesis_section si nÃ©cessaire

            # Appeler la vraie section SynthÃ¨se
            render_synthesis_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                bm25_engine,
                None,  # embedding_engine sera crÃ©Ã© Ã  la demande
            )
        else:
            st.title("ğŸ“Š SynthÃ¨se Comparative ğŸ”’")
            st.error("""
            ### âš ï¸ Module Non Disponible

            La synthÃ¨se nÃ©cessite que **tous les moteurs** soient disponibles (TF-IDF, BM25, Embeddings).

            **Pour dÃ©bloquer**, installe d'abord les embeddings:
            ```bash
            pip install sentence-transformers torch transformers
            ```

            **En attendant**, compare **TF-IDF vs BM25** dans la section BM25 â†’ Comparaison! âš”ï¸
            """)

    # === FOOTER ===
    st.divider()
    st.markdown(
        """
    <div style="text-align: center; color: #666; padding: 1rem 0;">
        <p>CrÃ©Ã© avec â¤ï¸ pour l'apprentissage de la recherche textuelle</p>
        <p style="font-size: 0.9rem;">ğŸ“š TF-IDF â€¢ ğŸ¯ BM25 â€¢ ğŸ§  Embeddings (Ã  venir)</p>
    </div>
    """,
        unsafe_allow_html=True,
    )


if __name__ == "__main__":
    main()
