"""
Explorateur de Recherche Textuelle - Application Streamlit Ã‰ducative
Application pÃ©dagogique pour enseigner TF-IDF, BM25, et autres techniques de recherche
"""

import streamlit as st
import numpy as np
import pandas as pd
import sys
import time
from pathlib import Path

# Ajouter le dossier src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from tfidf_engine import TFIDFEngine
from bm25_engine import BM25Engine
from data_loader import load_dataset, get_all_datasets_info

# Imports optionnels pour Embeddings (nÃ©cessite sentence-transformers)
try:
    EMBEDDINGS_AVAILABLE = True

    # Import des sections Embeddings et SynthÃ¨se (si dÃ©pendances disponibles)
    from app_embeddings_sections import (
        render_embeddings_section,
    )
    from app_synthesis_sections import render_synthesis_section
except ImportError:
    EMBEDDINGS_AVAILABLE = False
    # Le warning sera affichÃ© dans la sidebar

# Import des sections TF-IDF et BM25 (toujours disponibles)
from app_tfidf_sections import (
    render_tfidf_section,
)
from app_bm25_sections import (
    render_bm25_section,
)


# Configuration de la page
st.set_page_config(
    page_title="Explorateur de Recherche Textuelle ğŸ”",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded",
)


# Style CSS personnalisÃ©
st.markdown(
    """
<style>
    .main-title {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .subtitle {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .section-title {
        font-size: 2rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
</style>
""",
    unsafe_allow_html=True,
)


# ============================================================================
# FONCTIONS DE CACHE
# ============================================================================


@st.cache_data
def load_cached_dataset(
    dataset_name: str, sample_size: int = None, extended: bool = False
):
    """Charge un dataset avec cache"""
    return load_dataset(dataset_name, sample_size=sample_size, extended=extended)


@st.cache_resource
def create_tfidf_engine(documents_texts: list, remove_stopwords: bool = True):
    """CrÃ©e et entraÃ®ne le moteur TF-IDF avec cache"""
    engine = TFIDFEngine(documents_texts, remove_stopwords=remove_stopwords)
    engine.fit()
    return engine


@st.cache_resource
def create_bm25_engine(
    documents_texts: list,
    k1: float = 1.5,
    b: float = 0.75,
    remove_stopwords: bool = True,
):
    """CrÃ©e le moteur BM25 avec cache"""
    return BM25Engine(documents_texts, k1=k1, b=b, remove_stopwords=remove_stopwords)


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================


def render_tab_navigation(
    tabs_list: list, session_key: str, default_tab: str = None
) -> str:
    """
    Rend une navigation par tabs avec des boutons stylÃ©s

    Args:
        tabs_list: Liste des noms de tabs
        session_key: ClÃ© pour le session_state
        default_tab: Tab par dÃ©faut (premier si None)

    Returns:
        Le tab actuellement sÃ©lectionnÃ©
    """
    # Initialiser le state si nÃ©cessaire
    if session_key not in st.session_state:
        st.session_state[session_key] = default_tab or tabs_list[0]

    # CrÃ©er des colonnes pour les boutons horizontaux
    cols = st.columns(len(tabs_list))

    for idx, (col, tab_name) in enumerate(zip(cols, tabs_list)):
        with col:
            if st.session_state[session_key] == tab_name:
                # Tab actif - afficher avec style
                st.markdown(
                    f"""
                <div style="
                    background: linear-gradient(135deg, #1f77b4 0%, #2ca02c 100%);
                    padding: 10px 5px;
                    border-radius: 6px;
                    color: white;
                    font-weight: bold;
                    text-align: center;
                    font-size: 0.9rem;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.15);
                    margin-bottom: 10px;
                ">
                    {tab_name}
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                # Bouton cliquable
                if st.button(
                    tab_name, key=f"{session_key}_{idx}", use_container_width=True
                ):
                    st.session_state[session_key] = tab_name
                    st.rerun()

    st.markdown("<br>", unsafe_allow_html=True)
    return st.session_state[session_key]


def get_example_queries(dataset_name: str) -> dict:
    """
    Retourne des exemples de queries et placeholders pour chaque dataset

    Args:
        dataset_name: Nom du dataset ('recettes', 'films', 'wikipedia')

    Returns:
        Dict avec 'placeholder' et 'queries' (liste d'exemples)
    """
    examples = {
        "recettes": {
            "placeholder": "Ex: plat italien, cuisine Ã©picÃ©e, dessert chocolat...",
            "queries": [
                "plat italien pÃ¢tes fromage",
                "cuisine asiatique Ã©picÃ©e crevettes",
                "dessert chocolat franÃ§ais",
                "poisson grillÃ© mÃ©diterranÃ©en",
            ],
        },
        "films": {
            "placeholder": "Ex: science-fiction espace, comÃ©die romantique...",
            "queries": [
                "science-fiction espace vaisseau",
                "comÃ©die romantique amour couple",
                "super-hÃ©ros action marvel",
                "film horreur suspense peur",
            ],
        },
        "wikipedia": {
            "placeholder": "Ex: guerre mondiale, intelligence artificielle...",
            "queries": [
                "guerre mondiale conflit armÃ©e",
                "intelligence artificielle machine learning",
                "football coupe monde champion",
                "physique quantique atome particule",
            ],
        },
    }
    return examples.get(dataset_name, examples["recettes"])


# ============================================================================
# PAGE D'ACCUEIL
# ============================================================================


def render_datasets_section(dataset_name: str, use_extended: bool):
    """Section d'exploration des datasets (DÃ‰BOGAGE!)"""
    st.markdown(
        '<h1 class="main-title">ğŸ“¦ Explorateur de Datasets</h1>', unsafe_allow_html=True
    )
    st.markdown(
        '<p class="subtitle">Explore et vÃ©rifie les donnÃ©es chargÃ©es!</p>',
        unsafe_allow_html=True,
    )

    # Charger le dataset
    with st.spinner("ğŸ”„ Chargement du dataset..."):
        dataset = load_cached_dataset(dataset_name, extended=use_extended)

    # === INFOS DATASET ===
    st.header("ğŸ“Š Informations du Dataset")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ“š Nombre de documents", len(dataset))
    with col2:
        categories = list(set(doc.get("category", "N/A") for doc in dataset))
        st.metric("ğŸ·ï¸ CatÃ©gories", len(categories))
    with col3:
        avg_length = np.mean([len(doc["text"].split()) for doc in dataset])
        st.metric("ğŸ“ Longueur moyenne", f"{avg_length:.0f} mots")
    with col4:
        total_words = sum([len(doc["text"].split()) for doc in dataset])
        st.metric("ğŸ’¬ Total de mots", f"{total_words:,}")

    # Source des donnÃ©es
    st.markdown("---")
    st.subheader("ğŸ” Source des DonnÃ©es")

    # VÃ©rifier si on utilise HuggingFace ou hardcodÃ©
    from data_loader import HF_AVAILABLE

    if HF_AVAILABLE:
        st.success("âœ… **Hugging Face `datasets` est disponible!**")
    else:
        st.warning(
            "âš ï¸ **Hugging Face `datasets` NON disponible. Utilisation de donnÃ©es hardcodÃ©es.**"
        )

    st.info(f"""
    **Dataset actuel:** `{dataset_name}`
    **Taille:** `{"Extended (10k docs)" if use_extended else "Standard (1k docs)"}`
    **Documents chargÃ©s:** `{len(dataset)}`
    """)

    st.markdown("---")

    # === LISTE DES DOCUMENTS ===
    st.header("ğŸ“‹ Liste des Documents")

    # Recherche/Filtrage
    col1, col2 = st.columns([3, 1])
    with col1:
        search_text = st.text_input(
            "ğŸ” Rechercher dans les titres:",
            placeholder="Ex: pizza, science-fiction, guerre...",
            help="Filtre les documents dont le titre contient ce texte",
        )
    with col2:
        selected_category = st.selectbox(
            "ğŸ·ï¸ CatÃ©gorie:", ["Toutes"] + sorted(categories)
        )

    # Filtrer les documents
    filtered_docs = dataset
    if search_text:
        filtered_docs = [
            doc for doc in filtered_docs if search_text.lower() in doc["title"].lower()
        ]
    if selected_category != "Toutes":
        filtered_docs = [
            doc
            for doc in filtered_docs
            if doc.get("category", "N/A") == selected_category
        ]

    st.caption(f"ğŸ“Š {len(filtered_docs)} documents affichÃ©s (sur {len(dataset)} total)")

    # SÃ©lecteur de document
    if len(filtered_docs) == 0:
        st.warning("ğŸ˜• Aucun document trouvÃ© avec ces filtres!")
    else:
        # CrÃ©er une liste de choix
        doc_choices = [
            f"[{i + 1}] {doc['title'][:60]}{'...' if len(doc['title']) > 60 else ''}"
            for i, doc in enumerate(filtered_docs)
        ]

        selected_idx = st.selectbox(
            "ğŸ“„ SÃ©lectionne un document Ã  inspecter:",
            range(len(doc_choices)),
            format_func=lambda i: doc_choices[i],
        )

        # Afficher le document sÃ©lectionnÃ©
        if selected_idx is not None:
            doc = filtered_docs[selected_idx]

            st.markdown("---")
            st.subheader("ğŸ“„ DÃ©tails du Document")

            # Infos dans des colonnes
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ“ Titre", "")
                st.write(f"**{doc['title']}**")
            with col2:
                st.metric("ğŸ·ï¸ CatÃ©gorie", doc.get("category", "N/A"))
            with col3:
                word_count = len(doc["text"].split())
                st.metric("ğŸ“Š Longueur", f"{word_count} mots")

            # Contenu complet
            st.markdown("**ğŸ“– Contenu complet:**")
            st.text_area(
                "Texte du document",
                value=doc["text"],
                height=300,
                label_visibility="collapsed",
            )

            # Statistiques du texte
            with st.expander("ğŸ“Š Statistiques dÃ©taillÃ©es"):
                tokens = doc["text"].lower().split()
                unique_tokens = set(tokens)

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Mots totaux", len(tokens))
                with col2:
                    st.metric("Mots uniques", len(unique_tokens))
                with col3:
                    diversity = (
                        len(unique_tokens) / len(tokens) if len(tokens) > 0 else 0
                    )
                    st.metric("DiversitÃ© lexicale", f"{diversity:.2%}")

                # Mots les plus frÃ©quents
                from collections import Counter

                word_freq = Counter(tokens)
                most_common = word_freq.most_common(10)

                st.markdown("**ğŸ”¤ Top 10 mots les plus frÃ©quents:**")
                df = pd.DataFrame(most_common, columns=["Mot", "FrÃ©quence"])
                st.dataframe(df, use_container_width=True, hide_index=True)


def render_home():
    """Page d'accueil avec prÃ©sentation gÃ©nÃ©rale"""
    st.markdown(
        '<h1 class="main-title">ğŸ” Explorateur de Recherche Textuelle</h1>',
        unsafe_allow_html=True,
    )
    st.markdown(
        '<p class="subtitle">Une application interactive pour maÃ®triser les techniques de recherche!</p>',
        unsafe_allow_html=True,
    )

    # === INTRO VISUELLE ===
    st.markdown("""
    ## ğŸ¯ Qu'est-ce que la Recherche Textuelle?

    Imagine que tu as **10,000 recettes de cuisine** et tu cherches **"dessert au chocolat"**.
    Comment l'ordinateur trouve-t-il les **meilleurs rÃ©sultats** parmi tous ces documents?

    C'est exactement ce que tu vas apprendre dans cette app! ğŸš€
    """)

    # === EXEMPLE CONCRET ===
    st.info("""
    **ğŸ’¡ Exemple Concret:**

    Tu tapes: **"pÃ¢tes italiennes fromage"**

    L'algorithme doit:
    1. Comprendre quels **mots sont importants** (pas "le", "la", "de"...)
    2. Trouver les documents qui **contiennent ces mots**
    3. **Classer** les rÃ©sultats du plus au moins pertinent
    4. Te montrer les **meilleurs en premier**! ğŸ¯
    """)

    st.markdown("---")

    # === SECTIONS DISPONIBLES (CARDS) ===
    st.markdown("## ğŸ“š Parcours d'Apprentissage")

    # Section 1: TF-IDF
    with st.container():
        st.markdown("### ğŸ“Š Ã‰tape 1: TF-IDF - Les Fondamentaux")

        col1, col2 = st.columns([1, 2])

        with col1:
            st.markdown("""
            **Niveau:** ğŸŸ¢ DÃ©butant
            **DurÃ©e:** 15-20 min
            **Concepts:** 5
            """)

        with col2:
            st.markdown("""
            **Term Frequency - Inverse Document Frequency**

            La technique **classique** de recherche textuelle. Tu apprendras:
            - âœ… Pourquoi compter les mots ne suffit pas
            - ğŸ“ Comment normaliser les frÃ©quences (TF)
            - ğŸ” Pourquoi les mots rares sont plus importants (IDF)
            - ğŸ§® Comment calculer la similaritÃ© entre documents
            - âš ï¸ Les limites de cette approche
            """)

        st.success("ğŸ’¡ **RecommandÃ©:** Commence par TF-IDF pour comprendre les bases!")

    st.markdown("")

    # Section 2: BM25
    with st.container():
        st.markdown("### ğŸ¯ Ã‰tape 2: BM25 - L'AmÃ©lioration")

        col1, col2 = st.columns([1, 2])

        with col1:
            st.markdown("""
            **Niveau:** ğŸŸ¡ IntermÃ©diaire
            **DurÃ©e:** 20-25 min
            **Concepts:** 6
            """)

        with col2:
            st.markdown("""
            **Best Matching 25 - Ã‰tat de l'art**

            Une version **amÃ©liorÃ©e** de TF-IDF utilisÃ©e par les moteurs de recherche pro:
            - ğŸš€ RÃ©sout les problÃ¨mes de TF-IDF
            - ğŸ“ˆ Saturation intelligente (Ã©vite la sur-pondÃ©ration)
            - ğŸ›ï¸ ParamÃ¨tres ajustables (k1, b) pour tuning
            - âš”ï¸ Comparaison directe avec TF-IDF
            - âœ… Meilleurs rÃ©sultats en pratique
            """)

        st.info("ğŸ“ **PrÃ©requis:** Avoir compris TF-IDF avant!")

    st.markdown("")

    # Section 3: Embeddings
    if EMBEDDINGS_AVAILABLE:
        with st.container():
            st.markdown("### ğŸ§  Ã‰tape 3: Embeddings - La SÃ©mantique")

            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown("""
                **Niveau:** ğŸ”´ AvancÃ©
                **DurÃ©e:** 30-40 min
                **Concepts:** 7
                """)

            with col2:
                st.markdown("""
                **Recherche SÃ©mantique par RÃ©seaux de Neurones**

                La technique **moderne** basÃ©e sur l'IA:
                - ğŸ¤– Comprend le **sens** des mots, pas juste leur prÃ©sence
                - ğŸ”„ Trouve des **synonymes** automatiquement
                - ğŸ¯ Recherche par **concept** plutÃ´t que par mot exact
                - ğŸŒ Utilise des modÃ¨les prÃ©-entraÃ®nÃ©s (Sentence-BERT)
                - ğŸš€ Combinaison avec BM25 (Hybrid Search)
                """)

            st.success("ğŸ”¥ **Bonus:** Compare les 3 techniques cÃ´te Ã  cÃ´te!")

    else:
        st.warning("""
        ### ğŸ§  Embeddings ğŸ”’

        Section non disponible - dÃ©pendances manquantes.
        Installe `sentence-transformers` pour dÃ©bloquer cette section!

        ```bash
        pip install sentence-transformers torch
        ```
        """)

    st.markdown("---")

    # === GUIDE D'UTILISATION ===
    st.markdown("## ğŸš€ Guide d'Utilisation")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        ### 1ï¸âƒ£ Navigation

        Utilise la **sidebar** (â†) pour:
        - Choisir une section
        - SÃ©lectionner un dataset
        - Ajuster les paramÃ¨tres
        """)

    with col2:
        st.markdown("""
        ### 2ï¸âƒ£ Exploration

        Dans chaque section:
        - ğŸ“– **Intro:** Le concept expliquÃ©
        - ğŸ”¢ **Concepts:** Formules dÃ©taillÃ©es
        - ğŸ” **Recherche:** Teste en live
        """)

    with col3:
        st.markdown("""
        ### 3ï¸âƒ£ Apprentissage

        Profite de:
        - ğŸ“Š Graphiques interactifs
        - ğŸ“ Exemples pas-Ã -pas
        - âš”ï¸ Comparaisons entre techniques
        """)

    st.markdown("---")

    # === DATASETS ===
    st.markdown("## ğŸ“¦ Datasets Disponibles")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        ### ğŸ Recettes

        ~1,000 recettes de cuisine

        **CatÃ©gories:**
        - Italienne, FranÃ§aise
        - Asiatique, Mexicaine
        - Desserts, Plats

        **IdÃ©al pour:** Recherches simples
        """)

    with col2:
        st.markdown("""
        ### ğŸ¬ Films

        ~1,000 synopsis de films

        **CatÃ©gories:**
        - Science-fiction, Action
        - ComÃ©die, Drame
        - Fantasy, Horreur

        **IdÃ©al pour:** Concepts abstraits
        """)

    with col3:
        st.markdown("""
        ### ğŸ“š Wikipedia

        ~1,000 articles variÃ©s

        **CatÃ©gories:**
        - Technologie, Histoire
        - Science, Sport
        - Culture, GÃ©ographie

        **IdÃ©al pour:** Recherches complexes
        """)

    st.markdown("---")

    # === CALL TO ACTION ===
    st.markdown("""
    ## ğŸ“ PrÃªt Ã  Apprendre?

    **Parcours recommandÃ©:**

    1. ğŸ“Š **TF-IDF** â†’ Comprends les bases (15 min)
    2. ğŸ¯ **BM25** â†’ DÃ©couvre les amÃ©liorations (20 min)
    3. ğŸ§  **Embeddings** â†’ Explore l'IA moderne (30 min)
    4. ğŸ“ˆ **SynthÃ¨se** â†’ Compare tout (10 min)

    **Temps total:** ~75 minutes pour maÃ®triser la recherche textuelle! ğŸš€
    """)


# ============================================================================
# MAIN APP
# ============================================================================


def main():
    # === SIDEBAR NAVIGATION ===
    with st.sidebar:
        st.title("ğŸ” Explorateur")
        st.caption("Recherche Textuelle")

        st.markdown("### ğŸ“š Navigation")

        # Navigation avec boutons stylÃ©s
        if "current_section" not in st.session_state:
            st.session_state.current_section = "ğŸ  Accueil"

        # Sections disponibles (dÃ©sactiver Embeddings/SynthÃ¨se si pas installÃ©s)
        sections = ["ğŸ  Accueil", "ğŸ“¦ Datasets", "ğŸ“Š TF-IDF", "ğŸ¯ BM25"]
        if EMBEDDINGS_AVAILABLE:
            sections.extend(["ğŸ§  Embeddings", "ğŸ“Š SynthÃ¨se"])
        else:
            sections.extend(["ğŸ§  Embeddings ğŸ”’", "ğŸ“Š SynthÃ¨se ğŸ”’"])

        for section_name in sections:
            # Style diffÃ©rent pour la section active
            if st.session_state.current_section == section_name:
                # Bouton actif (style diffÃ©rent)
                st.markdown(
                    f"""
                <div style="background: linear-gradient(90deg, #1f77b4 0%, #2ca02c 100%); padding: 12px 20px; border-radius: 8px; margin-bottom: 8px; color: white; font-weight: bold; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    {section_name}
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                # Bouton cliquable
                if st.button(
                    section_name, key=f"nav_{section_name}", use_container_width=True
                ):
                    st.session_state.current_section = section_name
                    st.rerun()

        section = st.session_state.current_section

        st.divider()

        # Configuration globale (si pas sur accueil)
        if section != "ğŸ  Accueil":
            st.markdown("### âš™ï¸ Configuration")

            # SÃ©lection dataset
            datasets_info = get_all_datasets_info()
            dataset_names = [info["name"] for info in datasets_info]
            dataset_labels = {
                "recettes": "ğŸ Recettes",
                "films": "ğŸ¬ Films",
                "wikipedia": "ğŸ“š Wikipedia",
            }

            selected_dataset = st.selectbox(
                "Dataset:",
                dataset_names,
                format_func=lambda x: dataset_labels.get(x, x),
                key="dataset_select",
            )

            # Taille dataset
            use_extended = st.checkbox(
                "ğŸ“¦ Dataset Ã©tendu",
                value=False,
                help="Plus de documents pour tester performances",
                key="extended_check",
            )

            # Afficher la VRAIE taille du dataset sÃ©lectionnÃ©!
            try:
                # Compter rapidement le nombre de docs
                if selected_dataset in ["recettes", "films"]:
                    # Lire depuis synthetic/
                    file_mapping = {
                        "recettes": "data/synthetic/recipes_fr.json",
                        "films": "data/synthetic/films_fr.json",
                    }
                    import json
                    from pathlib import Path

                    if use_extended:
                        # Mode Ã©tendu = TOUS les docs du fichier
                        file_path = Path(file_mapping[selected_dataset])
                        if file_path.exists():
                            with open(file_path, "r", encoding="utf-8") as f:
                                data = json.load(f)
                                estimated_docs = f"{len(data):,}"
                                size_label = "(Ã©tendu)"
                        else:
                            estimated_docs = "~1,000"
                            size_label = "(Ã©tendu)"
                    else:
                        # Mode normal = 50 docs
                        estimated_docs = "50"
                        size_label = ""

                elif selected_dataset == "wikipedia":
                    if use_extended:
                        estimated_docs = "1,000"
                        size_label = "(Ã©tendu - HF)"
                    else:
                        estimated_docs = "50"
                        size_label = "(hardcodÃ©)"
                else:
                    estimated_docs = "?"
                    size_label = ""

                st.info(f"ğŸ“Š **{estimated_docs} documents** {size_label}")

            except Exception:
                # Fallback en cas d'erreur
                estimated_docs = "~1,000" if use_extended else "~50"
                st.info(f"ğŸ“Š {estimated_docs} documents")

            # ParamÃ¨tres avancÃ©s
            with st.expander("ğŸ”§ AvancÃ©s"):
                remove_stopwords = st.checkbox(
                    "Supprimer stopwords", value=True, key="stopwords_check"
                )
                show_intermediate = st.checkbox(
                    "Calculs intermÃ©diaires", value=False, key="intermediate_check"
                )

                # Menu de sÃ©lection du modÃ¨le d'embeddings (si disponible)
                if EMBEDDINGS_AVAILABLE:
                    st.markdown("**ğŸ§  ModÃ¨le Embeddings**")

                    # DÃ©finir les modÃ¨les disponibles avec infos
                    embedding_models = {
                        "MiniLM-L6 (Petit, Rapide)": {
                            "name": "paraphrase-multilingual-MiniLM-L6-v2",
                            "size": "~80 MB",
                            "speed": "âš¡âš¡âš¡",
                            "quality": "â­â­",
                        },
                        "MiniLM-L12 (Standard, RecommandÃ©)": {
                            "name": "paraphrase-multilingual-MiniLM-L12-v2",
                            "size": "~120 MB",
                            "speed": "âš¡âš¡",
                            "quality": "â­â­â­",
                        },
                        "MPNet (Grand, Meilleur)": {
                            "name": "paraphrase-multilingual-mpnet-base-v2",
                            "size": "~420 MB",
                            "speed": "âš¡",
                            "quality": "â­â­â­â­",
                        },
                    }

                    selected_model_label = st.selectbox(
                        "Choisir un modÃ¨le:",
                        list(embedding_models.keys()),
                        index=1,  # Par dÃ©faut: MiniLM-L12 (recommandÃ©)
                        key="embedding_model_select",
                        help="Petit = rapide mais moins prÃ©cis | Grand = lent mais meilleur",
                    )

                    embedding_model_name = embedding_models[selected_model_label][
                        "name"
                    ]
                    model_info = embedding_models[selected_model_label]

                    # Afficher les infos du modÃ¨le sÃ©lectionnÃ©
                    st.caption(
                        f"ğŸ“¦ Taille: {model_info['size']} | Vitesse: {model_info['speed']} | QualitÃ©: {model_info['quality']}"
                    )
                    st.caption("ğŸ’¾ Le modÃ¨le est tÃ©lÃ©chargÃ© UNE FOIS et mis en cache!")
                else:
                    embedding_model_name = "paraphrase-multilingual-MiniLM-L12-v2"  # DÃ©faut si pas disponible

        st.divider()

        # Warning si embeddings pas disponibles
        if not EMBEDDINGS_AVAILABLE:
            st.warning("âš ï¸ Embeddings non installÃ©s. Sections verrouillÃ©es ğŸ”’", icon="âš ï¸")

        st.caption("ğŸ’¡ Explore les sections pour apprendre!")

    # === ROUTING ===

    if section == "ğŸ  Accueil":
        render_home()

    elif section == "ğŸ“¦ Datasets":
        # Section d'exploration des datasets
        render_datasets_section(selected_dataset, use_extended)

    elif section in ["ğŸ“Š TF-IDF", "ğŸ¯ BM25"]:
        # Charger le dataset
        with st.spinner("ğŸ”„ Chargement du dataset..."):
            start_load = time.time()
            dataset = load_cached_dataset(selected_dataset, extended=use_extended)
            load_time = time.time() - start_load

            documents_texts = [doc["text"] for doc in dataset]
            documents_titles = [doc["title"] for doc in dataset]
            documents_categories = [doc["category"] for doc in dataset]

        # CrÃ©er les engines
        if section == "ğŸ“Š TF-IDF" or section == "ğŸ¯ BM25":
            with st.spinner("ğŸ§® PrÃ©paration des moteurs de recherche..."):
                start_fit = time.time()
                tfidf_engine = create_tfidf_engine(
                    documents_texts, remove_stopwords=remove_stopwords
                )
                fit_time = time.time() - start_fit

        # Render la section appropriÃ©e
        if section == "ğŸ“Š TF-IDF":
            render_tfidf_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                remove_stopwords,
                show_intermediate,
                load_time,
                fit_time,
            )

        elif section == "ğŸ¯ BM25":
            render_bm25_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                remove_stopwords,
            )

    elif section == "ğŸ§  Embeddings" or section == "ğŸ§  Embeddings ğŸ”’":
        if EMBEDDINGS_AVAILABLE:
            # Charger dataset et engines comme pour BM25
            with st.spinner("ğŸ”„ Chargement du dataset..."):
                dataset = load_cached_dataset(selected_dataset, extended=use_extended)
                documents_texts = [doc["text"] for doc in dataset]
                documents_titles = [doc["title"] for doc in dataset]
                documents_categories = [doc.get("category", "Autre") for doc in dataset]

            # CrÃ©er TF-IDF et BM25 engines (pour comparaison)
            with st.spinner("âš™ï¸ Initialisation des moteurs de recherche..."):
                tfidf_engine = create_tfidf_engine(documents_texts, remove_stopwords)
                bm25_engine = create_bm25_engine(documents_texts, remove_stopwords)

            # Appeler la vraie section Embeddings avec le modÃ¨le sÃ©lectionnÃ©
            render_embeddings_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                bm25_engine,
                remove_stopwords,
                embedding_model_name=embedding_model_name,  # NOUVEAU: modÃ¨le sÃ©lectionnÃ©!
            )
        else:
            st.title("ğŸ§  Embeddings Vectoriels ğŸ”’")
            st.error("""
            ### âš ï¸ Module Non Disponible

            Les embeddings nÃ©cessitent **sentence-transformers** et **PyTorch**.

            **Pour installer:**
            ```bash
            pip install sentence-transformers torch transformers
            ```

            **Note:** L'installation peut prendre 5-10 minutes (plusieurs GB Ã  tÃ©lÃ©charger).

            **En attendant**, tu peux utiliser **TF-IDF** et **BM25** qui sont 100% fonctionnels! ğŸš€
            """)

    elif section == "ğŸ“Š SynthÃ¨se" or section == "ğŸ“Š SynthÃ¨se ğŸ”’":
        if EMBEDDINGS_AVAILABLE:
            # Charger dataset et tous les engines
            with st.spinner("ğŸ”„ Chargement du dataset..."):
                dataset = load_cached_dataset(selected_dataset, extended=use_extended)
                documents_texts = [doc["text"] for doc in dataset]
                documents_titles = [doc["title"] for doc in dataset]
                documents_categories = [doc.get("category", "Autre") for doc in dataset]

            # CrÃ©er TOUS les engines pour la synthÃ¨se
            with st.spinner("âš™ï¸ Initialisation de tous les moteurs..."):
                tfidf_engine = create_tfidf_engine(documents_texts, remove_stopwords)
                bm25_engine = create_bm25_engine(documents_texts, remove_stopwords)
                # L'embedding engine sera crÃ©Ã© dans render_synthesis_section si nÃ©cessaire

            # Appeler la vraie section SynthÃ¨se
            render_synthesis_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                bm25_engine,
                None,  # embedding_engine sera crÃ©Ã© Ã  la demande
            )
        else:
            st.title("ğŸ“Š SynthÃ¨se Comparative ğŸ”’")
            st.error("""
            ### âš ï¸ Module Non Disponible

            La synthÃ¨se nÃ©cessite que **tous les moteurs** soient disponibles (TF-IDF, BM25, Embeddings).

            **Pour dÃ©bloquer**, installe d'abord les embeddings:
            ```bash
            pip install sentence-transformers torch transformers
            ```

            **En attendant**, compare **TF-IDF vs BM25** dans la section BM25 â†’ Comparaison! âš”ï¸
            """)

    # === FOOTER ===
    st.divider()
    st.markdown(
        """
    <div style="text-align: center; color: #666; padding: 1rem 0;">
        <p>CrÃ©Ã© avec â¤ï¸ pour l'apprentissage de la recherche textuelle</p>
        <p style="font-size: 0.9rem;">ğŸ“š TF-IDF â€¢ ğŸ¯ BM25 â€¢ ğŸ§  Embeddings (Ã  venir)</p>
    </div>
    """,
        unsafe_allow_html=True,
    )


if __name__ == "__main__":
    main()
