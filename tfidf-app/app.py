"""
Explorateur de Recherche Textuelle - Application Streamlit √âducative
Application p√©dagogique pour enseigner TF-IDF, BM25, et autres techniques de recherche
"""

import streamlit as st
import numpy as np
import pandas as pd
import sys
import time
from pathlib import Path

# Ajouter le dossier src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from tfidf_engine import TFIDFEngine, preprocess_text, cosine_similarity
from bm25_engine import BM25Engine
from data_loader import load_dataset, get_all_datasets_info

# Imports optionnels pour Embeddings (n√©cessite sentence-transformers)
try:
    from embedding_engine import EmbeddingSearch
    from hybrid_search import HybridSearch

    EMBEDDINGS_AVAILABLE = True

    # Import des sections Embeddings et Synth√®se (si d√©pendances disponibles)
    from app_embeddings_sections import (
        render_embeddings_section,
        create_embedding_engine,
        create_hybrid_engine,
    )
    from app_synthesis_sections import render_synthesis_section
except ImportError:
    EMBEDDINGS_AVAILABLE = False
    # Le warning sera affich√© dans la sidebar
from visualizations import (
    # TF-IDF visualizations
    plot_tf_comparison,
    plot_idf_curve,
    plot_idf_wordcloud,
    plot_tfidf_heatmap,
    plot_top_words_per_doc,
    plot_similarity_heatmap,
    plot_search_results,
    plot_documents_3d,
    plot_documents_2d,
    plot_tf_vs_tfidf_comparison,
    plot_vocabulary_stats,
    # BM25 visualizations
    plot_saturation_effect,
    plot_length_normalization,
    plot_parameter_space_heatmap,
    plot_tfidf_bm25_comparison,
    plot_score_distributions,
    # Embeddings visualizations
    plot_embedding_space_3d,
    plot_tsne_2d,
    plot_similarity_heatmap_embeddings,
    plot_clustering_2d,
    plot_technique_comparison_radar,
    plot_hybrid_alpha_effect,
    plot_multi_technique_comparison,
)


# Configuration de la page
st.set_page_config(
    page_title="Explorateur de Recherche Textuelle üîç",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded",
)


# Style CSS personnalis√©
st.markdown(
    """
<style>
    .main-title {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .subtitle {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .section-title {
        font-size: 2rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
</style>
""",
    unsafe_allow_html=True,
)


# ============================================================================
# FONCTIONS DE CACHE
# ============================================================================


@st.cache_data
def load_cached_dataset(
    dataset_name: str, sample_size: int = None, extended: bool = False
):
    """Charge un dataset avec cache"""
    return load_dataset(dataset_name, sample_size=sample_size, extended=extended)


@st.cache_resource
def create_tfidf_engine(documents_texts: list, remove_stopwords: bool = True):
    """Cr√©e et entra√Æne le moteur TF-IDF avec cache"""
    engine = TFIDFEngine(documents_texts, remove_stopwords=remove_stopwords)
    engine.fit()
    return engine


@st.cache_resource
def create_bm25_engine(
    documents_texts: list,
    k1: float = 1.5,
    b: float = 0.75,
    remove_stopwords: bool = True,
):
    """Cr√©e le moteur BM25 avec cache"""
    return BM25Engine(documents_texts, k1=k1, b=b, remove_stopwords=remove_stopwords)


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================


def render_tab_navigation(
    tabs_list: list, session_key: str, default_tab: str = None
) -> str:
    """
    Rend une navigation par tabs avec des boutons styl√©s

    Args:
        tabs_list: Liste des noms de tabs
        session_key: Cl√© pour le session_state
        default_tab: Tab par d√©faut (premier si None)

    Returns:
        Le tab actuellement s√©lectionn√©
    """
    # Initialiser le state si n√©cessaire
    if session_key not in st.session_state:
        st.session_state[session_key] = default_tab or tabs_list[0]

    # Cr√©er des colonnes pour les boutons horizontaux
    cols = st.columns(len(tabs_list))

    for idx, (col, tab_name) in enumerate(zip(cols, tabs_list)):
        with col:
            if st.session_state[session_key] == tab_name:
                # Tab actif - afficher avec style
                st.markdown(
                    f"""
                <div style="
                    background: linear-gradient(135deg, #1f77b4 0%, #2ca02c 100%);
                    padding: 10px 5px;
                    border-radius: 6px;
                    color: white;
                    font-weight: bold;
                    text-align: center;
                    font-size: 0.9rem;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.15);
                    margin-bottom: 10px;
                ">
                    {tab_name}
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                # Bouton cliquable
                if st.button(
                    tab_name, key=f"{session_key}_{idx}", use_container_width=True
                ):
                    st.session_state[session_key] = tab_name
                    st.rerun()

    st.markdown("<br>", unsafe_allow_html=True)
    return st.session_state[session_key]


def get_example_queries(dataset_name: str) -> dict:
    """
    Retourne des exemples de queries et placeholders pour chaque dataset

    Args:
        dataset_name: Nom du dataset ('recettes', 'films', 'wikipedia')

    Returns:
        Dict avec 'placeholder' et 'queries' (liste d'exemples)
    """
    examples = {
        "recettes": {
            "placeholder": "Ex: plat italien, cuisine √©pic√©e, dessert chocolat...",
            "queries": [
                "plat italien p√¢tes fromage",
                "cuisine asiatique √©pic√©e crevettes",
                "dessert chocolat fran√ßais",
                "poisson grill√© m√©diterran√©en",
            ],
        },
        "films": {
            "placeholder": "Ex: science-fiction espace, com√©die romantique...",
            "queries": [
                "science-fiction espace vaisseau",
                "com√©die romantique amour couple",
                "super-h√©ros action marvel",
                "film horreur suspense peur",
            ],
        },
        "wikipedia": {
            "placeholder": "Ex: guerre mondiale, intelligence artificielle...",
            "queries": [
                "guerre mondiale conflit arm√©e",
                "intelligence artificielle machine learning",
                "football coupe monde champion",
                "physique quantique atome particule",
            ],
        },
    }
    return examples.get(dataset_name, examples["recettes"])


# ============================================================================
# PAGE D'ACCUEIL
# ============================================================================


def render_datasets_section(dataset_name: str, use_extended: bool):
    """Section d'exploration des datasets (D√âBOGAGE!)"""
    st.markdown(
        '<h1 class="main-title">üì¶ Explorateur de Datasets</h1>', unsafe_allow_html=True
    )
    st.markdown(
        '<p class="subtitle">Explore et v√©rifie les donn√©es charg√©es!</p>',
        unsafe_allow_html=True,
    )

    # Charger le dataset
    with st.spinner("üîÑ Chargement du dataset..."):
        dataset = load_cached_dataset(dataset_name, extended=use_extended)

    # === INFOS DATASET ===
    st.header("üìä Informations du Dataset")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üìö Nombre de documents", len(dataset))
    with col2:
        categories = list(set(doc.get("category", "N/A") for doc in dataset))
        st.metric("üè∑Ô∏è Cat√©gories", len(categories))
    with col3:
        avg_length = np.mean([len(doc["text"].split()) for doc in dataset])
        st.metric("üìù Longueur moyenne", f"{avg_length:.0f} mots")
    with col4:
        total_words = sum([len(doc["text"].split()) for doc in dataset])
        st.metric("üí¨ Total de mots", f"{total_words:,}")

    # Source des donn√©es
    st.markdown("---")
    st.subheader("üîç Source des Donn√©es")

    # V√©rifier si on utilise HuggingFace ou hardcod√©
    from data_loader import HF_AVAILABLE

    if HF_AVAILABLE:
        st.success("‚úÖ **Hugging Face `datasets` est disponible!**")
    else:
        st.warning(
            "‚ö†Ô∏è **Hugging Face `datasets` NON disponible. Utilisation de donn√©es hardcod√©es.**"
        )

    st.info(f"""
    **Dataset actuel:** `{dataset_name}`
    **Taille:** `{"Extended (10k docs)" if use_extended else "Standard (1k docs)"}`
    **Documents charg√©s:** `{len(dataset)}`
    """)

    st.markdown("---")

    # === LISTE DES DOCUMENTS ===
    st.header("üìã Liste des Documents")

    # Recherche/Filtrage
    col1, col2 = st.columns([3, 1])
    with col1:
        search_text = st.text_input(
            "üîé Rechercher dans les titres:",
            placeholder="Ex: pizza, science-fiction, guerre...",
            help="Filtre les documents dont le titre contient ce texte",
        )
    with col2:
        selected_category = st.selectbox(
            "üè∑Ô∏è Cat√©gorie:", ["Toutes"] + sorted(categories)
        )

    # Filtrer les documents
    filtered_docs = dataset
    if search_text:
        filtered_docs = [
            doc for doc in filtered_docs if search_text.lower() in doc["title"].lower()
        ]
    if selected_category != "Toutes":
        filtered_docs = [
            doc
            for doc in filtered_docs
            if doc.get("category", "N/A") == selected_category
        ]

    st.caption(f"üìä {len(filtered_docs)} documents affich√©s (sur {len(dataset)} total)")

    # S√©lecteur de document
    if len(filtered_docs) == 0:
        st.warning("üòï Aucun document trouv√© avec ces filtres!")
    else:
        # Cr√©er une liste de choix
        doc_choices = [
            f"[{i + 1}] {doc['title'][:60]}{'...' if len(doc['title']) > 60 else ''}"
            for i, doc in enumerate(filtered_docs)
        ]

        selected_idx = st.selectbox(
            "üìÑ S√©lectionne un document √† inspecter:",
            range(len(doc_choices)),
            format_func=lambda i: doc_choices[i],
        )

        # Afficher le document s√©lectionn√©
        if selected_idx is not None:
            doc = filtered_docs[selected_idx]

            st.markdown("---")
            st.subheader("üìÑ D√©tails du Document")

            # Infos dans des colonnes
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìù Titre", "")
                st.write(f"**{doc['title']}**")
            with col2:
                st.metric("üè∑Ô∏è Cat√©gorie", doc.get("category", "N/A"))
            with col3:
                word_count = len(doc["text"].split())
                st.metric("üìä Longueur", f"{word_count} mots")

            # Contenu complet
            st.markdown("**üìñ Contenu complet:**")
            st.text_area(
                "Texte du document",
                value=doc["text"],
                height=300,
                label_visibility="collapsed",
            )

            # Statistiques du texte
            with st.expander("üìä Statistiques d√©taill√©es"):
                tokens = doc["text"].lower().split()
                unique_tokens = set(tokens)

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Mots totaux", len(tokens))
                with col2:
                    st.metric("Mots uniques", len(unique_tokens))
                with col3:
                    diversity = (
                        len(unique_tokens) / len(tokens) if len(tokens) > 0 else 0
                    )
                    st.metric("Diversit√© lexicale", f"{diversity:.2%}")

                # Mots les plus fr√©quents
                from collections import Counter

                word_freq = Counter(tokens)
                most_common = word_freq.most_common(10)

                st.markdown("**üî§ Top 10 mots les plus fr√©quents:**")
                df = pd.DataFrame(most_common, columns=["Mot", "Fr√©quence"])
                st.dataframe(df, use_container_width=True, hide_index=True)


def render_home():
    """Page d'accueil avec pr√©sentation g√©n√©rale"""
    st.markdown(
        '<h1 class="main-title">üîç Explorateur de Recherche Textuelle</h1>',
        unsafe_allow_html=True,
    )
    st.markdown(
        '<p class="subtitle">Une application interactive pour ma√Ætriser les techniques de recherche!</p>',
        unsafe_allow_html=True,
    )

    # === INTRO VISUELLE ===
    st.markdown("""
    ## üéØ Qu'est-ce que la Recherche Textuelle?

    Imagine que tu as **10,000 recettes de cuisine** et tu cherches **"dessert au chocolat"**.
    Comment l'ordinateur trouve-t-il les **meilleurs r√©sultats** parmi tous ces documents?

    C'est exactement ce que tu vas apprendre dans cette app! üöÄ
    """)

    # === EXEMPLE CONCRET ===
    st.info("""
    **üí° Exemple Concret:**

    Tu tapes: **"p√¢tes italiennes fromage"**

    L'algorithme doit:
    1. Comprendre quels **mots sont importants** (pas "le", "la", "de"...)
    2. Trouver les documents qui **contiennent ces mots**
    3. **Classer** les r√©sultats du plus au moins pertinent
    4. Te montrer les **meilleurs en premier**! üéØ
    """)

    st.markdown("---")

    # === SECTIONS DISPONIBLES (CARDS) ===
    st.markdown("## üìö Parcours d'Apprentissage")

    # Section 1: TF-IDF
    with st.container():
        st.markdown("### üìä √âtape 1: TF-IDF - Les Fondamentaux")

        col1, col2 = st.columns([1, 2])

        with col1:
            st.markdown("""
            **Niveau:** üü¢ D√©butant
            **Dur√©e:** 15-20 min
            **Concepts:** 5
            """)

        with col2:
            st.markdown("""
            **Term Frequency - Inverse Document Frequency**

            La technique **classique** de recherche textuelle. Tu apprendras:
            - ‚úÖ Pourquoi compter les mots ne suffit pas
            - üìê Comment normaliser les fr√©quences (TF)
            - üîç Pourquoi les mots rares sont plus importants (IDF)
            - üßÆ Comment calculer la similarit√© entre documents
            - ‚ö†Ô∏è Les limites de cette approche
            """)

        st.success("üí° **Recommand√©:** Commence par TF-IDF pour comprendre les bases!")

    st.markdown("")

    # Section 2: BM25
    with st.container():
        st.markdown("### üéØ √âtape 2: BM25 - L'Am√©lioration")

        col1, col2 = st.columns([1, 2])

        with col1:
            st.markdown("""
            **Niveau:** üü° Interm√©diaire
            **Dur√©e:** 20-25 min
            **Concepts:** 6
            """)

        with col2:
            st.markdown("""
            **Best Matching 25 - √âtat de l'art**

            Une version **am√©lior√©e** de TF-IDF utilis√©e par les moteurs de recherche pro:
            - üöÄ R√©sout les probl√®mes de TF-IDF
            - üìà Saturation intelligente (√©vite la sur-pond√©ration)
            - üéõÔ∏è Param√®tres ajustables (k1, b) pour tuning
            - ‚öîÔ∏è Comparaison directe avec TF-IDF
            - ‚úÖ Meilleurs r√©sultats en pratique
            """)

        st.info("üéì **Pr√©requis:** Avoir compris TF-IDF avant!")

    st.markdown("")

    # Section 3: Embeddings
    if EMBEDDINGS_AVAILABLE:
        with st.container():
            st.markdown("### üß† √âtape 3: Embeddings - La S√©mantique")

            col1, col2 = st.columns([1, 2])

            with col1:
                st.markdown("""
                **Niveau:** üî¥ Avanc√©
                **Dur√©e:** 30-40 min
                **Concepts:** 7
                """)

            with col2:
                st.markdown("""
                **Recherche S√©mantique par R√©seaux de Neurones**

                La technique **moderne** bas√©e sur l'IA:
                - ü§ñ Comprend le **sens** des mots, pas juste leur pr√©sence
                - üîÑ Trouve des **synonymes** automatiquement
                - üéØ Recherche par **concept** plut√¥t que par mot exact
                - üåê Utilise des mod√®les pr√©-entra√Æn√©s (Sentence-BERT)
                - üöÄ Combinaison avec BM25 (Hybrid Search)
                """)

            st.success("üî• **Bonus:** Compare les 3 techniques c√¥te √† c√¥te!")

    else:
        st.warning("""
        ### üß† Embeddings üîí

        Section non disponible - d√©pendances manquantes.
        Installe `sentence-transformers` pour d√©bloquer cette section!

        ```bash
        pip install sentence-transformers torch
        ```
        """)

    st.markdown("---")

    # === GUIDE D'UTILISATION ===
    st.markdown("## üöÄ Guide d'Utilisation")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        ### 1Ô∏è‚É£ Navigation

        Utilise la **sidebar** (‚Üê) pour:
        - Choisir une section
        - S√©lectionner un dataset
        - Ajuster les param√®tres
        """)

    with col2:
        st.markdown("""
        ### 2Ô∏è‚É£ Exploration

        Dans chaque section:
        - üìñ **Intro:** Le concept expliqu√©
        - üî¢ **Concepts:** Formules d√©taill√©es
        - üîç **Recherche:** Teste en live
        """)

    with col3:
        st.markdown("""
        ### 3Ô∏è‚É£ Apprentissage

        Profite de:
        - üìä Graphiques interactifs
        - üéì Exemples pas-√†-pas
        - ‚öîÔ∏è Comparaisons entre techniques
        """)

    st.markdown("---")

    # === DATASETS ===
    st.markdown("## üì¶ Datasets Disponibles")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        ### üçù Recettes

        ~1,000 recettes de cuisine

        **Cat√©gories:**
        - Italienne, Fran√ßaise
        - Asiatique, Mexicaine
        - Desserts, Plats

        **Id√©al pour:** Recherches simples
        """)

    with col2:
        st.markdown("""
        ### üé¨ Films

        ~1,000 synopsis de films

        **Cat√©gories:**
        - Science-fiction, Action
        - Com√©die, Drame
        - Fantasy, Horreur

        **Id√©al pour:** Concepts abstraits
        """)

    with col3:
        st.markdown("""
        ### üìö Wikipedia

        ~1,000 articles vari√©s

        **Cat√©gories:**
        - Technologie, Histoire
        - Science, Sport
        - Culture, G√©ographie

        **Id√©al pour:** Recherches complexes
        """)

    st.markdown("---")

    # === CALL TO ACTION ===
    st.markdown("""
    ## üéì Pr√™t √† Apprendre?

    **Parcours recommand√©:**

    1. üìä **TF-IDF** ‚Üí Comprends les bases (15 min)
    2. üéØ **BM25** ‚Üí D√©couvre les am√©liorations (20 min)
    3. üß† **Embeddings** ‚Üí Explore l'IA moderne (30 min)
    4. üìà **Synth√®se** ‚Üí Compare tout (10 min)

    **Temps total:** ~75 minutes pour ma√Ætriser la recherche textuelle! üöÄ
    """)

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.success(
            "üëâ **Commence maintenant en s√©lectionnant TF-IDF dans la sidebar!**"
        )

    st.markdown("---")

    # === FOOTER ===
    st.caption("""
    üí° **Conseil:** Tu peux revenir sur cette page √† tout moment en cliquant sur üè† Accueil dans la sidebar.

    üìñ **Objectif p√©dagogique:** Cette app est con√ßue pour des √©tudiants en d√©veloppement web (Bac+2/3) qui veulent comprendre comment fonctionnent les moteurs de recherche.
    """)


# ============================================================================
# SECTION TF-IDF (contenu existant restructur√©)
# ============================================================================


def render_tfidf_section(
    dataset,
    documents_texts,
    documents_titles,
    documents_categories,
    engine,
    remove_stopwords,
    show_intermediate,
    load_time,
    fit_time,
):
    """Section TF-IDF compl√®te avec tous les onglets"""

    st.title("üìä TF-IDF: Term Frequency - Inverse Document Frequency")

    # Sub-navigation avec boutons styl√©s
    tabs_tfidf = [
        "üìñ Introduction",
        "üî¢ Concepts",
        "üîç Recherche",
        "üìä Exploration",
        "üéì Pas-√†-Pas",
        "‚ö° Performance",
    ]
    tab = render_tab_navigation(tabs_tfidf, "tfidf_current_tab")

    if tab == "üìñ Introduction":
        render_tfidf_intro()
    elif tab == "üî¢ Concepts":
        render_tfidf_concepts(engine, documents_titles)
    elif tab == "üîç Recherche":
        render_tfidf_search(
            engine,
            documents_texts,
            documents_titles,
            documents_categories,
            show_intermediate,
        )
    elif tab == "üìä Exploration":
        render_tfidf_exploration(engine, documents_titles, documents_categories)
    elif tab == "üéì Pas-√†-Pas":
        render_tfidf_stepbystep(
            documents_texts, documents_titles, documents_categories, remove_stopwords
        )
    elif tab == "‚ö° Performance":
        render_tfidf_performance(
            engine, documents_texts, load_time, fit_time, remove_stopwords
        )


def render_tfidf_intro():
    """Introduction TF-IDF enrichie avec exemples d√©taill√©s"""
    st.header("üìñ Introduction: Le Probl√®me de la Recherche Textuelle")

    # === SECTION 1: LE CONTEXTE ===
    st.markdown("""
    ## üåç Le Contexte: Trouver l'aiguille dans la botte de foin

    Imagine que tu cherches **"recette italienne p√¢tes"** parmi 10,000 documents de cuisine.
    Comment l'ordinateur peut-il trouver les documents les plus **pertinents**?

    La solution na√Øve (compter les mots) √©choue lamentablement. Voyons pourquoi! üëá
    """)

    st.divider()

    # === SECTION 2: L'√âCHEC DE LA RECHERCHE NA√èVE ===
    st.markdown("### ‚ùå Probl√®me #1: La Longueur des Documents")

    col1, col2 = st.columns([3, 2])

    with col1:
        st.markdown("""
        **Approche na√Øve:** Compter simplement le nombre d'occurrences du mot.

        #### Sc√©nario Concret:

        Tu cherches **"chocolat"** dans des recettes:

        - **Doc A** (Titre: "Mousse au chocolat") - 50 mots
          - Mot "chocolat" appara√Æt **2 fois**
          - Proportion: **2/50 = 4%** du document
          - *C'est clairement une recette DE chocolat!*

        - **Doc B** (Titre: "Buffet complet") - 500 mots
          - Mot "chocolat" appara√Æt **3 fois** (mention rapide du dessert)
          - Proportion: **3/500 = 0.6%** du document
          - *Le chocolat est mentionn√© en passant*

        #### üí• Le Bug:

        L'approche na√Øve dit: **Doc B est plus pertinent** (3 > 2 occurrences)

        La r√©alit√©: **Doc A est clairement meilleur!** (4% vs 0.6%)
        """)

    with col2:
        st.code(
            """
üîç Recherche: "chocolat"

‚ùå Approche Na√Øve:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Doc A: 2 occurrences
Doc B: 3 occurrences
R√©sultat: B > A ‚ùå

‚úÖ Approche Intelligente:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Doc A: 4.0% du doc
Doc B: 0.6% du doc
R√©sultat: A > B ‚úÖ

üí° TF normalise par
   la longueur!
        """,
            language="text",
        )

    st.divider()

    # === SECTION 3: MOTS COMMUNS ===
    st.markdown("### ‚ùå Probl√®me #2: Les Mots Communs Polluent Tout")

    col1, col2 = st.columns([3, 2])

    with col1:
        st.markdown("""
        #### Sc√©nario: Recherche "cuisine traditionnelle"

        **Sans filtrage des mots communs:**

        Top 3 r√©sultats na√Øfs:
        1. üìÑ Doc avec **"la", "de", "un"** 50√ó chacun ‚Üí Score √©norme!
        2. üìÑ Doc avec **"et", "dans", "avec"** 40√ó ‚Üí Deuxi√®me!
        3. üìÑ Doc **vraiment** sur la cuisine traditionnelle ‚Üí Troisi√®me seulement!

        #### üí° Le Probl√®me:

        Les mots **super communs** comme "le", "la", "de", "un" apparaissent PARTOUT.

        Ils n'apportent **AUCUNE information** sur le sujet du document!

        - "le" ‚Üí Pr√©sent dans 99% des documents ‚Üí **Inutile!**
        - "traditionnelle" ‚Üí Pr√©sent dans 2% des documents ‚Üí **Tr√®s informatif!**

        #### üí° La Solution:

        **IDF (Inverse Document Frequency)** p√©nalise les mots qui apparaissent partout.

        Plus un mot est rare dans le corpus, plus son **IDF est √©lev√©**!
        """)

    with col2:
        st.code(
            """
üîç "cuisine traditionnelle"

‚ùå Sans IDF:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
1. "la" (score: 150)
2. "de" (score: 120)
3. "un" (score: 100)
...
42. "traditionnelle"
    (score: 3)

‚úÖ Avec IDF:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
IDF("la") = 0.01
  ‚Üí 150 √ó 0.01 = 1.5

IDF("traditionnelle")
  = 3.2
  ‚Üí 3 √ó 3.2 = 9.6

R√©sultat: "traditionnelle"
devient dominant! ‚úÖ
        """,
            language="text",
        )

    st.divider()

    # === SECTION 4: CAS D'USAGE R√âEL ===
    st.markdown("### üéØ Cas d'Usage R√©els de TF-IDF")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.info("""
        #### üîç Moteurs de Recherche

        Google, Bing utilisaient TF-IDF avant les embeddings!

        **Exemple:**
        - Requ√™te: "python tutorial"
        - TF-IDF trouve les docs qui parlent VRAIMENT de Python
        - Pas juste ceux qui mentionnent "python" 1 fois
        """)

    with col2:
        st.success("""
        #### üìß Filtrage de Spam

        D√©tecter les emails frauduleux

        **Exemple:**
        - Spam: "GAGNEZ", "GRATUIT", "URGENT"
        - IDF faible (dans tous les spams)
        - Mais TF √©lev√© dans spams
        - ‚Üí Signature claire!
        """)

    with col3:
        st.warning("""
        #### üìä Analyse de Documents

        Extraire les mots-cl√©s d'un texte

        **Exemple:**
        - Article scientifique
        - TF-IDF extrait: "algorithme", "r√©seau", "neuronal"
        - Ignore: "est", "dans", "pour"
        - ‚Üí Mots-cl√©s automatiques!
        """)

    st.divider()

    # === SECTION 5: LA SOLUTION TF-IDF ===
    st.markdown("""
    ## ‚úÖ La Solution: TF-IDF

    TF-IDF combine **deux mesures compl√©mentaires** pour r√©soudre ces probl√®mes:
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.info("""
        ### üìà TF (Term Frequency)

        **"Fr√©quence locale du mot dans le document"**

        **Formule:**
        ```
        TF = (nombre d'occurrences) / (total mots doc)
        ```

        **Ce qu'il fait:**
        - ‚úÖ Normalise par la longueur du document
        - ‚úÖ Compare des docs courts et longs √©quitablement
        - ‚úÖ Mesure l'importance locale d'un mot

        **Exemple:**
        - Doc de 100 mots avec "pizza" 5√ó
        - TF("pizza") = 5/100 = **0.05** (5%)
        """)

    with col2:
        st.success("""
        ### üìâ IDF (Inverse Document Frequency)

        **"Raret√© globale du mot dans tout le corpus"**

        **Formule:**
        ```
        IDF = log(total_docs / docs_avec_mot)
        ```

        **Ce qu'il fait:**
        - ‚úÖ P√©nalise les mots tr√®s communs
        - ‚úÖ Boost les mots rares et informatifs
        - ‚úÖ Mesure l'importance globale

        **Exemple:**
        - "le": dans 9,900/10,000 docs
        - IDF("le") = log(10000/9900) ‚âà **0.01**
        - "margherita": dans 50/10,000 docs
        - IDF("margherita") = log(10000/50) ‚âà **5.3**
        """)

    st.divider()

    st.markdown("""
    ## üßÆ TF-IDF = TF √ó IDF

    La formule magique multiplie les deux mesures:

    ```
    TF-IDF(mot, doc) = TF(mot, doc) √ó IDF(mot, corpus)
    ```

    #### üí° Interpr√©tation:

    Un mot a un **TF-IDF √©lev√©** si:
    1. Il appara√Æt **souvent dans CE document** (TF √©lev√©) ET
    2. Il appara√Æt **rarement dans les autres documents** (IDF √©lev√©)

    ‚Üí C'est un mot **discriminant** pour ce document! üéØ
    """)

    # Exemple visuel
    with st.expander("üìä Voir un Exemple Complet Calcul√©"):
        st.markdown("""
        ### Exemple: 3 Documents sur la Cuisine

        **Corpus:**
        1. Doc A: "La pizza margherita est une pizza italienne"
        2. Doc B: "La pasta carbonara est une recette italienne"
        3. Doc C: "La cuisine italienne est d√©licieuse"

        **Calculs pour le mot "pizza" dans Doc A:**

        **1Ô∏è‚É£ TF (Term Frequency):**
        ```
        Doc A contient 8 mots, "pizza" appara√Æt 2 fois
        TF("pizza", Doc A) = 2 / 8 = 0.25
        ```

        **2Ô∏è‚É£ IDF (Inverse Document Frequency):**
        ```
        "pizza" appara√Æt dans 1 document sur 3
        IDF("pizza") = log(3 / 1) = log(3) ‚âà 1.10
        ```

        **3Ô∏è‚É£ TF-IDF Final:**
        ```
        TF-IDF("pizza", Doc A) = 0.25 √ó 1.10 ‚âà 0.275
        ```

        **Comparaison avec "la":**
        ```
        TF("la", Doc A) = 1 / 8 = 0.125
        IDF("la") = log(3 / 3) = 0  (pr√©sent partout!)
        TF-IDF("la", Doc A) = 0.125 √ó 0 = 0
        ```

        ‚Üí **"pizza" a un score √©lev√©, "la" est √©limin√©!** ‚úÖ
        """)

    st.divider()

    st.success("""
    ### üéì Dans les Prochaines Sections

    Tu vas d√©couvrir:
    1. **Concepts TF-IDF** - Calculs d√©taill√©s avec visualisations
    2. **Recherche Interactive** - Teste le moteur en live!
    3. **Exploration du Corpus** - Analyse les mots-cl√©s
    4. **Exemple Pas-√†-Pas** - D√©roule un calcul complet
    5. **Performance** - Complexit√© et optimisations

    **‚Üí Passe √† l'onglet suivant!** üëâ
    """)


def render_tfidf_concepts(engine, documents_titles):
    """Concepts TF-IDF d√©taill√©s avec P√âDAGOGIE MAXIMALE"""
    st.header("üî¢ Concepts TF-IDF en Profondeur")

    st.markdown("""
    TF-IDF se compose de **3 concepts fondamentaux** que nous allons explorer un par un.

    Chaque concept r√©sout un probl√®me sp√©cifique de la recherche textuelle! üéØ
    """)

    # ============================================================================
    # CONCEPT 1: TERM FREQUENCY (TF)
    # ============================================================================
    with st.expander(
        "üìà **1. Term Frequency (TF)** - Fr√©quence des Mots", expanded=True
    ):
        st.markdown("""
        ### üí° L'Intuition

        **"Si un mot appara√Æt souvent dans un document, ce document parle probablement de ce sujet"**

        ### ü§î Le Probl√®me √† R√©soudre

        Imagine deux documents qui parlent de "chocolat":
        - **Doc A** (50 mots): "chocolat" appara√Æt **2 fois**
        - **Doc B** (500 mots): "chocolat" appara√Æt **3 fois**

        Sans normalisation, Doc B semble plus pertinent (3 > 2).
        **Mais!** Doc A consacre **4%** de son contenu au chocolat (2/50), tandis que Doc B seulement **0.6%** (3/500)!

        ### üìê La Formule
        """)

        st.latex(
            r"\text{TF}(mot, doc) = \frac{\text{nombre d'occurrences}}{\text{total de mots dans le doc}}"
        )

        st.markdown("""
        **Pourquoi diviser?** Pour normaliser! Un document court avec 2 occurrences peut √™tre plus "√† propos"
        du sujet qu'un document long avec 5 occurrences.

        ### üìä Exemple Visuel sur Notre Corpus

        Voici les TF de quelques mots dans 3 documents:
        """)

        # Graphique R√âDUIT (colonnes pour prendre moins d'espace!)
        col1, col2 = st.columns([2, 1])

        with col1:
            sample_indices = [0, 1, 2]
            sample_titles = [documents_titles[i] for i in sample_indices]
            fig_tf = plot_tf_comparison(engine.documents, sample_indices, sample_titles)
            st.pyplot(fig_tf)

        with col2:
            st.markdown("""
            **üîç Comment lire ce graphique:**

            - **Hauteur des barres** = TF (fr√©quence normalis√©e)
            - **Plus haut** = mot plus fr√©quent dans ce doc
            - **Comparaison** entre docs pour le m√™me mot

            **üí° Observation:**

            Un mot peut avoir un TF √©lev√© dans un doc et faible dans un autre.

            **Exemple:** "p√¢tes" a un TF de 0.08 dans la recette italienne, mais 0.00 dans le film!

            ‚û°Ô∏è Le TF capture bien le **sujet local** du document! ‚úÖ
            """)

        st.info("""
        **‚úÖ Ce que TF r√©sout:** Compare les documents √©quitablement, peu importe leur longueur!

        **‚ö†Ô∏è Ce que TF ne r√©sout PAS:** Les mots communs ("le", "la", "de") ont aussi des TF √©lev√©s...
        On verra comment IDF r√®gle ce probl√®me! üëá
        """)

    # ============================================================================
    # CONCEPT 2: INVERSE DOCUMENT FREQUENCY (IDF)
    # ============================================================================
    with st.expander("üìâ **2. Inverse Document Frequency (IDF)** - Raret√© des Mots"):
        st.markdown("""
        ### üí° L'Intuition

        **"Un mot RARE est plus INFORMATIF qu'un mot commun"**

        ### ü§î Le Probl√®me √† R√©soudre

        Tous les mots ne sont PAS √©gaux!
        - Le mot **"le"** appara√Æt dans TOUS les documents ‚Üí **PEU informatif** üòê
        - Le mot **"carbonara"** appara√Æt dans 1 seul document ‚Üí **TR√àS informatif**! üéØ

        ### üìê La Formule
        """)

        st.latex(r"\text{IDF}(mot) = \log\left(\frac{N}{n}\right) + 1")

        st.caption(
            "O√π: N = nombre total de documents, n = nombre de documents contenant le mot"
        )

        st.markdown("""
        **Pourquoi le logarithme?** Pour compresser l'√©chelle! Sans log, un mot pr√©sent dans 1 doc sur 10,000
        aurait un IDF de 10,000 - bien trop √©lev√©!

        Le log transforme √ßa en ~4, plus raisonnable. üìâ

        ### üìä Exemple: Courbe IDF

        Voici comment l'IDF varie selon le nombre de documents contenant un mot:
        """)

        # Graphiques IDF en colonnes
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**üìà Courbe IDF vs Fr√©quence**")
            fig_idf = plot_idf_curve(
                engine.idf_vector, engine.vocabulary, engine.documents
            )
            st.pyplot(fig_idf)

            st.markdown("""
            **üîç Comment lire:**
            - **Axe X** = Nombre de docs contenant le mot
            - **Axe Y** = Score IDF
            - **Courbe d√©croissante** = Plus un mot est fr√©quent, plus son IDF est faible

            **üí° Observation:**
            - Mot dans **1 doc** ‚Üí IDF √©lev√© (~3)
            - Mot dans **TOUS les docs** ‚Üí IDF proche de 0
            """)

        with col2:
            st.markdown("**‚òÅÔ∏è WordCloud par IDF**")
            # Prendre les 200 premiers mots du vocabulaire
            idf_dict = {
                engine.vocabulary[i]: engine.idf_vector[i]
                for i in range(min(200, len(engine.vocabulary)))
            }
            fig_wc = plot_idf_wordcloud(idf_dict)
            st.pyplot(fig_wc)

            st.markdown("""
            **üîç Comment lire:**
            - **Taille du mot** = IDF (raret√©)
            - **Gros mots** = mots RARES (informatifs!)
            - **Petits mots** = mots communs (peu informatifs)

            **üí° Observation:**

            Les mots sp√©cifiques sont **gros** (ex: "carbonara", "tiramisu"), tandis que les mots g√©n√©riques sont **petits** (ex: "tr√®s", "bien").
            """)

        st.success("""
        **‚úÖ Ce que IDF r√©sout:** Donne plus de poids aux mots RARES (informatifs) et moins aux mots COMMUNS!

        **Exemple concret:**
        - "le" ‚Üí IDF = 0.05 (commun, peu informatif)
        - "carbonara" ‚Üí IDF = 2.5 (rare, tr√®s informatif!)

        ‚û°Ô∏è Maintenant combinons TF et IDF! üéØ
        """)

    # ============================================================================
    # CONCEPT 3: TF-IDF COMBIN√â
    # ============================================================================
    with st.expander("üéØ **3. TF-IDF Combin√©** - La Magie Op√®re!"):
        st.markdown("""
        ### üí° L'Id√©e G√©niale

        **TF-IDF = Multiplie la fr√©quence locale (TF) par la raret√© globale (IDF)**

        ### üìê La Formule Finale
        """)

        st.latex(
            r"\text{TF-IDF}(mot, doc) = \text{TF}(mot, doc) \times \text{IDF}(mot)"
        )

        st.markdown("""
        **Ce que √ßa donne:**

        Les mots avec un **TF-IDF √©lev√©** sont ceux qui sont:
        1. **Fr√©quents dans LE document** (TF √©lev√©) ‚úÖ
        2. **Rares dans LES AUTRES documents** (IDF √©lev√©) ‚úÖ

        ‚û°Ô∏è Ce sont exactement les mots qui **caract√©risent** ce document! üéØ

        ### üìä Heatmap TF-IDF

        Visualisation des mots les plus importants pour chaque document:
        """)

        st.info("""
        **üí° Avant de regarder la heatmap:**

        - **Lignes** = Documents
        - **Colonnes** = Mots (top 15)
        - **Couleur** = Score TF-IDF (rouge = √©lev√©, bleu = faible)

        **Ce qu'on cherche:** Des cases **rouges** qui montrent quel mot caract√©rise quel document!
        """)

        # Heatmap r√©duite
        col1, col2 = st.columns([3, 1])

        with col1:
            fig_heatmap = plot_tfidf_heatmap(
                engine.tfidf_matrix, engine.vocabulary, documents_titles, top_words=15
            )
            st.pyplot(fig_heatmap)

        with col2:
            st.markdown("""
            **üîç Comment analyser:**

            1. **Regarder les colonnes** (mots):
               - Certains mots sont rouges pour UN doc, bleus pour les autres
               - ‚û°Ô∏è Ce mot CARACT√âRISE ce doc!

            2. **Regarder les lignes** (docs):
               - Chaque doc a ses propres mots "rouges"
               - ‚û°Ô∏è Son "empreinte" unique!

            3. **Patterns int√©ressants**:
               - Docs similaires ont des patterns similaires
               - Docs diff√©rents ont patterns diff√©rents

            **Exemple:**
            - Doc "P√¢tes Carbonara" ‚Üí "p√¢tes", "parmesan", "guanciale" en rouge
            - Doc "Interstellar" ‚Üí "espace", "temps", "trou" en rouge

            ‚û°Ô∏è TF-IDF capture parfaitement le sujet de chaque doc! ‚úÖ
            """)

        st.success("""
        **üéâ F√©licitations! Tu comprends TF-IDF!**

        **R√©cap en 3 points:**
        1. **TF** = Fr√©quence normalis√©e (local au document)
        2. **IDF** = Raret√© (global au corpus)
        3. **TF-IDF** = TF √ó IDF = Mots qui caract√©risent chaque document!

        **üéØ Utilisation:** Pour comparer une **requ√™te** avec des **documents**,
        on calcule le TF-IDF de chaque mot, puis on mesure la **similarit√©** (prochain concept!)
        """)

    # ============================================================================
    # CONCEPT BONUS: COSINE SIMILARITY
    # ============================================================================
    with st.expander("üìê **Bonus: Similarit√© Cosinus** - Comparer les Documents"):
        st.markdown("""
        ### üí° Le Concept G√©om√©trique

        Une fois qu'on a les vecteurs TF-IDF, comment comparer une **requ√™te** avec des **documents**?

        **R√©ponse:** La Similarit√© Cosinus! Elle mesure l'**angle** entre deux vecteurs.

        ### üìê La Formule
        """)

        st.latex(r"\text{cos}(\theta) = \frac{A \cdot B}{\|A\| \times \|B\|}")

        st.markdown("""
        **Composantes:**
        - **A ¬∑ B** = Produit scalaire (dot product) des vecteurs
        - **||A||** = Norme (longueur) du vecteur A
        - **||B||** = Norme (longueur) du vecteur B

        **R√©sultat:** Un score entre **0** et **1**:
        - **1.0** = Vecteurs identiques (angle = 0¬∞) ‚Üí **Tr√®s similaires!** üéØ
        - **0.5** = Vecteurs √† 60¬∞ ‚Üí Moyennement similaires
        - **0.0** = Vecteurs perpendiculaires (90¬∞) ‚Üí Pas similaires du tout

        ### ü§î Pourquoi l'Angle et pas juste la Distance?

        **Exemple concret:**
        - Doc A (court): Vecteur TF-IDF [0.1, 0.2, 0.1]
        - Doc B (long): Vecteur TF-IDF [0.5, 1.0, 0.5]

        Ces vecteurs pointent dans la **m√™me direction** (ratio 1:2:1), mais B est 5√ó plus long!

        - **Distance euclidienne:** Grande! ‚ùå (sugg√®re qu'ils sont diff√©rents)
        - **Angle (cosinus):** Petit! ‚úÖ (d√©tecte qu'ils parlent du m√™me sujet)

        ‚û°Ô∏è L'angle capture la **similitude th√©matique** ind√©pendamment de la longueur! üéØ
        """)

        st.info("""
        **üí° En pratique:**

        Pour une requ√™te "plat italien p√¢tes":
        1. Calculer son vecteur TF-IDF
        2. Calculer la similarit√© cosinus avec CHAQUE document
        3. Trier les documents par score d√©croissant
        4. Afficher les top r√©sultats!

        **C'est exactement ce que fait la section "Recherche Interactive"!** üîç
        """)

    st.markdown("---")
    st.success("""
    ‚úÖ **Section Concepts termin√©e!**

    Tu ma√Ætrises maintenant:
    - TF (fr√©quence normalis√©e)
    - IDF (raret√© globale)
    - TF-IDF (combinaison magique)
    - Similarit√© Cosinus (comparaison)

    **üëâ Passe √† la "Recherche Interactive" pour voir TF-IDF en action!**
    """)


def render_tfidf_search(
    engine, documents_texts, documents_titles, documents_categories, show_intermediate
):
    """Recherche interactive TF-IDF avec analyses p√©dagogiques"""
    st.header("üîç Recherche Interactive TF-IDF")

    st.markdown("""
    **Teste TF-IDF en action!** üöÄ

    Entre une requ√™te (plusieurs mots), et on va trouver les documents les plus pertinents
    en calculant la **similarit√© cosinus** entre ta requ√™te et chaque document.

    **Comment √ßa marche:**
    1. Ta requ√™te est transform√©e en vecteur TF-IDF
    2. On calcule la similarit√© avec TOUS les documents
    3. On trie par score d√©croissant
    4. On affiche les meilleurs r√©sultats! üéØ
    """)

    # Utiliser un formulaire pour soumission avec Enter
    with st.form("tfidf_search_form", clear_on_submit=False):
        col1, col2 = st.columns([3, 1])

        with col1:
            query = st.text_input(
                "üîé Entre ta requ√™te:",
                value="plat italien p√¢tes",  # Valeur par d√©faut!
                placeholder="Ex: plat italien, science-fiction espace, guerre mondiale...",
                key="tfidf_query_input",
                help='üí° **Exemples:** "plat italien p√¢tes fromage" | "cuisine asiatique √©pic√©e crevettes" | "dessert chocolat fran√ßais" | "poisson grill√© m√©diterran√©en"',
            )

        with col2:
            top_k = st.slider(
                "R√©sultats:",
                3,
                20,
                5,
                key="tfidf_topk_slider",
                help="Nombre de documents les plus pertinents √† afficher",
            )

        # Bouton de soumission (Enter fonctionne aussi!)
        submitted = st.form_submit_button("üöÄ Rechercher!", type="primary")

    if submitted and query:
        with st.spinner("üîç Recherche en cours..."):
            results = engine.search(query, top_k=top_k)

            if len(results) == 0 or all(score == 0 for _, score in results):
                st.warning("üòï Aucun r√©sultat. Essaie d'autres mots!")
            else:
                st.success(f"‚úÖ {len(results)} r√©sultats trouv√©s!")

                # ========= GRAPHIQUE + ANALYSE C√îTE √Ä C√îTE =========
                st.markdown("### üìä Visualisation des Scores")

                col_graph, col_analysis = st.columns([2, 1])

                with col_graph:
                    fig_results = plot_search_results(results, documents_titles, query)
                    st.pyplot(fig_results)

                with col_analysis:
                    st.markdown("**üîç Comment lire ce graphique:**")
                    st.markdown("""
                    - **Axe X** = Score de similarit√© (0 √† 1)
                    - **Axe Y** = Documents trouv√©s
                    - **Plus √† droite** = plus similaire!

                    **üí° Interpr√©tation des scores:**
                    - **> 0.5** ‚Üí Tr√®s pertinent! üéØ
                    - **0.3 - 0.5** ‚Üí Moyennement pertinent üëå
                    - **< 0.3** ‚Üí Faiblement pertinent üòê
                    """)

                    # Analyse automatique des r√©sultats!
                    top_score = results[0][1]
                    score_range = results[0][1] - results[-1][1]

                    if top_score > 0.5:
                        st.success(
                            f"üéØ **Excellent!** Le top r√©sultat a un score de {top_score:.3f} - tr√®s pertinent!"
                        )
                    elif top_score > 0.3:
                        st.info(
                            f"üëå **Bon!** Score de {top_score:.3f} - pertinence moyenne."
                        )
                    else:
                        st.warning(
                            f"üòê **Moyen...** Score max de {top_score:.3f} - essaye d'autres mots?"
                        )

                    if score_range > 0.2:
                        st.markdown(
                            f"üìä **Bonne s√©paration:** Les scores varient de {results[-1][1]:.3f} √† {results[0][1]:.3f} - TF-IDF distingue bien les docs!"
                        )
                    else:
                        st.markdown(
                            f"üìä **Scores proches:** √âcart de seulement {score_range:.3f} - les docs se ressemblent!"
                        )

                # ========= R√âSULTATS D√âTAILL√âS =========
                st.markdown("---")
                st.markdown("### üéØ R√©sultats D√©taill√©s")

                for rank, (doc_idx, score) in enumerate(results[:5], 1):
                    # Badge de qualit√© selon le score
                    if score > 0.5:
                        badge = "üî• **Tr√®s pertinent!**"
                        badge_color = "green"
                    elif score > 0.3:
                        badge = "üëå **Pertinent**"
                        badge_color = "blue"
                    else:
                        badge = "üòê **Faiblement pertinent**"
                        badge_color = "orange"

                    with st.expander(
                        f"**#{rank}** - {documents_titles[doc_idx]} ‚Ä¢ Score: **{score:.3f}** {badge}"
                    ):
                        col1, col2 = st.columns([2, 1])

                        with col1:
                            st.caption(
                                f"**Cat√©gorie:** {documents_categories[doc_idx]}"
                            )
                            st.write(documents_texts[doc_idx][:300] + "...")

                        with col2:
                            st.markdown("**üìä Pourquoi ce score?**")

                            # Analyser les mots de la query pr√©sents dans le doc
                            query_words = set(query.lower().split())
                            doc_words = set(documents_texts[doc_idx].lower().split())
                            common_words = query_words & doc_words

                            if common_words:
                                st.markdown(
                                    f"‚úÖ **Mots en commun:** {', '.join(list(common_words)[:5])}"
                                )
                                st.markdown(
                                    f"üìà **Overlap:** {len(common_words)}/{len(query_words)} mots"
                                )
                            else:
                                st.markdown("‚ùå Aucun mot en commun (synonymes?)")

                            # Optionnel: afficher les calculs d√©taill√©s
                            if show_intermediate:
                                with st.expander("üî¨ Calculs d√©taill√©s"):
                                    explanation = engine.get_explanation(query, doc_idx)
                                    st.json(explanation)

                # ========= CONSEILS P√âDAGOGIQUES =========
                st.markdown("---")
                st.info("""
                **üí° Exp√©rimente!**

                - **Requ√™te courte** (1-2 mots) ‚Üí R√©sultats larges
                - **Requ√™te longue** (4-5 mots) ‚Üí R√©sultats pr√©cis
                - **Mots rares** ‚Üí Meilleurs scores (IDF √©lev√©!)
                - **Mots communs** ‚Üí Scores plus faibles

                **üéØ Astuce:** Utilise des mots **sp√©cifiques** √† ce que tu cherches!
                """)


def render_tfidf_exploration(engine, documents_titles, documents_categories):
    """Exploration du corpus TF-IDF avec analyses approfondies"""
    st.header("üìä Exploration du Corpus")

    st.markdown("""
    Cette section te permet d'explorer le **corpus dans son ensemble** et de comprendre
    ses caract√©ristiques globales! üî¨

    Tu verras:
    - Les statistiques du corpus
    - La distribution du vocabulaire
    - Les mots les plus informatifs (IDF √©lev√©)
    - La structure des documents en 3D
    """)

    # ============================================================================
    # M√âTRIQUES GLOBALES
    # ============================================================================
    st.markdown("### üìà M√©triques du Corpus")

    col1, col2, col3, col4 = st.columns(4)

    num_docs = len(documents_titles)
    vocab_size = len(engine.vocabulary)
    avg_words = np.mean([len(doc) for doc in engine.documents])
    num_categories = len(set(documents_categories))

    col1.metric(
        "üìö Documents", num_docs, help="Nombre total de documents dans le corpus"
    )
    col2.metric(
        "üî§ Vocabulaire",
        vocab_size,
        help="Nombre de mots uniques (apr√®s preprocessing)",
    )
    col3.metric(
        "üìù Mots/Doc", f"{avg_words:.1f}", help="Longueur moyenne d'un document"
    )
    col4.metric("üè∑Ô∏è Cat√©gories", num_categories, help="Nombre de cat√©gories diff√©rentes")

    # Interpr√©tation automatique
    st.markdown("**üí° Interpr√©tation:**")

    if vocab_size > num_docs * 10:
        st.info(
            f"üìñ **Vocabulaire riche:** {vocab_size} mots pour {num_docs} docs ‚Üí Corpus diversifi√©!"
        )
    elif vocab_size > num_docs * 5:
        st.info(f"üìñ **Vocabulaire normal:** Ratio vocabulaire/docs √©quilibr√©.")
    else:
        st.warning(
            f"üìñ **Vocabulaire limit√©:** Peu de mots uniques ‚Üí Docs probablement similaires."
        )

    if avg_words > 100:
        st.info(
            f"üìÑ **Documents longs:** Moyenne de {avg_words:.0f} mots ‚Üí Textes d√©taill√©s!"
        )
    elif avg_words > 50:
        st.info(f"üìÑ **Documents moyens:** Longueur raisonnable pour l'analyse.")
    else:
        st.info(
            f"üìÑ **Documents courts:** {avg_words:.0f} mots en moyenne ‚Üí Textes concis!"
        )

    st.markdown("---")

    # ============================================================================
    # DISTRIBUTION DU VOCABULAIRE
    # ============================================================================
    st.markdown("### üìä Distribution du Vocabulaire")

    col_graph1, col_analysis1 = st.columns([2, 1])

    with col_graph1:
        st.markdown("**üìà Statistiques de Fr√©quence**")
        fig_vocab = plot_vocabulary_stats(engine.documents)
        st.pyplot(fig_vocab)

    with col_analysis1:
        st.markdown("**üîç Comment lire:**")
        st.markdown("""
        Ce graphique montre la **distribution des longueurs de documents**.

        - **Axe X** = Longueur du document (nombre de mots)
        - **Axe Y** = Nombre de documents
        - **Forme de la courbe** = Distribution du corpus

        **üí° Ce qu'on veut:**
        - **Distribution uniforme** ‚Üí Corpus √©quilibr√© ‚úÖ
        - **Pics multiples** ‚Üí Cat√©gories distinctes üéØ
        - **Un seul pic** ‚Üí Docs similaires en longueur

        **üìä Observation:**

        Si tous les docs ont ~la m√™me longueur, TF-IDF fonctionnera bien!
        Si les longueurs varient beaucoup, attention √† la normalisation!
        """)

    st.markdown("---")

    # ============================================================================
    # TOP MOTS PAR IDF
    # ============================================================================
    st.markdown("### üèÜ Top Mots les Plus Informatifs (IDF)")

    st.markdown("""
    Voici les mots avec les **IDF les plus √©lev√©s** - ce sont les mots les plus **RARES** et donc
    les plus **INFORMATIFS** du corpus! üéØ
    """)

    # Extraire top 20 mots par IDF
    idf_items = [
        (engine.vocabulary[idx], engine.idf_vector[idx])
        for idx in range(len(engine.vocabulary))
    ]
    top_idf = sorted(idf_items, key=lambda x: x[1], reverse=True)[:20]

    col_graph2, col_analysis2 = st.columns([2, 1])

    with col_graph2:
        st.markdown("**üìä Top 20 Mots par IDF**")

        # Cr√©er un bar chart simple
        import matplotlib.pyplot as plt

        fig, ax = plt.subplots(figsize=(8, 6))
        words = [w for w, _ in top_idf]
        idfs = [idf for _, idf in top_idf]
        ax.barh(words[::-1], idfs[::-1], color="#1f77b4")
        ax.set_xlabel("Score IDF")
        ax.set_title("Mots les Plus Informatifs")
        plt.tight_layout()
        st.pyplot(fig)

    with col_analysis2:
        st.markdown("**üîç Analyse:**")
        st.markdown(f"""
        **Top 3 mots:**
        1. **{top_idf[0][0]}** ({top_idf[0][1]:.2f})
        2. **{top_idf[1][0]}** ({top_idf[1][1]:.2f})
        3. **{top_idf[2][0]}** ({top_idf[2][1]:.2f})

        **üí° Ce que √ßa signifie:**

        Ces mots sont **rares** dans le corpus!
        - IDF √©lev√© ‚Üí Peu de docs contiennent ce mot
        - ‚û°Ô∏è Tr√®s informatif pour caract√©riser un doc

        **üéØ En pratique:**

        Si ta requ√™te contient ces mots, les r√©sultats seront **tr√®s pr√©cis**!

        Si un document contient ces mots, il se **d√©marque** des autres!
        """)

    st.markdown("---")

    # ============================================================================
    # PROJECTION 3D DES DOCUMENTS
    # ============================================================================
    st.markdown("### üåê Projection 3D des Documents")

    st.info("""
    **üí° Avant de regarder la visualisation:**

    Chaque document est repr√©sent√© par un **point dans l'espace 3D**.
    - La position est calcul√©e avec **PCA** (r√©duction de dimensionalit√©)
    - Les couleurs = cat√©gories
    - **Documents proches** = sujets similaires!
    - **Documents √©loign√©s** = sujets diff√©rents!

    **üéØ Ce qu'on cherche:**
    - Des **clusters** (groupes) par cat√©gorie ‚úÖ
    - Une bonne **s√©paration** entre cat√©gories ‚úÖ
    """)

    col_graph3, col_analysis3 = st.columns([3, 1])

    with col_graph3:
        fig_3d = plot_documents_3d(
            engine.tfidf_matrix, documents_titles, documents_categories
        )
        st.plotly_chart(fig_3d, use_container_width=True)

    with col_analysis3:
        st.markdown("**üîç Interpr√©tation:**")
        st.markdown("""
        **Comment analyser:**

        1. **Rotation:** Clique et fais glisser pour tourner la vue üîÑ

        2. **Zoom:** Scroll pour zoomer/d√©zoomer üîç

        3. **Hover:** Survole un point pour voir le titre üëÜ

        **üí° Patterns √† observer:**

        - **Clusters bien s√©par√©s** ‚Üí TF-IDF distingue bien les cat√©gories! ‚úÖ

        - **Chevauchement** ‚Üí Certains docs se ressemblent malgr√© des cat√©gories diff√©rentes ü§î

        - **Points isol√©s** ‚Üí Docs uniques, diff√©rents des autres! üåü

        **üéØ Utilit√©:**

        Cette visualisation montre si ton corpus est bien **structur√©** et si TF-IDF capte les **diff√©rences** entre documents!
        """)

    st.markdown("---")
    st.success("""
    ‚úÖ **Section Exploration termin√©e!**

    Tu as maintenant une **vue d'ensemble compl√®te** du corpus:
    - Ses statistiques globales
    - Ses mots les plus informatifs
    - Sa structure spatiale

    **üëâ Ces analyses t'aident √† comprendre si TF-IDF est adapt√© √† ton corpus!**
    """)


def render_tfidf_stepbystep(
    documents_texts, documents_titles, documents_categories, remove_stopwords
):
    """Exemple pas-√†-pas TF-IDF COMPLET avec tous les calculs d√©taill√©s"""
    st.header("üéì Exemple Complet Pas-√†-Pas")

    st.markdown("""
    Dans cette section, tu vas voir **TOUS les calculs** en d√©tail, √©tape par √©tape!

    On va prendre 3 documents et calculer leur similarit√© avec ta requ√™te. üî¨
    """)

    # === DOCUMENTS D'EXEMPLE ===
    sample_indices = list(range(min(3, len(documents_texts))))

    st.markdown("### üìö Documents utilis√©s pour l'exemple")

    for idx in sample_indices:
        with st.expander(
            f"üìÑ Document {idx + 1}: {documents_titles[idx]}", expanded=(idx == 0)
        ):
            st.write(f"**Cat√©gorie:** {documents_categories[idx]}")
            st.write(f"**Contenu:** {documents_texts[idx]}")
            word_count = len(documents_texts[idx].split())
            st.caption(f"üìä Longueur: {word_count} mots")

    st.markdown("---")

    # === QUERY INPUT ===
    query = st.text_input(
        "üîé Ta requ√™te de test:",
        value="plat italien fromage",
        key="tfidf_tutorial",
        help='üí° **Exemples:** "chocolat dessert" | "p√¢tes italiennes sauce" | "poisson grill√© citron"',
    )

    if not query:
        st.warning("‚¨ÜÔ∏è Entre une requ√™te ci-dessus pour voir les calculs!")
        return

    # === CALCULS ===
    with st.spinner("üßÆ Calcul en cours..."):
        sample_texts = [documents_texts[i] for i in sample_indices]
        mini_engine = TFIDFEngine(sample_texts, remove_stopwords=remove_stopwords)
        mini_engine.fit()

        query_tokens = preprocess_text(query)

        st.success(f'‚úÖ Calculs termin√©s pour la requ√™te: **"{query}"**')

    # === √âTAPE 1: VOCABULAIRE ===
    st.markdown("---")
    st.markdown("## üî¢ √âtape 1: Construction du Vocabulaire")

    st.markdown("""
    On commence par **extraire tous les mots uniques** de nos 3 documents.
    C'est notre **vocabulaire** (ou *vocabulary*).
    """)

    vocab_size = len(mini_engine.vocabulary)
    st.metric("üìö Taille du vocabulaire", f"{vocab_size} mots uniques")

    with st.expander("üëÄ Voir le vocabulaire complet"):
        vocab_list = sorted(list(mini_engine.vocabulary))
        st.write(", ".join(vocab_list[:100]))
        if len(vocab_list) > 100:
            st.caption(f"... et {len(vocab_list) - 100} autres mots")

    # === √âTAPE 2: TERM FREQUENCY (TF) ===
    st.markdown("---")
    st.markdown("## üìä √âtape 2: Calcul des Term Frequencies (TF)")

    st.markdown("""
    **TF = Combien de fois un mot appara√Æt dans un document, normalis√© par la longueur.**

    **Formule:** `TF(mot, doc) = nb_occurrences / nb_total_mots`

    **Pourquoi normaliser?** Pour ne pas favoriser les documents longs!
    """)

    st.latex(r"\text{TF}(t, d) = \frac{\text{count}(t, d)}{|\text{words}(d)|}")

    # Calculer TF pour les mots de la query
    query_words_in_vocab = [w for w in query_tokens if w in mini_engine.vocabulary]

    if len(query_words_in_vocab) == 0:
        st.warning(
            "‚ö†Ô∏è Aucun mot de ta requ√™te n'est dans le vocabulaire! Essaie d'autres mots."
        )
        return

    st.info(
        f"üéØ **Mots de ta requ√™te dans le vocabulaire:** {', '.join(query_words_in_vocab)}"
    )

    # Cr√©er tableau TF
    tf_data = []
    for doc_idx in sample_indices:
        row = {"Document": documents_titles[doc_idx][:30] + "..."}
        for word in query_words_in_vocab:
            word_idx = mini_engine.word_to_idx[word]  # FIX: Utiliser word_to_idx!
            tf_value = mini_engine.tf_matrix[doc_idx, word_idx]
            row[word] = f"{tf_value:.4f}"
        tf_data.append(row)

    df_tf = pd.DataFrame(tf_data)
    st.markdown("**üìä Tableau des TF (Term Frequencies):**")
    st.dataframe(df_tf, use_container_width=True, hide_index=True)

    st.markdown("""
    **üí° Interpr√©tation:**
    - Plus le TF est **√©lev√©**, plus le mot est **fr√©quent** dans le document
    - Un TF de 0.05 = le mot repr√©sente **5%** du document
    - Un TF de 0.00 = le mot n'appara√Æt **pas** dans ce document
    """)

    # === √âTAPE 3: INVERSE DOCUMENT FREQUENCY (IDF) ===
    st.markdown("---")
    st.markdown("## üîç √âtape 3: Calcul des Inverse Document Frequencies (IDF)")

    st.markdown("""
    **IDF = Mesure de la raret√© d'un mot dans TOUS les documents.**

    **Formule:** `IDF(mot) = log(nb_total_docs / nb_docs_contenant_mot)`

    **Pourquoi?** Les mots **rares** sont plus **informatifs** que les mots communs!
    """)

    st.latex(r"\text{IDF}(t) = \log\left(\frac{N}{n_t}\right)")

    st.caption(
        "O√π: N = nombre total de documents, n_t = nombre de documents contenant le terme t"
    )

    # Calculer IDF pour les mots de la query
    idf_data = []
    for word in query_words_in_vocab:
        word_idx = mini_engine.word_to_idx[word]  # FIX: Utiliser word_to_idx!
        idf_value = mini_engine.idf_vector[word_idx]

        # Compter dans combien de docs le mot appara√Æt
        docs_with_word = sum(
            1
            for doc_idx in sample_indices
            if mini_engine.tf_matrix[doc_idx, word_idx] > 0
        )

        idf_data.append(
            {
                "Mot": word,
                "Docs contenant": f"{docs_with_word}/{len(sample_indices)}",
                "IDF": f"{idf_value:.4f}",
                "Raret√©": "üî¥ Rare"
                if docs_with_word == 1
                else "üü° Moyen"
                if docs_with_word == 2
                else "üü¢ Commun",
            }
        )

    df_idf = pd.DataFrame(idf_data)
    st.markdown("**üìä Tableau des IDF (Inverse Document Frequencies):**")
    st.dataframe(df_idf, use_container_width=True, hide_index=True)

    st.markdown("""
    **üí° Interpr√©tation:**
    - IDF **√©lev√©** (ex: 0.48) = mot **RARE** (appara√Æt dans peu de docs) ‚Üí **tr√®s informatif**! üî¥
    - IDF **moyen** (ex: 0.18) = mot **commun** dans certains docs ‚Üí informatif üü°
    - IDF **faible** (ex: 0.00) = mot dans **TOUS** les docs ‚Üí peu informatif üü¢
    """)

    # === √âTAPE 4: TF-IDF (MULTIPLICATION) ===
    st.markdown("---")
    st.markdown("## üéØ √âtape 4: Calcul Final TF-IDF")

    st.markdown("""
    **TF-IDF = TF √ó IDF**

    On **multiplie** la fr√©quence locale (TF) par la raret√© globale (IDF)!

    **R√©sultat:** Les mots qui sont √† la fois:
    - **Fr√©quents dans le document** (TF √©lev√©)
    - **Rares dans le corpus** (IDF √©lev√©)

    ... ont un **score TF-IDF √©lev√©**! C'est eux qui caract√©risent le document! ‚ú®
    """)

    st.latex(r"\text{TF-IDF}(t, d) = \text{TF}(t, d) \times \text{IDF}(t)")

    # Cr√©er tableau TF-IDF
    tfidf_data = []
    for doc_idx in sample_indices:
        row = {"Document": documents_titles[doc_idx][:30] + "..."}
        for word in query_words_in_vocab:
            word_idx = mini_engine.word_to_idx[word]  # FIX: Utiliser word_to_idx!
            tfidf_value = mini_engine.tfidf_matrix[doc_idx, word_idx]
            row[word] = f"{tfidf_value:.4f}"
        tfidf_data.append(row)

    df_tfidf = pd.DataFrame(tfidf_data)
    st.markdown("**üìä Tableau des TF-IDF:**")
    st.dataframe(df_tfidf, use_container_width=True, hide_index=True)

    # === √âTAPE 5: VECTORISATION DE LA QUERY ===
    st.markdown("---")
    st.markdown("## üî§ √âtape 5: Vectorisation de la Requ√™te")

    st.markdown("""
    On doit aussi calculer le **vecteur TF-IDF de la requ√™te**!

    **Processus:**
    1. Calculer le TF de chaque mot dans la requ√™te
    2. Multiplier par l'IDF (d√©j√† calcul√©)
    3. On obtient le vecteur TF-IDF de la query!
    """)

    # Calculer vecteur query
    query_vector = np.zeros(len(mini_engine.vocabulary))
    query_word_count = {}
    for word in query_tokens:
        if word in mini_engine.vocabulary:
            query_word_count[word] = query_word_count.get(word, 0) + 1

    query_tfidf_data = []
    for word in query_words_in_vocab:
        word_idx = mini_engine.word_to_idx[word]  # FIX: Utiliser word_to_idx!
        tf_query = query_word_count.get(word, 0) / len(query_tokens)
        idf = mini_engine.idf_vector[word_idx]
        tfidf_query = tf_query * idf
        query_vector[word_idx] = tfidf_query

        query_tfidf_data.append(
            {
                "Mot": word,
                "TF (requ√™te)": f"{tf_query:.4f}",
                "IDF": f"{idf:.4f}",
                "TF-IDF": f"{tfidf_query:.4f}",
            }
        )

    df_query = pd.DataFrame(query_tfidf_data)
    st.markdown("**üìä Vecteur TF-IDF de ta requ√™te:**")
    st.dataframe(df_query, use_container_width=True, hide_index=True)

    # === √âTAPE 6: SIMILARIT√â COSINUS ===
    st.markdown("---")
    st.markdown("## üìê √âtape 6: Calcul de la Similarit√© Cosinus")

    st.markdown("""
    **Comment comparer la requ√™te avec chaque document?**

    On utilise la **similarit√© cosinus** = mesure l'angle entre deux vecteurs!

    **Formule:**
    """)

    st.latex(r"\text{cos}(\theta) = \frac{A \cdot B}{\|A\| \times \|B\|}")

    st.markdown("""
    **O√π:**
    - `A ¬∑ B` = **Produit scalaire** (dot product)
    - `||A||` = **Norme** du vecteur A (longueur)
    - `||B||` = **Norme** du vecteur B

    **R√©sultat:** Score entre 0 et 1:
    - **1.0** = vecteurs identiques (angle = 0¬∞) ‚Üí **documents tr√®s similaires!** üéØ
    - **0.5** = vecteurs moyennement similaires
    - **0.0** = vecteurs orthogonaux (aucun mot en commun)
    """)

    # Calculer similarit√©s
    results = mini_engine.search(query, top_k=len(sample_indices))

    similarity_data = []
    for doc_idx, score in results:
        doc_vector = mini_engine.tfidf_matrix[doc_idx, :]

        # Calculs d√©taill√©s
        dot_product = np.dot(query_vector, doc_vector)
        norm_query = np.linalg.norm(query_vector)
        norm_doc = np.linalg.norm(doc_vector)

        similarity_data.append(
            {
                "Rang": len(similarity_data) + 1,
                "Document": documents_titles[doc_idx][:40] + "...",
                "Dot Product": f"{dot_product:.4f}",
                "Norme Query": f"{norm_query:.4f}",
                "Norme Doc": f"{norm_doc:.4f}",
                "Similarit√©": f"{score:.4f}",
                "Pertinence": "ü•á Excellent!"
                if score > 0.3
                else "ü•à Bon"
                if score > 0.1
                else "ü•â Faible",
            }
        )

    df_sim = pd.DataFrame(similarity_data)
    st.markdown("**üìä Calculs de Similarit√© pour Chaque Document:**")
    st.dataframe(df_sim, use_container_width=True, hide_index=True)

    # === R√âSULTAT FINAL ===
    st.markdown("---")
    st.markdown("## üèÜ R√©sultat Final: Classement")

    st.markdown("""
    Les documents sont **class√©s par ordre d√©croissant** de similarit√© cosinus!

    Le document avec le score le plus √©lev√© est le **plus pertinent** pour ta requ√™te! üéØ
    """)

    # Afficher le classement final avec style
    for rank, (doc_idx, score) in enumerate(results, 1):
        if rank == 1:
            st.success(
                f"ü•á **#{rank}:** {documents_titles[doc_idx]} - Score: **{score:.4f}**"
            )
        elif rank == 2:
            st.info(
                f"ü•à **#{rank}:** {documents_titles[doc_idx]} - Score: **{score:.4f}**"
            )
        else:
            st.warning(
                f"ü•â **#{rank}:** {documents_titles[doc_idx]} - Score: **{score:.4f}**"
            )

    st.markdown("---")

    st.success("""
    ‚úÖ **F√©licitations!** Tu as vu TOUS les calculs de TF-IDF en d√©tail!

    **R√©cap:**
    1. ‚úÖ Vocabulaire construit
    2. ‚úÖ TF calcul√©s (fr√©quence locale)
    3. ‚úÖ IDF calcul√©s (raret√© globale)
    4. ‚úÖ TF-IDF = TF √ó IDF
    5. ‚úÖ Query vectoris√©e
    6. ‚úÖ Similarit√© cosinus calcul√©e
    7. ‚úÖ Documents class√©s!

    **üéì Tu ma√Ætrises maintenant TF-IDF!**
    """)


def render_tfidf_performance(
    engine, documents_texts, load_time, fit_time, remove_stopwords
):
    """Performances TF-IDF avec benchmarks automatiques et p√©dagogie"""
    st.header("‚ö° Analyse des Performances TF-IDF")

    st.markdown("""
    Cette section t'explique **comment TF-IDF performe** et **pourquoi**!

    Tu verras:
    - Les m√©triques de ton corpus actuel
    - La complexit√© algorithmique expliqu√©e
    - Des benchmarks automatiques sur diff√©rents datasets
    - L'impact de la taille du corpus sur la vitesse
    """)

    # ============================================================================
    # M√âTRIQUES DU CORPUS ACTUEL
    # ============================================================================
    st.markdown("### üìä M√©triques du Corpus Actuel")

    n_docs = len(documents_texts)
    n_vocab = len(engine.vocabulary)
    avg_doc_len = np.mean([len(doc) for doc in engine.documents])
    total_words = sum(len(doc) for doc in engine.documents)

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("üìö Documents", f"{n_docs:,}", help="Nombre de documents index√©s")
    col2.metric(
        "üî§ Vocabulaire",
        f"{n_vocab:,}",
        help="Nombre de mots uniques (apr√®s preprocessing)",
    )
    col3.metric(
        "üìù Mots/Doc", f"{avg_doc_len:.0f}", help="Longueur moyenne d'un document"
    )
    col4.metric(
        "üíæ Total Mots", f"{total_words:,}", help="Nombre total de mots dans le corpus"
    )

    st.divider()

    # ============================================================================
    # TEMPS D'EX√âCUTION
    # ============================================================================
    st.markdown("### ‚è±Ô∏è Temps d'Ex√©cution")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("**üîÑ Chargement**")
        st.metric("", f"{load_time:.3f}s")
        st.caption("Temps de lecture et pr√©traitement des donn√©es")

    with col2:
        st.markdown("**üßÆ Indexation**")
        st.metric("", f"{fit_time:.3f}s")
        st.caption("Calcul des matrices TF, IDF et TF-IDF")

    with col3:
        st.markdown("**üí° Efficacit√©**")
        docs_per_sec = (
            n_docs / (load_time + fit_time) if (load_time + fit_time) > 0 else 0
        )
        st.metric("", f"{docs_per_sec:.0f} docs/s")
        st.caption("Nombre de documents index√©s par seconde")

    # Interpr√©tation automatique
    total_time = load_time + fit_time
    if total_time < 0.1:
        st.success(
            f"üöÄ **Ultra rapide!** Indexation en {total_time:.3f}s - parfait pour ce corpus!"
        )
    elif total_time < 1.0:
        st.info(f"‚ö° **Rapide!** Indexation en {total_time:.3f}s - tr√®s bon!")
    elif total_time < 5.0:
        st.info(f"üëå **Correct!** Indexation en {total_time:.3f}s - acceptable.")
    else:
        st.warning(
            f"üêå **Lent...** Indexation en {total_time:.3f}s - corpus volumineux!"
        )

    st.divider()

    # ============================================================================
    # COMPLEXIT√â ALGORITHMIQUE
    # ============================================================================
    st.markdown("### üßÆ Complexit√© Algorithmique Expliqu√©e")

    st.markdown("""
    **TF-IDF a une complexit√© algorithmique en `O(n √ó m)` o√π:**
    - **n** = nombre de documents
    - **m** = longueur moyenne des documents

    **Ce que √ßa signifie:**
    - Si tu **doubles le nombre de documents**, le temps d'indexation **double** aussi ‚è±Ô∏è
    - Si tu **doubles la longueur des documents**, le temps **double** aussi ‚è±Ô∏è

    **Op√©rations principales:**
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **1. Preprocessing (O(n √ó m)):**
        - Tokenization
        - Lowercasing
        - Stopwords removal
        - Vocabulaire construction

        **2. Calcul TF (O(n √ó m)):**
        - Compter occurrences
        - Normaliser par longueur
        - Stocker dans matrice
        """)

    with col2:
        st.markdown("""
        **3. Calcul IDF (O(n √ó v)):**
        - Compter docs contenant chaque mot
        - Appliquer log
        - Stocker dans vecteur

        **4. Calcul TF-IDF (O(n √ó v)):**
        - Multiplication TF √ó IDF
        - Stocker matrice finale
        """)

    # Estimation th√©orique
    st.info(f"""
    **üí° Estimation pour ton corpus:**
    - Complexit√© preprocessing: O({n_docs} √ó {avg_doc_len:.0f}) ‚âà {n_docs * avg_doc_len:.0f} op√©rations
    - Complexit√© TF-IDF: O({n_docs} √ó {n_vocab}) ‚âà {n_docs * n_vocab:.0f} op√©rations

    **Total estim√©:** ~{(n_docs * avg_doc_len + n_docs * n_vocab):.0f} op√©rations
    """)

    st.divider()

    # ============================================================================
    # BENCHMARKS AUTOMATIQUES
    # ============================================================================
    st.markdown("### üèÅ Benchmarks Automatiques")

    st.markdown("""
    **On va comparer les performances** sur diff√©rents datasets pour voir l'impact de la taille! üìä

    Clique sur le bouton ci-dessous pour lancer les benchmarks (√ßa prend ~10-20 secondes).
    """)

    if st.button("üöÄ Lancer les Benchmarks!", type="primary", key="tfidf_bench_btn"):
        with st.spinner("‚è±Ô∏è Benchmarking en cours... (peut prendre 10-20s)"):
            from src.data_loader import load_dataset
            import time

            # D√©finir les tests
            benchmark_tests = [
                {"name": "recettes", "extended": False, "label": "Recettes (30 docs)"},
                {"name": "films", "extended": False, "label": "Films (25 docs)"},
                {
                    "name": "wikipedia",
                    "extended": False,
                    "label": "Wikipedia (50 docs)",
                },
            ]

            results = []

            for test in benchmark_tests:
                try:
                    # Charger dataset
                    start = time.time()
                    dataset = load_dataset(test["name"], extended=test["extended"])
                    texts = [doc["text"] for doc in dataset]
                    load_t = time.time() - start

                    # Indexer
                    start = time.time()
                    test_engine = TFIDFEngine(texts, remove_stopwords=remove_stopwords)
                    test_engine.fit()
                    fit_t = time.time() - start

                    # Recherche (query simple)
                    start = time.time()
                    test_engine.search("test recherche exemple", top_k=5)
                    search_t = time.time() - start

                    results.append(
                        {
                            "Dataset": test["label"],
                            "Docs": len(texts),
                            "Vocab": len(test_engine.vocabulary),
                            "Load (s)": f"{load_t:.3f}",
                            "Index (s)": f"{fit_t:.3f}",
                            "Search (s)": f"{search_t:.3f}",
                            "Total (s)": f"{load_t + fit_t:.3f}",
                            "_total_numeric": load_t + fit_t,
                            "_docs_numeric": len(texts),
                        }
                    )
                except Exception as e:
                    st.error(f"Erreur sur {test['label']}: {e}")
                    continue

            if results:
                # Afficher tableau
                df_results = pd.DataFrame(results)
                df_display = df_results.drop(
                    columns=["_total_numeric", "_docs_numeric"]
                )

                st.markdown("**üìä R√©sultats des Benchmarks:**")
                st.dataframe(df_display, use_container_width=True, hide_index=True)

                st.markdown("---")

                # Graphique: Temps vs Nombre de docs
                st.markdown(
                    "**üìà Graphique: Temps d'Indexation vs Nombre de Documents**"
                )

                col_graph, col_analysis = st.columns([2, 1])

                with col_graph:
                    import matplotlib.pyplot as plt

                    fig, ax = plt.subplots(figsize=(8, 5))

                    x = [r["_docs_numeric"] for r in results]
                    y = [r["_total_numeric"] for r in results]
                    labels = [r["Dataset"] for r in results]

                    # Scatter plot
                    ax.scatter(x, y, s=100, alpha=0.6, color="#1f77b4")

                    # Labels
                    for i, label in enumerate(labels):
                        ax.annotate(
                            label,
                            (x[i], y[i]),
                            xytext=(5, 5),
                            textcoords="offset points",
                            fontsize=8,
                        )

                    # Ligne de tendance
                    if len(x) > 1:
                        z = np.polyfit(x, y, 1)
                        p = np.poly1d(z)
                        ax.plot(x, p(x), "r--", alpha=0.8, label="Tendance lin√©aire")
                        ax.legend()

                    ax.set_xlabel("Nombre de Documents")
                    ax.set_ylabel("Temps Total (s)")
                    ax.set_title("Performance TF-IDF: Temps vs Taille du Corpus")
                    ax.grid(True, alpha=0.3)

                    plt.tight_layout()
                    st.pyplot(fig)

                with col_analysis:
                    st.markdown("**üîç Analyse:**")

                    fastest = min(results, key=lambda x: x["_total_numeric"])
                    slowest = max(results, key=lambda x: x["_total_numeric"])

                    st.markdown(f"""
                    **‚ö° Plus rapide:**
                    {fastest["Dataset"]}
                    - {fastest["Total (s)"]}s
                    - {fastest["Docs"]} docs

                    **üêå Plus lent:**
                    {slowest["Dataset"]}
                    - {slowest["Total (s)"]}s
                    - {slowest["Docs"]} docs

                    **üí° Observation:**

                    La ligne rouge montre la tendance **lin√©aire** ‚Üí confirme la complexit√© O(n)!

                    Plus il y a de documents, plus √ßa prend de temps **proportionnellement**.
                    """)

                st.success("""
                ‚úÖ **Conclusion des Benchmarks:**

                TF-IDF est **rapide et scalable** pour des corpus de taille petite √† moyenne!

                - **< 100 docs:** Quasi instantan√© ‚ö°
                - **100-1000 docs:** Tr√®s rapide (< 1s) üöÄ
                - **1000-10000 docs:** Rapide (1-10s) üëå
                - **> 10000 docs:** Optimisations recommand√©es (index invers√©, etc.)
                """)

    st.divider()

    # ============================================================================
    # OPTIMISATIONS POSSIBLES
    # ============================================================================
    st.markdown("### üöÄ Optimisations Possibles")

    st.markdown("""
    Si ton corpus devient **tr√®s gros** (> 10,000 docs), voici comment acc√©l√©rer TF-IDF:
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **1. Index Invers√©**

        Au lieu de stocker une matrice compl√®te (docs √ó mots), stocke seulement les mots **pr√©sents** dans chaque document.

        ‚û°Ô∏è √âconomise de la RAM et acc√©l√®re la recherche!

        **2. Sparse Matrices**

        Utilise `scipy.sparse` au lieu de NumPy dense.

        ‚û°Ô∏è Matrice TF-IDF souvent > 90% de z√©ros!

        **3. Preprocessing Cache**

        Sauvegarde les documents preprocess√©s sur disque.

        ‚û°Ô∏è √âvite de retokenizer √† chaque run!
        """)

    with col2:
        st.markdown("""
        **4. Batch Processing**

        Traite les documents par batch de 1000.

        ‚û°Ô∏è √âvite les pics de RAM!

        **5. Parallelization**

        Utilise `multiprocessing` pour tokenizer en parall√®le.

        ‚û°Ô∏è CPU multi-core = gain de vitesse!

        **6. Approximations**

        Limite le vocabulaire aux N mots les plus fr√©quents.

        ‚û°Ô∏è Trade-off pr√©cision vs vitesse!
        """)

    st.info("""
    **üí° Pour ton usage actuel:**

    Avec des corpus de ~1000 docs, **aucune optimisation n'est n√©cessaire**!

    TF-IDF est d√©j√† **rapide** et **efficace** pour cette taille. üéØ
    """)


# ============================================================================
# SECTION BM25 (NOUVEAU!)
# ============================================================================


def render_bm25_section(
    dataset,
    documents_texts,
    documents_titles,
    documents_categories,
    tfidf_engine,
    remove_stopwords,
):
    """Section BM25 compl√®te"""

    st.title("üéØ BM25: Best Matching 25 - TF-IDF Am√©lior√©")

    # Sub-navigation avec boutons styl√©s
    tabs_bm25 = [
        "üìñ Introduction",
        "üî¢ Concepts",
        "üîç Recherche",
        "üìä Exploration",
        "üéì Pas-√†-Pas",
        "‚öîÔ∏è Comparaison",
        "‚ö° Performance",
    ]
    tab = render_tab_navigation(tabs_bm25, "bm25_current_tab")

    if tab == "üìñ Introduction":
        render_bm25_intro()
    elif tab == "üî¢ Concepts":
        render_bm25_concepts(documents_texts, remove_stopwords)
    elif tab == "üîç Recherche":
        render_bm25_search(
            documents_texts, documents_titles, documents_categories, remove_stopwords
        )
    elif tab == "üìä Exploration":
        render_bm25_exploration(documents_texts, documents_titles, remove_stopwords)
    elif tab == "üéì Pas-√†-Pas":
        render_bm25_stepbystep(documents_texts, documents_titles, remove_stopwords)
    elif tab == "‚öîÔ∏è Comparaison":
        render_bm25_comparison(
            documents_texts, documents_titles, tfidf_engine, remove_stopwords
        )
    elif tab == "‚ö° Performance":
        render_bm25_performance(documents_texts, remove_stopwords)


def render_bm25_intro():
    """Introduction BM25 & Probl√®mes de TF-IDF - HYPER P√âDAGOGIQUE"""
    st.header("üìñ BM25: √âvolution Intelligente de TF-IDF")

    st.markdown("""
    ### üéØ Contexte Historique

    **TF-IDF** (ann√©es 1970) √©tait r√©volutionnaire pour son √©poque.
    **BM25** (1994) est son √©volution moderne, d√©velopp√©e par Stephen Robertson et Karen Sp√§rck Jones.

    BM25 = **B**est **M**atching **25** (25√®me it√©ration de l'algorithme!)
    """)

    st.divider()

    st.markdown("## ‚ùå Les 3 Probl√®mes Fondamentaux de TF-IDF")

    # === PROBL√àME #1: SATURATION ===
    with st.expander("**üî¥ Probl√®me #1: Saturation Lin√©aire du TF**", expanded=True):
        st.markdown("""
        ### üí° Le Probl√®me en D√©tail

        Dans TF-IDF, le score cro√Æt **lin√©airement** avec le nombre d'occurrences.
        Mais est-ce r√©aliste? ü§î
        """)

        # Exemple concret avec calculs
        st.markdown("""
        #### üìù Exemple Concret

        Imaginons 3 documents parlant de "Python":
        """)

        col1, col2, col3 = st.columns(3)

        with col1:
            st.info("""
            **üìÑ Doc A**

            - Longueur: 100 mots
            - "python": **1√ó fois**
            - TF = 1/100 = **0.01**

            *Article de blog mentionnant Python en passant*
            """)

        with col2:
            st.warning("""
            **üìÑ Doc B**

            - Longueur: 100 mots
            - "python": **10√ó fois**
            - TF = 10/100 = **0.10**

            *Article d√©di√© √† Python*
            """)

        with col3:
            st.error("""
            **üìÑ Doc C**

            - Longueur: 100 mots
            - "python": **50√ó fois**
            - TF = 50/100 = **0.50**

            *Spam avec r√©p√©titions*
            """)

        st.markdown("""
        ### ü§Ø Le Probl√®me

        Avec TF-IDF:
        - Doc B (10√ó) a un score **10√ó plus √©lev√©** que Doc A (1√ó)
        - Doc C (50√ó) a un score **5√ó plus √©lev√©** que Doc B (10√ó)

        **Mais en r√©alit√©:**
        - Apr√®s 10 occurrences, le mot n'apporte **plus d'information nouvelle**!
        - Doc C n'est pas 50√ó plus pertinent que Doc A
        - On veut un **effet de saturation** (plateau)
        """)

        # Graphique en colonnes
        col_g1, col_g2 = st.columns(2)

        with col_g1:
            fig_sat = plot_saturation_effect()
            st.pyplot(fig_sat)

        with col_g2:
            st.markdown("""
            ### üìä Analyse du Graphique

            **Ligne rouge (TF-IDF):**
            - Croissance lin√©aire infinie
            - 100 occurrences = 100√ó le score de 1
            - **Irr√©aliste!** ‚ùå

            **Courbes color√©es (BM25):**
            - Croissance rapide au d√©but
            - Plateau apr√®s N occurrences
            - **R√©aliste!** ‚úÖ

            **Param√®tre k1:**
            - k1 faible ‚Üí saturation rapide
            - k1 √©lev√© ‚Üí saturation lente
            """)

    # === PROBL√àME #2: NORMALISATION ===
    with st.expander("**üü† Probl√®me #2: Normalisation Na√Øve par Longueur**"):
        st.markdown("""
        ### üí° Le Probl√®me en D√©tail

        TF-IDF normalise en divisant simplement par la longueur totale.
        R√©sultat: les documents longs sont **toujours p√©nalis√©s**.
        """)

        st.markdown("""
        #### üìù Exemple Concret

        Deux recettes parlant de "chocolat":
        """)

        col1, col2 = st.columns(2)

        with col1:
            st.info("""
            **üç´ Recette Courte (50 mots)**

            ```
            Mousse au chocolat simple:
            200g chocolat, 4 oeufs, sucre.
            Faire fondre chocolat.
            Monter blancs. M√©langer.
            [+ 42 mots de remplissage...]
            ```

            - "chocolat": **2 occurrences**
            - TF = 2/50 = **0.04** (4%)
            """)

        with col2:
            st.warning("""
            **üç´ Recette D√©taill√©e (500 mots)**

            ```
            Mousse au chocolat professionnelle:
            Introduction sur le chocolat (50 mots)
            Liste d√©taill√©e ingr√©dients (100 mots)
            √âtapes d√©taill√©es avec chocolat (200 mots)
            Astuces et variantes chocolat (150 mots)
            ```

            - "chocolat": **15 occurrences**
            - TF = 15/500 = **0.03** (3%)
            """)

        st.markdown("""
        ### ü§Ø Le Probl√®me

        **Avec TF-IDF:**
        - Recette courte (2√ó chocolat) ‚Üí TF = 0.04
        - Recette d√©taill√©e (15√ó chocolat) ‚Üí TF = 0.03
        - La recette d√©taill√©e a un **score PLUS BAS** ‚ùå

        **Ce qu'on veut:**
        - P√©naliser les docs longs... **mais pas toujours!**
        - Certains corpus ont naturellement des docs longs (articles scientifiques)
        - D'autres ont des docs courts (tweets, recettes)
        - On veut un **contr√¥le ajustable** via param√®tre **b**
        """)

        st.markdown("""
        ### üí° Solution BM25

        Le param√®tre **b** contr√¥le l'intensit√© de la p√©nalit√©:

        - **b = 0**: Aucune p√©nalit√© (ignore la longueur)
        - **b = 0.5**: P√©nalit√© l√©g√®re
        - **b = 0.75**: P√©nalit√© standard ‚≠ê (recommand√©)
        - **b = 1.0**: P√©nalit√© compl√®te (comme TF-IDF)

        Tu peux adapter selon ton corpus!
        """)

    # === PROBL√àME #3: PAS DE CONTR√îLE ===
    with st.expander("**üü° Probl√®me #3: Aucun Param√®tre Ajustable**"):
        st.markdown("""
        ### üí° Le Probl√®me

        TF-IDF est une formule **fig√©e**:
        """)

        st.latex(
            r"\text{TF-IDF} = \frac{f}{|D|} \times \log\left(\frac{N}{n(t)}\right)"
        )

        st.markdown("""
        **Cons√©quences:**
        - ‚ùå Impossible d'adapter selon le type de corpus
        - ‚ùå Impossible de tuner pour de meilleures performances
        - ‚ùå Un seul comportement pour tous les cas

        **Exemples de corpus diff√©rents:**

        | Type de Corpus | Comportement Optimal |
        |----------------|---------------------|
        | **Tweets** (courts) | Peu de normalisation (b faible) |
        | **Articles** (longs) | Normalisation forte (b √©lev√©) |
        | **Spam** (r√©p√©titions) | Saturation rapide (k1 faible) |
        | **Litt√©rature** (vari√©) | Saturation lente (k1 √©lev√©) |

        TF-IDF ne peut s'adapter √† aucun de ces cas! ‚ùå
        """)

    st.divider()

    # === SOLUTION BM25 ===
    st.markdown("## ‚úÖ BM25: La Solution Intelligente")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.success("""
        ### üéõÔ∏è Param√®tre k1

        **Contr√¥le la saturation du TF**

        **Valeurs typiques:**
        - 0.5 ‚Üí Saturation rapide
        - **1.5** ‚Üí Standard ‚≠ê
        - 2.0 ‚Üí Saturation lente
        - ‚àû ‚Üí Comme TF-IDF

        **Effet:**
        Apr√®s N occurrences, le score plafonne intelligemment!
        """)

    with col2:
        st.success("""
        ### ‚öñÔ∏è Param√®tre b

        **Contr√¥le la normalisation**

        **Valeurs typiques:**
        - 0.0 ‚Üí Aucune
        - **0.75** ‚Üí Standard ‚≠ê
        - 1.0 ‚Üí Compl√®te

        **Effet:**
        Ajuste la p√©nalit√© des documents longs selon ton corpus!
        """)

    with col3:
        st.success("""
        ### üìä IDF Am√©lior√©

        **Smoothing int√©gr√©**

        **Formule:**
        ```
        log((N - n + 0.5) /
            (n + 0.5))
        ```

        **Effet:**
        - √âvite divisions par z√©ro
        - Plus stable que TF-IDF
        - Meilleure gestion des mots rares
        """)

    st.divider()

    st.markdown("## üéØ Formule Compl√®te BM25")

    st.latex(r"""
    \text{BM25}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \times \frac{f(q_i, D) \times (k1 + 1)}{f(q_i, D) + k1 \times \left(1 - b + b \times \frac{|D|}{\text{avgdl}}\right)}
    """)

    st.markdown(r"""
    ### üìñ D√©composition de la Formule

    | Composant | Signification | R√¥le |
    |-----------|---------------|------|
    | **IDF(qi)** | Inverse Document Frequency | Raret√© du mot (avec smoothing) |
    | **f(qi, D)** | Fr√©quence du mot | Nombre d'occurrences dans le doc |
    | **k1** | Param√®tre saturation | Contr√¥le le plateau du TF |
    | **b** | Param√®tre normalisation | Contr√¥le la p√©nalit√© de longueur |
    | **\|D\|** | Longueur du document | Nombre de mots dans le doc |
    | **avgdl** | Longueur moyenne | Moyenne du corpus |

    ### üí° En R√©sum√©

    **TF-IDF:** Simple mais limit√© (ann√©es 1970)
    **BM25:** Intelligent et ajustable (1994 - encore utilis√© aujourd'hui!)

    BM25 est le **standard industriel** pour la recherche textuelle:
    - Utilis√© par Elasticsearch
    - Utilis√© par Apache Lucene/Solr
    - Base de millions de moteurs de recherche
    """)


def render_bm25_concepts(documents_texts, remove_stopwords):
    """Concepts BM25 d√©taill√©s - HYPER P√âDAGOGIQUE"""
    st.header("üî¢ Comprendre BM25 en Profondeur")

    st.markdown("""
    D√©cortiquons chaque composant de BM25 avec des **exemples concrets** et des **calculs chiffr√©s**!
    """)

    # === IDF AM√âLIOR√â ===
    with st.expander(
        "üìâ **Composant #1: IDF Am√©lior√© (avec smoothing)**", expanded=True
    ):
        st.markdown("""
        ### üí° L'IDF de TF-IDF avait des Probl√®mes

        **Formule TF-IDF IDF:**
        """)

        st.latex(r"\text{IDF}_{\text{TF-IDF}}(t) = \log\left(\frac{N}{n(t)}\right)")

        st.markdown("""
        **Probl√®mes:**
        1. ‚ö†Ô∏è **Division par z√©ro** si n(t) = 0 (mot absent du corpus)
        2. ‚ö†Ô∏è **Valeurs extr√™mes** pour les mots tr√®s rares
        3. ‚ö†Ô∏è **Pas de smoothing** pour stabiliser
        """)

        st.divider()

        st.markdown("""
        ### ‚úÖ BM25 IDF R√©sout Ces Probl√®mes

        **Formule BM25 IDF:**
        """)

        st.latex(
            r"\text{IDF}_{\text{BM25}}(q) = \log\left(\frac{N - n(q) + 0.5}{n(q) + 0.5}\right)"
        )

        st.markdown("""
        **Composants:**
        - **N** = nombre total de documents dans le corpus
        - **n(q)** = nombre de documents contenant le terme q
        - **+0.5** = **smoothing de Laplace** (√©vite divisions par z√©ro)
        """)

        st.markdown("""
        ### üìù Exemple Concret avec Calculs

        Corpus de **1000 documents**:
        """)

        # Tableau comparatif avec calculs
        import pandas as pd

        examples = [
            {"Mot": "le", "n(q)": 950, "Raret√©": "Tr√®s commun"},
            {"Mot": "cuisine", "n(q)": 300, "Raret√©": "Commun"},
            {"Mot": "python", "n(q)": 50, "Raret√©": "Rare"},
            {"Mot": "blockchain", "n(q)": 5, "Raret√©": "Tr√®s rare"},
        ]

        for ex in examples:
            n = ex["n(q)"]
            N = 1000
            # TF-IDF IDF
            idf_tfidf = np.log(N / n) if n > 0 else float("inf")
            # BM25 IDF
            idf_bm25 = np.log((N - n + 0.5) / (n + 0.5))

            ex["IDF TF-IDF"] = f"{idf_tfidf:.3f}"
            ex["IDF BM25"] = f"{idf_bm25:.3f}"

        df_idf = pd.DataFrame(examples)
        st.dataframe(df_idf, use_container_width=True)

        st.markdown("""
        ### üìä Observations

        **Pour les mots communs ("le"):**
        - TF-IDF: 0.054 (tr√®s proche de 0)
        - BM25: 0.053 (similaire)
        - ‚úÖ Peu de diff√©rence

        **Pour les mots rares ("blockchain"):**
        - TF-IDF: 5.298 (valeur √©lev√©e)
        - BM25: 5.298 (plus stable avec smoothing)
        - ‚úÖ BM25 mieux stabilis√©

        **Avantage du +0.5:**
        - √âvite les explosions de valeurs
        - Plus robuste aux mots tr√®s rares
        - Meilleure g√©n√©ralisation
        """)

    # === SATURATION DU TF ===
    with st.expander("üéõÔ∏è **Composant #2: Saturation du TF (Param√®tre k1)**"):
        st.markdown("""
        ### üí° Pourquoi Saturer le TF?

        **Observation r√©aliste:**
        Apr√®s **10 occurrences**, un mot n'apporte **plus beaucoup d'info nouvelle**.

        - 1 occurrence ‚Üí Le doc parle du sujet ‚úÖ
        - 10 occurrences ‚Üí Le doc parle VRAIMENT du sujet ‚úÖ‚úÖ
        - 100 occurrences ‚Üí Le doc... parle toujours du sujet (mais pas 100√ó plus!) ‚ö†Ô∏è
        """)

        st.markdown("""
        ### üî¢ Formule du TF Satur√©
        """)

        st.latex(r"\text{TF}_{\text{BM25}} = \frac{f \times (k1 + 1)}{f + k1}")

        st.markdown("""
        **Composants:**
        - **f** = fr√©quence du terme dans le document
        - **k1** = param√®tre contr√¥lant la vitesse de saturation
        """)

        st.markdown("""
        ### üìù Exemple Concret: Mot "Python"

        Testons diff√©rentes valeurs de **k1**:
        """)

        # Calculs pour diff√©rents k1
        frequencies = [1, 2, 5, 10, 20, 50, 100]
        k1_values = [0.5, 1.2, 1.5, 2.0]

        data = []
        for f in frequencies:
            row = {"Occurrences (f)": f}
            for k1 in k1_values:
                tf_bm25 = (f * (k1 + 1)) / (f + k1)
                row[f"k1={k1}"] = f"{tf_bm25:.3f}"
            data.append(row)

        df_saturation = pd.DataFrame(data)
        st.dataframe(df_saturation, use_container_width=True)

        st.markdown("""
        ### üìä Observations Cl√©s

        **Avec k1 = 0.5 (saturation rapide):**
        - 10 occ ‚Üí 0.909
        - 100 occ ‚Üí 0.993
        - Plafonne tr√®s vite! (bon pour √©viter le spam)

        **Avec k1 = 1.5 (standard ‚≠ê):**
        - 10 occ ‚Üí 1.304
        - 100 occ ‚Üí 1.485
        - √âquilibre r√©aliste

        **Avec k1 = 2.0 (saturation lente):**
        - 10 occ ‚Üí 1.375
        - 100 occ ‚Üí 1.970
        - Plus de croissance (bon pour textes vari√©s)

        **k1 ‚Üí ‚àû (comme TF-IDF):**
        - Croissance lin√©aire sans limite
        """)

        # Graphique en colonnes
        col_g1, col_g2 = st.columns(2)

        with col_g1:
            fig_sat = plot_saturation_effect(k1_values=[0.5, 1.2, 1.5, 2.0])
            st.pyplot(fig_sat)

        with col_g2:
            st.markdown("""
            ### üìà Analyse du Graphique

            **Axe X:** Nombre d'occurrences du mot
            **Axe Y:** Score TF r√©sultant

            **Ligne rouge (TF-IDF):**
            - Monte ind√©finiment
            - 100 occ = 100√ó le score
            - **Probl√©matique!** ‚ùå

            **Courbes BM25:**
            - **Bleue (k1=0.5)**: Plateau √† ~1.0
            - **Orange (k1=1.2)**: Plateau √† ~1.2
            - **Verte (k1=1.5)**: Plateau √† ~1.5 ‚≠ê
            - **Rouge (k1=2.0)**: Plateau √† ~2.0

            **Conseil:**
            k1=1.5 est le standard pour la plupart des corpus!
            """)

    # === NORMALISATION ===
    with st.expander("‚öñÔ∏è **Composant #3: Normalisation de Longueur (Param√®tre b)**"):
        st.markdown("""
        ### üí° Le Probl√®me des Documents Longs

        **Question:** Un document de 1000 mots devrait-il √™tre p√©nalis√©
        par rapport √† un document de 100 mots?

        **R√©ponse:** **√áa d√©pend du corpus!** ü§î

        - **Tweets** (courts naturellement) ‚Üí Peu de p√©nalit√©
        - **Articles scientifiques** (longs naturellement) ‚Üí Forte p√©nalit√©
        - **Recettes** (longueur mixte) ‚Üí P√©nalit√© mod√©r√©e
        """)

        st.markdown("""
        ### üî¢ Formule de Normalisation
        """)

        st.latex(r"\text{norm} = 1 - b + b \times \frac{|D|}{\text{avgdl}}")

        st.markdown("""
        **Composants:**
        - **|D|** = longueur du document actuel (en mots)
        - **avgdl** = longueur moyenne du corpus (average document length)
        - **b** = intensit√© de la p√©nalit√© (0 = aucune, 1 = compl√®te)
        """)

        st.markdown("""
        ### üìù Exemple Concret

        Corpus avec **avgdl = 100 mots** (moyenne):
        """)

        # Calculs pour diff√©rents b
        doc_lengths = [50, 100, 200, 500, 1000]
        b_values = [0.0, 0.5, 0.75, 1.0]
        avgdl = 100

        data = []
        for length in doc_lengths:
            row = {"Longueur doc": f"{length} mots"}
            for b in b_values:
                norm = 1 - b + b * (length / avgdl)
                row[f"b={b}"] = f"{norm:.3f}"
            data.append(row)

        df_norm = pd.DataFrame(data)
        st.dataframe(df_norm, use_container_width=True)

        st.markdown("""
        ### üìä Interpr√©tation

        **Facteur de normalisation > 1** = P√©nalit√© (doc plus long que la moyenne)
        **Facteur de normalisation = 1** = Neutre (doc de longueur moyenne)
        **Facteur de normalisation < 1** = Boost (doc plus court que la moyenne)

        **Avec b = 0 (aucune normalisation):**
        - Facteur = 1.0 pour tous les docs
        - La longueur est **ignor√©e**
        - Bon pour corpus homog√®nes

        **Avec b = 0.75 (standard ‚≠ê):**
        - Doc 50 mots ‚Üí 0.625 (boost de +60%)
        - Doc 200 mots ‚Üí 1.750 (p√©nalit√© de -43%)
        - Doc 1000 mots ‚Üí 8.500 (p√©nalit√© de -88%)
        - √âquilibre raisonnable

        **Avec b = 1.0 (normalisation compl√®te):**
        - P√©nalit√© maximale pour les docs longs
        - Comme TF-IDF (division par longueur)
        """)

        # Cr√©er un mini corpus pour calculer avgdl
        bm25_demo = BM25Engine(documents_texts[:10], remove_stopwords=remove_stopwords)

        col_g1, col_g2 = st.columns(2)

        with col_g1:
            fig_norm = plot_length_normalization(
                avgdl=bm25_demo.avgdl, doc_lengths=[50, 100, 150, 200]
            )
            st.pyplot(fig_norm)

        with col_g2:
            st.markdown(f"""
            ### üìà Analyse du Graphique

            **Corpus actuel:**
            - avgdl = {bm25_demo.avgdl:.1f} mots

            **Ligne horizontale (b=0):**
            - Facteur = 1.0 constant
            - Aucune p√©nalit√©

            **Courbes montantes (b > 0):**
            - Plus b est √©lev√©, plus la pente est forte
            - b=0.75 (standard) = compromis

            **Conseil pratique:**
            - **b=0.5** si corpus homog√®ne (longueurs similaires)
            - **b=0.75** standard (recommand√©) ‚≠ê
            - **b=1.0** si beaucoup de spam/docs longs
            """)

    # === FORMULE COMPL√àTE ===
    with st.expander("üéØ **Formule Compl√®te BM25**"):
        st.markdown("""
        ### üî• La Grande Formule (tout ensemble!)
        """)

        st.latex(r"""
        \text{BM25}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \times \frac{f(q_i, D) \times (k1 + 1)}{f(q_i, D) + k1 \times \left(1 - b + b \times \frac{|D|}{\text{avgdl}}\right)}
        """)

        st.markdown("""
        ### üìñ D√©cortiquons la Formule

        **Œ£ (Somme):** On additionne pour **chaque mot** de la query

        **IDF(qi):** Raret√© du mot i dans le corpus (avec smoothing)

        **Num√©rateur:** f(qi, D) √ó (k1 + 1)
        ‚Üí Fr√©quence du mot, l√©g√®rement boost√©e

        **D√©nominateur:** f(qi, D) + k1 √ó [1 - b + b √ó |D|/avgdl]
        ‚Üí Fr√©quence + facteur de saturation √ó normalisation
        """)

        st.markdown("""
        ### üéì Algorithme en Pseudo-Code

        ```python
        def BM25(document, query, k1=1.5, b=0.75):
            score = 0

            for mot in query:
                # 1. Calculer IDF
                idf = log((N - n + 0.5) / (n + 0.5))

                # 2. Compter fr√©quence
                f = count(mot, document)

                # 3. Calculer normalisation
                norm = 1 - b + b * (len(document) / avgdl)

                # 4. Calculer TF satur√©
                tf = (f * (k1 + 1)) / (f + k1 * norm)

                # 5. Multiplier IDF √ó TF
                score += idf * tf

            return score
        ```
        """)

        st.success("""
        ### ‚úÖ Avantages de BM25

        1. **Saturation intelligente** via k1 (√©vite le spam)
        2. **Normalisation ajustable** via b (adapte au corpus)
        3. **IDF stable** avec smoothing (robuste)
        4. **Param√®tres tunables** (optimisation possible)
        5. **Standard industriel** (utilis√© partout!)
        """)


def render_bm25_search(
    documents_texts, documents_titles, documents_categories, remove_stopwords
):
    """Recherche interactive BM25"""
    st.header("üîç Recherche Interactive BM25")

    st.markdown("""
    Teste BM25 avec tes propres param√®tres!
    """)

    # Utiliser un formulaire pour soumission avec Enter
    with st.form("bm25_search_form", clear_on_submit=False):
        col1, col2, col3 = st.columns([2, 1, 1])

        with col1:
            query = st.text_input(
                "üîé Votre recherche:",
                value="plat italien fromage",  # Valeur par d√©faut!
                placeholder="Ex: plat italien, film science-fiction, guerre mondiale...",
                key="bm25_query_input",
                help='üí° **Exemples:** "plat italien fromage" | "science-fiction vaisseau espace" | "guerre conflit mondial arm√©e" | "football champion coupe"',
            )

        with col2:
            k1 = st.slider(
                "k1 (saturation)",
                min_value=0.0,
                max_value=3.0,
                value=1.5,
                step=0.1,
                help="‚öôÔ∏è Contr√¥le la saturation du TF. **Standard = 1.5** | Plus √©lev√© = moins de saturation | Plus bas = saturation rapide",
                key="bm25_k1_slider",
            )

        with col3:
            b = st.slider(
                "b (normalisation)",
                min_value=0.0,
                max_value=1.0,
                value=0.75,
                step=0.05,
                help="‚öôÔ∏è Contr√¥le la p√©nalit√© de longueur. **Standard = 0.75** | 0 = aucune | 1 = compl√®te",
                key="bm25_b_slider",
            )

        top_k = st.slider(
            "Nombre de r√©sultats:",
            3,
            20,
            5,
            key="bm25_topk_slider",
            help="Nombre de documents les plus pertinents √† afficher",
        )

        # Bouton de soumission (Enter fonctionne aussi!)
        submitted = st.form_submit_button("üöÄ Rechercher avec BM25!", type="primary")

    if submitted and query:
        with st.spinner("üîç Recherche BM25 en cours..."):
            # Cr√©er engine BM25 avec les param√®tres
            bm25_engine = BM25Engine(
                documents_texts, k1=k1, b=b, remove_stopwords=remove_stopwords
            )

            results = bm25_engine.search(query, top_k=top_k)

            if len(results) == 0 or all(score == 0 for _, score in results):
                st.warning("üòï Aucun r√©sultat. Essaie d'autres mots!")
            else:
                st.success(f"‚úÖ {len(results)} r√©sultats BM25 trouv√©s!")

                # === ANALYSE DES PARAM√àTRES ===
                st.markdown("### ‚öôÔ∏è Interpr√©tation de tes Param√®tres")

                col1, col2, col3 = st.columns(3)

                with col1:
                    # Analyse k1
                    if k1 < 1.0:
                        k1_interpretation = "**Saturation rapide** üöÄ (anti-spam)"
                        k1_color = "üü¢"
                    elif k1 < 1.8:
                        k1_interpretation = "**Standard** ‚≠ê (√©quilibr√©)"
                        k1_color = "üü°"
                    else:
                        k1_interpretation = (
                            "**Saturation lente** üêå (favorise r√©p√©titions)"
                        )
                        k1_color = "üî¥"

                    st.info(f"""
                    **k1 = {k1}** {k1_color}

                    {k1_interpretation}

                    Impact: Les mots plafonnent apr√®s ~{int(k1 * 10)} occurrences
                    """)

                with col2:
                    # Analyse b
                    if b < 0.5:
                        b_interpretation = (
                            "**Faible normalisation** (favorise docs longs)"
                        )
                        b_color = "üü¢"
                    elif b < 0.85:
                        b_interpretation = "**Normalisation standard** ‚≠ê"
                        b_color = "üü°"
                    else:
                        b_interpretation = (
                            "**Forte normalisation** (p√©nalise docs longs)"
                        )
                        b_color = "üî¥"

                    st.info(f"""
                    **b = {b}** {b_color}

                    {b_interpretation}

                    avgdl = {bm25_engine.avgdl:.1f} mots
                    """)

                with col3:
                    # Stats query
                    query_words = query.lower().split()
                    st.info(f"""
                    **Query:** {len(query_words)} mots

                    Mots: {", ".join(query_words[:3])}{"..." if len(query_words) > 3 else ""}

                    Corpus: {len(documents_texts)} docs
                    """)

                st.divider()

                # === VISUALISATION R√âSULTATS ===
                st.markdown("### üìä Visualisation des Scores")

                col_g1, col_g2 = st.columns(2)

                with col_g1:
                    fig_results = plot_search_results(results, documents_titles, query)
                    st.pyplot(fig_results)

                with col_g2:
                    st.markdown("### üìà Analyse des Scores")

                    all_scores = [score for _, score in results]
                    max_score = max(all_scores)
                    min_score = min(all_scores)
                    avg_score = np.mean(all_scores)

                    st.markdown(f"""
                    **Statistiques:**
                    - ü•á Score max: **{max_score:.4f}**
                    - ü•â Score min: **{min_score:.4f}**
                    - üìä Score moyen: **{avg_score:.4f}**
                    - üìè √âcart: **{(max_score - min_score):.4f}**

                    **Observations:**
                    """)

                    # Analyses automatiques
                    if max_score > avg_score * 3:
                        st.success(
                            "‚úÖ **Excellente s√©paration!** Le meilleur r√©sultat se d√©marque clairement."
                        )
                    elif max_score > avg_score * 1.5:
                        st.info(
                            "üí° **Bonne s√©paration.** Les r√©sultats sont bien diff√©renci√©s."
                        )
                    else:
                        st.warning(
                            "‚ö†Ô∏è **Faible s√©paration.** Les documents ont des scores similaires. Essaie de modifier k1 ou b."
                        )

                    if min_score < 0.1:
                        st.info(
                            "üìâ Les derniers r√©sultats ont des scores tr√®s faibles (< 0.1). Ils contiennent peu de mots de ta query."
                        )

                # === R√âSULTATS D√âTAILL√âS ===
                st.markdown("### üéØ Top R√©sultats D√©taill√©s")

                for rank, (doc_idx, score) in enumerate(results[:5], 1):
                    # Calcul du pourcentage par rapport au max
                    score_pct = (score / max_score * 100) if max_score > 0 else 0

                    with st.expander(
                        f"#{rank} - {documents_titles[doc_idx]} | BM25: {score:.3f} ({score_pct:.0f}%)"
                    ):
                        st.caption(f"üìÇ Cat√©gorie: {documents_categories[doc_idx]}")
                        st.write(documents_texts[doc_idx][:300] + "...")

                        # Info sur la longueur du doc
                        doc_length = len(documents_texts[doc_idx].split())
                        length_ratio = doc_length / bm25_engine.avgdl

                        col_info1, col_info2, col_info3 = st.columns(3)

                        with col_info1:
                            st.metric("Longueur", f"{doc_length} mots")
                        with col_info2:
                            st.metric("vs. Moyenne", f"{length_ratio:.2f}√ó")
                        with col_info3:
                            if length_ratio > 1.5:
                                st.metric("Type", "Long üìú")
                            elif length_ratio < 0.7:
                                st.metric("Type", "Court üìã")
                            else:
                                st.metric("Type", "Moyen üìÑ")

                        if st.checkbox(
                            f"üîç Voir calcul d√©taill√© #{rank}",
                            key=f"bm25_explain_{rank}",
                        ):
                            explanation = bm25_engine.explain(query, doc_idx)

                            st.markdown("""
                            #### üìê D√©tails du Calcul BM25
                            """)

                            # Afficher les valeurs cl√©s
                            col1, col2, col3 = st.columns(3)

                            with col1:
                                st.metric(
                                    "avgdl (corpus)", f"{explanation['avgdl']:.1f} mots"
                                )
                            with col2:
                                st.metric(
                                    "Longueur doc", f"{explanation['doc_length']} mots"
                                )
                            with col3:
                                st.metric(
                                    "Facteur norm", f"{explanation['norm_factor']:.3f}"
                                )

                            st.markdown(f"""
                            **Interpr√©tation du facteur de normalisation:**
                            - Valeur: **{explanation["norm_factor"]:.3f}**
                            - Si > 1: Document **p√©nalis√©** (plus long que la moyenne)
                            - Si = 1: Document de longueur **moyenne**
                            - Si < 1: Document **boost√©** (plus court que la moyenne)

                            **Score final BM25:** **{explanation["total_score"]:.4f}**
                            """)


def render_bm25_exploration(documents_texts, documents_titles, remove_stopwords):
    """Exploration & Tuning BM25"""
    st.header("üìä Exploration & Tuning des Param√®tres")

    st.markdown("""
    ### üéõÔ∏è Laboratoire de Tuning BM25

    Explore l'impact des param√®tres k1 et b sur les scores!
    """)

    # S√©lection document
    doc_idx = st.selectbox(
        "Choisis un document:",
        range(min(20, len(documents_titles))),
        format_func=lambda x: documents_titles[x],
    )

    test_query = st.text_input(
        "Query de test:",
        value="recette cuisine",
        key="bm25_tuning_query",
        help='üí° Exemples: "plat italien" | "cuisine asiatique" | "dessert chocolat"',
    )

    if test_query:
        with st.spinner("üß™ G√©n√©ration de la heatmap..."):
            bm25_engine = BM25Engine(documents_texts, remove_stopwords=remove_stopwords)

            fig_heatmap = plot_parameter_space_heatmap(
                bm25_engine,
                test_query,
                doc_idx,
                k1_range=(0.5, 3.0),
                b_range=(0.0, 1.0),
                resolution=15,
            )

            st.plotly_chart(fig_heatmap, use_container_width=True)

            st.info("""
            üí° **Interpr√©tation:**
            - Zones **rouges** = scores √©lev√©s
            - ‚≠ê **√âtoile blanche** = param√®tres standard (k1=1.5, b=0.75)
            - Explore l'espace pour voir l'impact!
            """)


def render_bm25_stepbystep(documents_texts, documents_titles, remove_stopwords):
    """Exemple pas-√†-pas BM25 - HYPER D√âTAILL√â"""
    st.header("üéì Calcul BM25 Pas-√†-Pas (Exemple Complet)")

    st.markdown("""
    Suivons **TOUTES les √©tapes** du calcul BM25, de A √† Z, avec des **exemples concrets**!

    On va d√©cortiquer chaque formule et voir comment BM25 classe les documents.
    """)

    # === S√âLECTION DOCUMENTS ===
    st.markdown("## üìÑ Documents d'Exemple")

    sample_indices = list(range(min(3, len(documents_texts))))
    sample_texts = [documents_texts[i] for i in sample_indices]
    sample_titles = [documents_titles[i] for i in sample_indices]

    for idx, (title, text) in enumerate(zip(sample_titles, sample_texts)):
        with st.expander(f"üìÑ **Document {idx + 1}:** {title}"):
            st.write(text)
            st.caption(f"Longueur: {len(text.split())} mots")

    st.divider()

    # === QUERY ===
    query = st.text_input(
        "üîé Entre ta Query:",
        value="italien fromage",
        key="bm25_tutorial",
        help='üí° Teste avec: "italien fromage" | "chocolat dessert" | "poisson grill√©" | "asiatique √©pic√©"',
    )

    if query:
        # === PARAM√àTRES ===
        st.markdown("## ‚öôÔ∏è Param√®tres BM25")

        col1, col2 = st.columns(2)
        with col1:
            k1_tutorial = st.number_input(
                "k1 (saturation):",
                min_value=0.0,
                max_value=3.0,
                value=1.5,
                step=0.1,
                key="bm25_tutorial_k1",
                help="Contr√¥le la saturation du TF. Standard = 1.5",
            )
        with col2:
            b_tutorial = st.number_input(
                "b (normalisation):",
                min_value=0.0,
                max_value=1.0,
                value=0.75,
                step=0.05,
                key="bm25_tutorial_b",
                help="Contr√¥le la p√©nalit√© de longueur. Standard = 0.75",
            )

        st.divider()

        # Cr√©er l'engine BM25
        mini_bm25 = BM25Engine(
            sample_texts,
            k1=k1_tutorial,
            b=b_tutorial,
            remove_stopwords=remove_stopwords,
        )

        # Preprocessing de la query
        from src.preprocessing import preprocess_text

        query_words = preprocess_text(query, remove_stopwords=remove_stopwords)

        # === √âTAPE 0: STATS CORPUS ===
        with st.expander("**üìä √âtape 0: Statistiques du Mini-Corpus**", expanded=False):
            st.markdown("""
            ### Avant de calculer BM25, analysons notre corpus!
            """)

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("Nombre de documents (N)", mini_bm25.N)
            with col2:
                st.metric("Vocabulaire", len(mini_bm25.vocabulary))
            with col3:
                st.metric("Longueur moyenne (avgdl)", f"{mini_bm25.avgdl:.1f} mots")

            # Tableau des longueurs
            lengths_data = []
            for idx, text in enumerate(sample_texts):
                doc_length = len(text.split())
                ratio = doc_length / mini_bm25.avgdl
                lengths_data.append(
                    {
                        "Document": sample_titles[idx][:30],
                        "Longueur": doc_length,
                        "vs. Moyenne": f"{ratio:.2f}√ó",
                    }
                )

            df_lengths = pd.DataFrame(lengths_data)
            st.dataframe(df_lengths, use_container_width=True)

            st.info(f"""
            üí° **avgdl** est crucial pour BM25! Les documents plus longs que {mini_bm25.avgdl:.1f} mots seront p√©nalis√©s (si b > 0).
            """)

        # === √âTAPE 1: IDF ===
        with st.expander(
            "**üìâ √âtape 1: Calcul des IDF (Inverse Document Frequency)**",
            expanded=False,
        ):
            st.markdown("""
            ### Formule BM25 IDF (avec smoothing)
            """)

            st.latex(
                r"\text{IDF}(t) = \log\left(\frac{N - n(t) + 0.5}{n(t) + 0.5}\right)"
            )

            st.markdown(
                """
            O√π:
            - **N** = nombre total de documents (ici: {})
            - **n(t)** = nombre de docs contenant le terme t
            - **+0.5** = smoothing de Laplace
            """.format(mini_bm25.N)
            )

            # Calculer IDF pour chaque mot de la query
            idf_data = []
            for word in query_words:
                if word in mini_bm25.word_to_idx:
                    idx = mini_bm25.word_to_idx[word]
                    n_t = mini_bm25.doc_count[idx]
                    idf = np.log((mini_bm25.N - n_t + 0.5) / (n_t + 0.5))

                    idf_data.append(
                        {
                            "Mot": word,
                            "n(t)": n_t,
                            "Calcul": f"log(({mini_bm25.N} - {n_t} + 0.5) / ({n_t} + 0.5))",
                            "IDF": f"{idf:.4f}",
                        }
                    )
                else:
                    idf_data.append(
                        {"Mot": word, "n(t)": 0, "Calcul": "Mot absent", "IDF": "N/A"}
                    )

            df_idf = pd.DataFrame(idf_data)
            st.dataframe(df_idf, use_container_width=True)

            st.markdown("""
            ### üí° Interpr√©tation

            - **IDF √©lev√©** ‚Üí Mot rare ‚Üí Plus important!
            - **IDF faible** ‚Üí Mot commun ‚Üí Moins important
            - Le smoothing (+0.5) √©vite les divisions par z√©ro et stabilise les valeurs
            """)

        # === √âTAPE 2: FR√âQUENCES ===
        with st.expander("**üî¢ √âtape 2: Comptage des Fr√©quences**", expanded=False):
            st.markdown("""
            ### Comptons combien de fois chaque mot de la query appara√Æt dans chaque document!
            """)

            freq_data = []
            for doc_idx, text in enumerate(sample_texts):
                row = {"Document": sample_titles[doc_idx][:30]}
                doc_words = preprocess_text(text, remove_stopwords=remove_stopwords)

                for word in query_words:
                    count = doc_words.count(word)
                    row[word] = count

                freq_data.append(row)

            df_freq = pd.DataFrame(freq_data)
            st.dataframe(df_freq, use_container_width=True)

            st.info("""
            üìå **Note:** Ce sont les fr√©quences brutes (nombre d'occurrences).
            BM25 va les **saturer** avec le param√®tre k1!
            """)

        # === √âTAPE 3: NORMALISATION ===
        with st.expander("**‚öñÔ∏è √âtape 3: Facteurs de Normalisation**", expanded=False):
            st.markdown("""
            ### Formule de Normalisation
            """)

            st.latex(r"\text{norm}(D) = 1 - b + b \times \frac{|D|}{\text{avgdl}}")

            st.markdown(f"""
            Param√®tres:
            - **b** = {b_tutorial} (intensit√© de la p√©nalit√©)
            - **avgdl** = {mini_bm25.avgdl:.1f} mots
            """)

            norm_data = []
            for doc_idx, text in enumerate(sample_texts):
                doc_length = len(text.split())
                norm_factor = (
                    1 - b_tutorial + b_tutorial * (doc_length / mini_bm25.avgdl)
                )

                norm_data.append(
                    {
                        "Document": sample_titles[doc_idx][:30],
                        "|D| (longueur)": doc_length,
                        "Calcul": f"1 - {b_tutorial} + {b_tutorial} √ó ({doc_length}/{mini_bm25.avgdl:.1f})",
                        "Facteur norm": f"{norm_factor:.3f}",
                    }
                )

            df_norm = pd.DataFrame(norm_data)
            st.dataframe(df_norm, use_container_width=True)

            st.markdown("""
            ### üí° Interpr√©tation

            - **norm > 1** ‚Üí Document **p√©nalis√©** (plus long que la moyenne)
            - **norm = 1** ‚Üí Document de longueur moyenne
            - **norm < 1** ‚Üí Document **boost√©** (plus court que la moyenne)

            Ce facteur sera utilis√© dans le d√©nominateur de BM25!
            """)

        # === √âTAPE 4: TF SATUR√â ===
        with st.expander("**üéõÔ∏è √âtape 4: TF Satur√© (avec k1)**", expanded=False):
            st.markdown("""
            ### Formule du TF Satur√© BM25
            """)

            st.latex(
                r"\text{TF}_{\text{BM25}} = \frac{f \times (k1 + 1)}{f + k1 \times \text{norm}}"
            )

            st.markdown(f"""
            O√π:
            - **f** = fr√©quence du mot dans le doc
            - **k1** = {k1_tutorial} (contr√¥le la saturation)
            - **norm** = facteur de normalisation (calcul√© √† l'√©tape 3)
            """)

            # Calculer TF satur√© pour chaque mot dans chaque doc
            tf_data = []
            for doc_idx, text in enumerate(sample_texts):
                doc_words = preprocess_text(text, remove_stopwords=remove_stopwords)
                doc_length = len(text.split())
                norm_factor = (
                    1 - b_tutorial + b_tutorial * (doc_length / mini_bm25.avgdl)
                )

                row = {"Document": sample_titles[doc_idx][:30]}

                for word in query_words:
                    f = doc_words.count(word)
                    tf_bm25 = (f * (k1_tutorial + 1)) / (f + k1_tutorial * norm_factor)
                    row[f"{word} (f={f})"] = f"{tf_bm25:.4f}"

                tf_data.append(row)

            df_tf = pd.DataFrame(tf_data)
            st.dataframe(df_tf, use_container_width=True)

            st.markdown("""
            ### üí° Observation Cl√©

            Contrairement √† TF-IDF (o√π TF = f/longueur), ici le TF **plafonne**!

            - Si f = 0 ‚Üí TF = 0
            - Si f = 1 ‚Üí TF ‚âà 1.0
            - Si f = 10 ‚Üí TF ‚âà 1.3 (saturation!)
            - Si f = 100 ‚Üí TF ‚âà 1.5 (plateau atteint!)

            **C'est le c≈ìur de BM25!** üéØ
            """)

        # === √âTAPE 5: BM25 FINAL ===
        with st.expander("**üéØ √âtape 5: Score BM25 Final (IDF √ó TF)**", expanded=False):
            st.markdown("""
            ### Formule Compl√®te BM25
            """)

            st.latex(r"""
            \text{BM25}(D) = \sum_{t \in Q} \text{IDF}(t) \times \frac{f(t, D) \times (k1 + 1)}{f(t, D) + k1 \times \text{norm}(D)}
            """)

            st.markdown("""
            On **multiplie IDF √ó TF** pour chaque mot, puis on **additionne**!
            """)

            # Calculer BM25 complet
            bm25_data = []
            for doc_idx, text in enumerate(sample_texts):
                doc_words = preprocess_text(text, remove_stopwords=remove_stopwords)
                doc_length = len(text.split())
                norm_factor = (
                    1 - b_tutorial + b_tutorial * (doc_length / mini_bm25.avgdl)
                )

                total_score = 0
                details = []

                for word in query_words:
                    if word in mini_bm25.word_to_idx:
                        idx = mini_bm25.word_to_idx[word]

                        # IDF
                        n_t = mini_bm25.doc_count[idx]
                        idf = np.log((mini_bm25.N - n_t + 0.5) / (n_t + 0.5))

                        # TF satur√©
                        f = doc_words.count(word)
                        tf = (f * (k1_tutorial + 1)) / (f + k1_tutorial * norm_factor)

                        # Score du mot
                        word_score = idf * tf
                        total_score += word_score

                        details.append(
                            f"{word}: {idf:.3f} √ó {tf:.3f} = {word_score:.4f}"
                        )

                bm25_data.append(
                    {
                        "Document": sample_titles[doc_idx][:30],
                        "D√©tail": " + ".join(details)
                        if details
                        else "Aucun mot trouv√©",
                        "Score BM25": f"{total_score:.4f}",
                    }
                )

            df_bm25 = pd.DataFrame(bm25_data)
            st.dataframe(df_bm25, use_container_width=True, height=200)

            st.success("""
            ‚úÖ **Voil√† le score BM25 final!**
            Plus le score est √©lev√©, plus le document est pertinent pour la query.
            """)

        # === √âTAPE 6: CLASSEMENT ===
        with st.expander("**üèÜ √âtape 6: Classement Final**", expanded=True):
            st.markdown("""
            ### Classement par Score BM25 D√©croissant
            """)

            results = mini_bm25.search(query, top_k=3)

            if len(results) == 0:
                st.warning("üòï Aucun r√©sultat trouv√©!")
            else:
                for rank, (doc_idx, score) in enumerate(results, 1):
                    if rank == 1:
                        medal = "ü•á"
                    elif rank == 2:
                        medal = "ü•à"
                    else:
                        medal = "ü•â"

                    st.markdown(f"""
                    {medal} **#{rank} - {sample_titles[doc_idx]}**
                    Score BM25: **{score:.4f}**
                    """)

                    # Snippet
                    st.caption(sample_texts[doc_idx][:150] + "...")

                st.divider()

                st.markdown("""
                ### üéì Conclusion

                Nous avons calcul√© BM25 **de A √† Z**:

                1. ‚úÖ **IDF** avec smoothing (raret√© des mots)
                2. ‚úÖ **Fr√©quences** brutes (comptage)
                3. ‚úÖ **Normalisation** par longueur (facteur b)
                4. ‚úÖ **TF satur√©** (effet de plateau k1)
                5. ‚úÖ **Multiplication** IDF √ó TF pour chaque mot
                6. ‚úÖ **Classement** des documents

                **BM25 > TF-IDF** car il √©vite la saturation lin√©aire et permet de tuner les param√®tres! üöÄ
                """)


def render_bm25_comparison(
    documents_texts, documents_titles, tfidf_engine, remove_stopwords
):
    """Comparaison TF-IDF vs BM25 - ENRICHIE"""
    st.header("‚öîÔ∏è TF-IDF vs BM25: Le Duel!")

    st.markdown("""
    ### üéØ Objectif

    Comparons les **deux algorithmes** sur la **m√™me requ√™te** pour voir:
    - Quels documents sont retrouv√©s par chacun
    - Comment les scores diff√®rent
    - Quel algorithme performe mieux
    """)

    query_compare = st.text_input(
        "üîé Requ√™te de comparaison:",
        value="recette italienne p√¢tes fromage",
        key="compare_query",
        help="üí° Teste avec plusieurs mots pour voir la diff√©rence!",
    )

    top_k_compare = st.slider("Nombre de r√©sultats:", 5, 20, 10, key="compare_topk")

    if query_compare and st.button(
        "‚öîÔ∏è Lancer la Comparaison!", type="primary", key="compare_btn"
    ):
        with st.spinner("‚öîÔ∏è Comparaison en cours..."):
            import time

            start_tfidf = time.time()
            tfidf_results = tfidf_engine.search(query_compare, top_k=top_k_compare)
            time_tfidf = (time.time() - start_tfidf) * 1000  # ms

            start_bm25 = time.time()
            bm25_engine = BM25Engine(
                documents_texts, k1=1.5, b=0.75, remove_stopwords=remove_stopwords
            )
            bm25_results = bm25_engine.search(query_compare, top_k=top_k_compare)
            time_bm25 = (time.time() - start_bm25) * 1000  # ms

            # === M√âTRIQUES RAPIDES ===
            st.markdown("## üìä M√©triques Globales")

            col1, col2, col3, col4 = st.columns(4)

            tfidf_indices = set([idx for idx, _ in tfidf_results])
            bm25_indices = set([idx for idx, _ in bm25_results])
            overlap = len(tfidf_indices.intersection(bm25_indices))

            col1.metric("‚è±Ô∏è TF-IDF", f"{time_tfidf:.2f} ms")
            col2.metric("‚è±Ô∏è BM25", f"{time_bm25:.2f} ms")
            col3.metric(
                "üìä Overlap",
                f"{overlap}/{top_k_compare}",
                f"{(overlap / top_k_compare * 100):.0f}%",
            )
            col4.metric(
                "üéØ Concordance",
                "√âlev√©e"
                if overlap > top_k_compare * 0.7
                else "Moyenne"
                if overlap > top_k_compare * 0.4
                else "Faible",
            )

            st.divider()

            # === VISUALISATION COMPARATIVE ===
            st.markdown("## üìà Comparaison Visuelle des Scores")

            col_g1, col_g2 = st.columns(2)

            with col_g1:
                fig_comp = plot_tfidf_bm25_comparison(
                    tfidf_results,
                    bm25_results,
                    documents_titles,
                    query_compare,
                    top_k=top_k_compare,
                )
                st.pyplot(fig_comp)

            with col_g2:
                st.markdown("### üìä Analyse du Graphique")

                # Analyses statistiques
                tfidf_scores = [score for _, score in tfidf_results]
                bm25_scores = [score for _, score in bm25_results]

                tfidf_max = max(tfidf_scores)
                bm25_max = max(bm25_scores)
                tfidf_range = max(tfidf_scores) - min(tfidf_scores)
                bm25_range = max(bm25_scores) - min(bm25_scores)

                st.markdown(f"""
                **TF-IDF:**
                - Score max: **{tfidf_max:.4f}**
                - √âcart: **{tfidf_range:.4f}**

                **BM25:**
                - Score max: **{bm25_max:.4f}**
                - √âcart: **{bm25_range:.4f}**

                **Observations:**
                """)

                if bm25_range > tfidf_range * 1.2:
                    st.success(
                        "‚úÖ **BM25 a une meilleure s√©paration** des scores! Les r√©sultats sont plus diff√©renci√©s."
                    )
                elif tfidf_range > bm25_range * 1.2:
                    st.info(
                        "üí° **TF-IDF a une meilleure s√©paration** pour cette query."
                    )
                else:
                    st.info("üí° **S√©paration similaire** entre les deux algorithmes.")

            st.divider()

            # === ANALYSE DES DIFF√âRENCES ===
            st.markdown("## üîç Analyse des Diff√©rences")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### üî¥ Uniques √† TF-IDF")
                tfidf_unique = tfidf_indices - bm25_indices
                if len(tfidf_unique) > 0:
                    for idx in list(tfidf_unique)[:3]:
                        tfidf_score = next(
                            score for doc_idx, score in tfidf_results if doc_idx == idx
                        )
                        st.markdown(
                            f"- **{documents_titles[idx][:40]}** (score: {tfidf_score:.4f})"
                        )
                    st.caption(f"Total: {len(tfidf_unique)} documents uniques")
                else:
                    st.info("Aucun document unique!")

            with col2:
                st.markdown("### üü¢ Uniques √† BM25")
                bm25_unique = bm25_indices - tfidf_indices
                if len(bm25_unique) > 0:
                    for idx in list(bm25_unique)[:3]:
                        bm25_score = next(
                            score for doc_idx, score in bm25_results if doc_idx == idx
                        )
                        st.markdown(
                            f"- **{documents_titles[idx][:40]}** (score: {bm25_score:.4f})"
                        )
                    st.caption(f"Total: {len(bm25_unique)} documents uniques")
                else:
                    st.info("Aucun document unique!")

            st.divider()

            # === DISTRIBUTION DES SCORES ===
            st.markdown("## üìä Distribution des Scores")

            col_dist1, col_dist2 = st.columns(2)

            with col_dist1:
                fig_dist = plot_score_distributions(tfidf_scores, bm25_scores)
                st.pyplot(fig_dist)

            with col_dist2:
                st.markdown("### üìà Interpr√©tation")

                st.markdown("""
                **Histogrammes:**
                - Montrent la **r√©partition** des scores
                - TF-IDF (rouge) vs BM25 (vert)

                **Id√©al:**
                - Distribution **√©tal√©e** (bonne s√©paration)
                - Pic √† gauche (faibles scores)
                - Queue √† droite (bons r√©sultats)
                """)

                # Calcul de la variance pour mesurer la dispersion
                import numpy as np

                var_tfidf = np.var(tfidf_scores)
                var_bm25 = np.var(bm25_scores)

                if var_bm25 > var_tfidf * 1.2:
                    st.success(
                        "‚úÖ **BM25 a une meilleure dispersion** ‚Üí R√©sultats plus diff√©renci√©s"
                    )
                elif var_tfidf > var_bm25 * 1.2:
                    st.info("üí° **TF-IDF a une meilleure dispersion** pour cette query")
                else:
                    st.info("üí° **Dispersion similaire**")

            st.divider()

            # === CONCLUSION ===
            st.markdown("## üéì Conclusion")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                ### üî¥ TF-IDF

                **Avantages:**
                - ‚úÖ Simple √† comprendre
                - ‚úÖ Rapide √† calculer
                - ‚úÖ Pas de param√®tres

                **Inconv√©nients:**
                - ‚ùå Saturation lin√©aire
                - ‚ùå Normalisation rigide
                - ‚ùå Pas ajustable
                """)

            with col2:
                st.markdown("""
                ### üü¢ BM25

                **Avantages:**
                - ‚úÖ Saturation intelligente (k1)
                - ‚úÖ Normalisation ajustable (b)
                - ‚úÖ IDF am√©lior√© (smoothing)
                - ‚úÖ Standard industriel

                **Inconv√©nients:**
                - ‚ö†Ô∏è L√©g√®rement plus complexe
                - ‚ö†Ô∏è N√©cessite tuning des param√®tres
                """)

            overlap_pct = (overlap / top_k_compare) * 100
            if overlap_pct > 70:
                st.success(f"""
                ‚úÖ **Accord √©lev√© ({overlap_pct:.0f}%):** Les deux algorithmes sont coh√©rents!
                BM25 apporte surtout une **meilleure s√©paration** des scores.
                """)
            elif overlap_pct > 40:
                st.info(f"""
                üí° **Accord mod√©r√© ({overlap_pct:.0f}%):** Les algorithmes diff√®rent!
                BM25 trouve des documents que TF-IDF manque (et vice-versa).
                """)
            else:
                st.warning(f"""
                ‚ö†Ô∏è **Accord faible ({overlap_pct:.0f}%):** R√©sultats tr√®s diff√©rents!
                Cela peut indiquer que **BM25 est plus adapt√©** √† ce corpus.
                """)


def render_bm25_performance(documents_texts, remove_stopwords):
    """Performance BM25 - HYPER D√âTAILL√âE"""
    st.header("‚ö° Performances BM25: Analyse Compl√®te")

    st.markdown("""
    Analysons en profondeur les **performances de BM25** et comparons-les avec TF-IDF!
    """)

    # === COMPLEXIT√â ALGORITHMIQUE ===
    st.markdown("## üßÆ Complexit√© Algorithmique")

    st.markdown("""
    **Question importante:** BM25 est-il plus lent que TF-IDF? ü§î
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.info("""
        ### üî¥ TF-IDF

        **Preprocessing (indexation):**
        - Compter les mots: O(n √ó m)
        - Calculer IDF: O(v)
        - Calculer TF-IDF: O(n √ó v)

        **Recherche:**
        - Vectoriser query: O(|q|)
        - Cosine similarity: O(n √ó v)

        **Total:** O(n √ó m + n √ó v)
        """)

    with col2:
        st.success("""
        ### üü¢ BM25

        **Preprocessing (indexation):**
        - Compter les mots: O(n √ó m)
        - Calculer avgdl: O(n)
        - Calculer IDF: O(v)

        **Recherche:**
        - Calculer BM25: O(n √ó |q|)

        **Total:** O(n √ó m + n √ó |q|)

        ‚úÖ **Identique!**
        """)

    st.markdown("""
    ### üí° Pourquoi M√™me Complexit√©?

    Les calculs suppl√©mentaires de BM25 sont en **O(1)** par terme:
    - **norm_factor** = `1 - b + b √ó (|D| / avgdl)` ‚Üí **O(1)**
    - **TF satur√©** = `f √ó (k1 + 1) / (f + k1 √ó norm)` ‚Üí **O(1)**

    Ces multiplications/divisions sont **n√©gligeables** par rapport au comptage des mots!

    **Conclusion:** BM25 n'est **PAS** plus lent que TF-IDF en pratique! üöÄ
    """)

    st.divider()

    # === M√âTRIQUES DU CORPUS ACTUEL ===
    st.markdown("## üìä M√©triques du Corpus Actuel")

    import time

    # Mesurer le temps de chargement
    start_load = time.time()
    n_docs = len(documents_texts)
    total_words = sum(len(doc.split()) for doc in documents_texts)
    avg_length = total_words / n_docs if n_docs > 0 else 0
    time_load = (time.time() - start_load) * 1000

    # Mesurer l'indexation BM25
    start_index = time.time()
    bm25_engine = BM25Engine(
        documents_texts, k1=1.5, b=0.75, remove_stopwords=remove_stopwords
    )
    time_index = (time.time() - start_index) * 1000

    vocab_size = len(bm25_engine.vocabulary)

    col1, col2, col3, col4 = st.columns(4)

    col1.metric("üìö Documents", f"{n_docs:,}")
    col2.metric("üìñ Vocabulaire", f"{vocab_size:,}")
    col3.metric("üìè Longueur moy.", f"{avg_length:.1f} mots")
    col4.metric("üí¨ Total mots", f"{total_words:,}")

    st.divider()

    col_t1, col_t2, col_t3 = st.columns(3)

    col_t1.metric("‚è±Ô∏è Chargement", f"{time_load:.2f} ms")
    col_t2.metric("‚è±Ô∏è Indexation BM25", f"{time_index:.2f} ms")

    # Efficacit√©
    docs_per_sec = (n_docs / time_index * 1000) if time_index > 0 else 0
    if docs_per_sec > 1000:
        efficiency = "Ultra rapide! üöÄ"
        col_t3.metric("üöÄ Efficacit√©", f"{docs_per_sec:.0f} docs/s", delta="Excellent")
    elif docs_per_sec > 100:
        efficiency = "Rapide! ‚úÖ"
        col_t3.metric("‚ö° Efficacit√©", f"{docs_per_sec:.0f} docs/s", delta="Bon")
    else:
        efficiency = "Lent... ‚ö†Ô∏è"
        col_t3.metric("üêå Efficacit√©", f"{docs_per_sec:.0f} docs/s", delta="Am√©liorer")

    st.info(f"""
    üí° **Interpr√©tation:** {efficiency}
    BM25 a index√© {n_docs:,} documents en **{time_index:.2f} ms** ({docs_per_sec:.0f} docs/s).
    """)

    st.divider()

    # === EXPLICATION COMPLEXIT√â ===
    st.markdown("## üìñ Comprendre la Complexit√© O(n √ó m)")

    st.markdown("""
    ### Que signifient **n** et **m**?

    - **n** = nombre de documents dans le corpus
    - **m** = longueur moyenne d'un document (en mots)
    - **v** = taille du vocabulaire (mots uniques)
    - **|q|** = longueur de la query
    """)

    st.markdown(f"""
    ### Pour ton corpus actuel:

    - **n** = {n_docs:,} documents
    - **m** = {avg_length:.0f} mots/doc (moyenne)
    - **v** = {vocab_size:,} mots uniques

    **Complexit√© d'indexation:** O({n_docs:,} √ó {avg_length:.0f}) = O({n_docs * avg_length:,.0f}) op√©rations
    """)

    with st.expander("üîç Voir le D√©tail des Op√©rations"):
        st.markdown(f"""
        ### √âtapes de l'Indexation BM25

        **1. Tokenisation (parcourir tous les mots):**
        - {n_docs:,} docs √ó {avg_length:.0f} mots = **{n_docs * avg_length:,.0f} mots** √† traiter
        - Complexit√©: **O(n √ó m)**

        **2. Construction du vocabulaire:**
        - Ajouter chaque mot unique dans un dictionnaire
        - Complexit√©: **O(n √ó m)** (pire cas)
        - R√©sultat: **{vocab_size:,} mots uniques**

        **3. Calcul de avgdl (longueur moyenne):**
        - Somme des longueurs / nombre de docs
        - Complexit√©: **O(n)**
        - R√©sultat: **avgdl = {bm25_engine.avgdl:.1f} mots**

        **4. Comptage des documents contenant chaque mot (pour IDF):**
        - Pour chaque mot, compter dans combien de docs il appara√Æt
        - Complexit√©: **O(n √ó v)** (pire cas)

        **Total:** O(n √ó m + n √ó v) ‚âà **O(n √ó m)** (car g√©n√©ralement m > v pour un doc)
        """)

    st.markdown(r"""
    ### üìà Impact de Doubler n ou m

    | Action | Impact sur Temps | Exemple |
    |--------|------------------|---------|
    | **n √ó 2** (doubler les docs) | **Temps √ó 2** | 1000 ‚Üí 2000 docs |
    | **m √ó 2** (docs 2√ó plus longs) | **Temps √ó 2** | 100 ‚Üí 200 mots/doc |
    | **v √ó 2** (vocabulaire 2√ó plus grand) | Impact faible | 5000 ‚Üí 10000 mots |
    | **\|q\| √ó 2** (query 2√ó plus longue) | Impact faible (recherche only) | 3 ‚Üí 6 mots |

    **Conclusion:** Le nombre de documents **n** et leur longueur **m** sont les facteurs cl√©s!
    """)

    st.divider()

    # === BENCHMARKS AUTOMATIQUES ===
    st.markdown("## üèÅ Benchmarks Automatiques Multi-Datasets")

    st.markdown("""
    Testons BM25 sur **diff√©rents datasets** pour voir l'impact de la taille du corpus!
    """)

    if st.button("üöÄ Lancer les Benchmarks!", type="primary", key="bm25_bench_btn"):
        with st.spinner("‚è≥ Benchmarks en cours... (peut prendre quelques secondes)"):
            from src.data_loader import load_dataset

            benchmark_results = []

            # D√©finir les datasets √† tester (petits √©chantillons)
            test_configs = [
                ("recettes", False, 50),
                ("films", False, 50),
                ("wikipedia", False, 200),
                ("recettes", True, None),  # Version √©tendue
            ]

            for dataset_name, extended, sample_size in test_configs:
                try:
                    # Charger le dataset
                    start = time.time()
                    dataset = load_dataset(
                        dataset_name, extended=extended, sample_size=sample_size
                    )
                    time_load_bench = (time.time() - start) * 1000

                    if len(dataset) == 0:
                        continue

                    texts = [doc["text"] for doc in dataset]
                    n_bench = len(texts)

                    # Indexation BM25
                    start = time.time()
                    bm25_bench = BM25Engine(
                        texts, k1=1.5, b=0.75, remove_stopwords=remove_stopwords
                    )
                    time_index_bench = (time.time() - start) * 1000

                    # Recherche test
                    test_query = "italien fromage"
                    start = time.time()
                    _ = bm25_bench.search(test_query, top_k=10)
                    time_search = (time.time() - start) * 1000

                    vocab_bench = len(bm25_bench.vocabulary)

                    benchmark_results.append(
                        {
                            "Dataset": f"{dataset_name} {'(√©tendu)' if extended else ''}",
                            "Docs": n_bench,
                            "Vocabulaire": vocab_bench,
                            "Load (ms)": f"{time_load_bench:.2f}",
                            "Index (ms)": f"{time_index_bench:.2f}",
                            "Search (ms)": f"{time_search:.2f}",
                            "Total (ms)": f"{(time_load_bench + time_index_bench + time_search):.2f}",
                        }
                    )

                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erreur avec {dataset_name}: {str(e)}")
                    continue

            if len(benchmark_results) > 0:
                # Afficher les r√©sultats
                st.markdown("### üìä R√©sultats des Benchmarks")

                df_bench = pd.DataFrame(benchmark_results)
                st.dataframe(df_bench, use_container_width=True)

                # Analyse automatique
                st.markdown("### üìà Analyse des R√©sultats")

                # Graphique: Temps d'indexation vs nombre de docs
                import matplotlib.pyplot as plt

                docs_list = [int(r["Docs"]) for r in benchmark_results]
                index_times = [float(r["Index (ms)"]) for r in benchmark_results]

                col_plot1, col_plot2 = st.columns(2)

                with col_plot1:
                    fig, ax = plt.subplots(figsize=(6, 4))
                    ax.scatter(docs_list, index_times, s=100, alpha=0.7, color="green")
                    ax.plot(docs_list, index_times, "--", alpha=0.5, color="green")
                    ax.set_xlabel("Nombre de Documents", fontsize=11)
                    ax.set_ylabel("Temps d'Indexation (ms)", fontsize=11)
                    ax.set_title(
                        "BM25: Temps vs Nombre de Docs", fontsize=12, fontweight="bold"
                    )
                    ax.grid(True, alpha=0.3)
                    st.pyplot(fig)
                    plt.close()

                with col_plot2:
                    st.markdown("### üìä Observations")

                    if len(docs_list) >= 2:
                        # Calculer une tendance lin√©aire simple
                        from numpy import polyfit

                        coeffs = polyfit(docs_list, index_times, 1)
                        slope = coeffs[0]

                        st.markdown(f"""
                        **Tendance:**
                        - Pente: **{slope:.4f} ms/doc**
                        - Relation: **Quasi-lin√©aire** ‚úÖ

                        **Interpr√©tation:**
                        - Doubler le nombre de docs ‚âà doubler le temps
                        - Confirme la complexit√© **O(n)**!

                        **Vitesse moyenne:**
                        - **{(len(docs_list) / sum(index_times) * 1000):.0f} docs/s**
                        """)

                    # Dataset le plus rapide/lent
                    fastest_idx = index_times.index(min(index_times))
                    slowest_idx = index_times.index(max(index_times))

                    st.success(f"""
                    ‚ö° **Plus rapide:** {benchmark_results[fastest_idx]["Dataset"]}
                    ({benchmark_results[fastest_idx]["Docs"]} docs en {benchmark_results[fastest_idx]["Index (ms)"]} ms)
                    """)

                    st.warning(f"""
                    üêå **Plus lent:** {benchmark_results[slowest_idx]["Dataset"]}
                    ({benchmark_results[slowest_idx]["Docs"]} docs en {benchmark_results[slowest_idx]["Index (ms)"]} ms)
                    """)

                st.divider()

                st.markdown("### üéì Conclusion des Benchmarks")

                max_docs = max(docs_list)
                min_docs = min(docs_list)
                max_time = max(index_times)
                min_time = min(index_times)

                ratio_docs = max_docs / min_docs
                ratio_time = max_time / min_time

                st.markdown(f"""
                **Scalabilit√© de BM25:**

                - En passant de **{min_docs} √† {max_docs} docs** (√ó{ratio_docs:.1f}),
                  le temps passe de **{min_time:.2f} √† {max_time:.2f} ms** (√ó{ratio_time:.1f})

                **Observations:**
                """)

                if abs(ratio_time - ratio_docs) < 0.5:
                    st.success(f"""
                    ‚úÖ **Scalabilit√© lin√©aire confirm√©e!**
                    Le ratio de temps ({ratio_time:.1f}√ó) correspond au ratio de docs ({ratio_docs:.1f}√ó).
                    BM25 respecte bien la complexit√© O(n)!
                    """)
                else:
                    st.info(f"""
                    üí° **Scalabilit√© observ√©e:** Ratio temps ({ratio_time:.1f}√ó) vs ratio docs ({ratio_docs:.1f}√ó).
                    Les variations peuvent √™tre dues aux longueurs de documents diff√©rentes.
                    """)

            else:
                st.error("‚ùå Aucun benchmark n'a pu √™tre ex√©cut√©!")

    st.divider()

    # === OPTIMISATIONS ===
    st.markdown("## üîß Optimisations Possibles")

    st.markdown("""
    Pour de **tr√®s gros corpus** (millions de documents), voici des optimisations possibles:
    """)

    col_opt1, col_opt2 = st.columns(2)

    with col_opt1:
        st.markdown("""
        ### 1Ô∏è‚É£ Index Invers√©

        **Principe:** Stocker pour chaque mot la liste des documents qui le contiennent.

        **Avantage:** Ne parcourir que les docs pertinents (pas tout le corpus)!

        **Gain:** O(n) ‚Üí O(k) o√π k = docs contenant les mots de la query

        ---

        ### 2Ô∏è‚É£ Matrices Creuses (Sparse)

        **Principe:** Ne stocker que les valeurs non-nulles.

        **Avantage:** √âconomie m√©moire massive!

        **Gain:** M√©moire O(n √ó v) ‚Üí O(nnz) o√π nnz = valeurs non-nulles

        ---

        ### 3Ô∏è‚É£ Cache de Preprocessing

        **Principe:** Sauvegarder l'index BM25 sur disque.

        **Avantage:** Pas besoin de r√©indexer √† chaque run!

        **Gain:** Temps de d√©marrage divis√© par 10-100√ó
        """)

    with col_opt2:
        st.markdown("""
        ### 4Ô∏è‚É£ Batch Processing

        **Principe:** Traiter les documents par lots parall√®les.

        **Avantage:** Utiliser tous les CPU cores!

        **Gain:** Temps divis√© par le nombre de cores (4-16√ó)

        ---

        ### 5Ô∏è‚É£ Approximations (ANN)

        **Principe:** Approximate Nearest Neighbors (LSH, HNSW).

        **Avantage:** Recherche ultra-rapide (log n au lieu de n)!

        **Gain:** O(n) ‚Üí O(log n) pour la recherche

        ---

        ### 6Ô∏è‚É£ Elasticsearch / Solr

        **Principe:** Utiliser un moteur d√©di√© (bas√© sur BM25!)

        **Avantage:** Toutes les optimisations ci-dessus + distribution!

        **Gain:** Scalabilit√© jusqu'√† des milliards de docs
        """)

    st.success("""
    ‚úÖ **Pour ce projet p√©dagogique:**
    L'impl√©mentation actuelle est suffisante pour des corpus de **quelques milliers de documents**.
    Pour de la production, utilise **Elasticsearch** ou **Apache Solr** (qui impl√©mentent BM25 nativement)!

    ---

    Compare les **performances r√©elles** de TF-IDF vs BM25 sur 100 documents!
    """)

    if st.button("üöÄ Lancer le Benchmark!", type="primary", key="bm25_benchmark_btn"):
        with st.spinner("‚è±Ô∏è Benchmarking en cours..."):
            # TF-IDF
            start = time.time()
            tfidf_engine = TFIDFEngine(
                documents_texts[:100], remove_stopwords=remove_stopwords
            )
            tfidf_engine.fit()
            tfidf_time = time.time() - start

            # BM25
            start = time.time()
            bm25_engine = BM25Engine(
                documents_texts[:100], remove_stopwords=remove_stopwords
            )
            bm25_time = time.time() - start

            st.success("‚úÖ Benchmark termin√©!")

            col1, col2, col3 = st.columns(3)
            col1.metric("‚è±Ô∏è TF-IDF", f"{tfidf_time:.4f}s")
            col2.metric("‚è±Ô∏è BM25", f"{bm25_time:.4f}s")

            # Diff√©rence avec indicateur
            diff = abs(bm25_time - tfidf_time)
            diff_percent = (diff / tfidf_time) * 100 if tfidf_time > 0 else 0
            col3.metric("üìä Diff√©rence", f"{diff:.4f}s", f"{diff_percent:.1f}%")

            st.info(
                "üí° **Conclusion:** Les deux algos ont la m√™me complexit√©! BM25 apporte de meilleurs r√©sultats sans p√©nalit√© de performance!"
            )


# ============================================================================
# MAIN APP
# ============================================================================


def main():
    # === SIDEBAR NAVIGATION ===
    with st.sidebar:
        st.title("üîç Explorateur")
        st.caption("Recherche Textuelle")

        st.markdown("### üìö Navigation")

        # Navigation avec boutons styl√©s
        if "current_section" not in st.session_state:
            st.session_state.current_section = "üè† Accueil"

        # Sections disponibles (d√©sactiver Embeddings/Synth√®se si pas install√©s)
        sections = ["üè† Accueil", "üì¶ Datasets", "üìä TF-IDF", "üéØ BM25"]
        if EMBEDDINGS_AVAILABLE:
            sections.extend(["üß† Embeddings", "üìä Synth√®se"])
        else:
            sections.extend(["üß† Embeddings üîí", "üìä Synth√®se üîí"])

        for section_name in sections:
            # Style diff√©rent pour la section active
            if st.session_state.current_section == section_name:
                # Bouton actif (style diff√©rent)
                st.markdown(
                    f"""
                <div style="background: linear-gradient(90deg, #1f77b4 0%, #2ca02c 100%); padding: 12px 20px; border-radius: 8px; margin-bottom: 8px; color: white; font-weight: bold; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                    {section_name}
                </div>
                """,
                    unsafe_allow_html=True,
                )
            else:
                # Bouton cliquable
                if st.button(
                    section_name, key=f"nav_{section_name}", use_container_width=True
                ):
                    st.session_state.current_section = section_name
                    st.rerun()

        section = st.session_state.current_section

        st.divider()

        # Configuration globale (si pas sur accueil)
        if section != "üè† Accueil":
            st.markdown("### ‚öôÔ∏è Configuration")

            # S√©lection dataset
            datasets_info = get_all_datasets_info()
            dataset_names = [info["name"] for info in datasets_info]
            dataset_labels = {
                "recettes": "üçù Recettes",
                "films": "üé¨ Films",
                "wikipedia": "üìö Wikipedia",
            }

            selected_dataset = st.selectbox(
                "Dataset:",
                dataset_names,
                format_func=lambda x: dataset_labels.get(x, x),
                key="dataset_select",
            )

            # Taille dataset
            use_extended = st.checkbox(
                "üì¶ Dataset √©tendu",
                value=False,
                help="Plus de documents pour tester performances",
                key="extended_check",
            )

            # Afficher la VRAIE taille du dataset s√©lectionn√©!
            try:
                # Compter rapidement le nombre de docs
                if selected_dataset in ["recettes", "films"]:
                    # Lire depuis synthetic/
                    file_mapping = {
                        "recettes": "data/synthetic/recipes_fr.json",
                        "films": "data/synthetic/films_fr.json",
                    }
                    import json
                    from pathlib import Path

                    if use_extended:
                        # Mode √©tendu = TOUS les docs du fichier
                        file_path = Path(file_mapping[selected_dataset])
                        if file_path.exists():
                            with open(file_path, "r", encoding="utf-8") as f:
                                data = json.load(f)
                                estimated_docs = f"{len(data):,}"
                                size_label = "(√©tendu)"
                        else:
                            estimated_docs = "~1,000"
                            size_label = "(√©tendu)"
                    else:
                        # Mode normal = 50 docs
                        estimated_docs = "50"
                        size_label = ""

                elif selected_dataset == "wikipedia":
                    if use_extended:
                        estimated_docs = "1,000"
                        size_label = "(√©tendu - HF)"
                    else:
                        estimated_docs = "50"
                        size_label = "(hardcod√©)"
                else:
                    estimated_docs = "?"
                    size_label = ""

                st.info(f"üìä **{estimated_docs} documents** {size_label}")

            except Exception as e:
                # Fallback en cas d'erreur
                estimated_docs = "~1,000" if use_extended else "~50"
                st.info(f"üìä {estimated_docs} documents")

            # Param√®tres avanc√©s
            with st.expander("üîß Avanc√©s"):
                remove_stopwords = st.checkbox(
                    "Supprimer stopwords", value=True, key="stopwords_check"
                )
                show_intermediate = st.checkbox(
                    "Calculs interm√©diaires", value=False, key="intermediate_check"
                )

                # Menu de s√©lection du mod√®le d'embeddings (si disponible)
                if EMBEDDINGS_AVAILABLE:
                    st.markdown("**üß† Mod√®le Embeddings**")

                    # D√©finir les mod√®les disponibles avec infos
                    embedding_models = {
                        "MiniLM-L6 (Petit, Rapide)": {
                            "name": "paraphrase-multilingual-MiniLM-L6-v2",
                            "size": "~80 MB",
                            "speed": "‚ö°‚ö°‚ö°",
                            "quality": "‚≠ê‚≠ê",
                        },
                        "MiniLM-L12 (Standard, Recommand√©)": {
                            "name": "paraphrase-multilingual-MiniLM-L12-v2",
                            "size": "~120 MB",
                            "speed": "‚ö°‚ö°",
                            "quality": "‚≠ê‚≠ê‚≠ê",
                        },
                        "MPNet (Grand, Meilleur)": {
                            "name": "paraphrase-multilingual-mpnet-base-v2",
                            "size": "~420 MB",
                            "speed": "‚ö°",
                            "quality": "‚≠ê‚≠ê‚≠ê‚≠ê",
                        },
                    }

                    selected_model_label = st.selectbox(
                        "Choisir un mod√®le:",
                        list(embedding_models.keys()),
                        index=1,  # Par d√©faut: MiniLM-L12 (recommand√©)
                        key="embedding_model_select",
                        help="Petit = rapide mais moins pr√©cis | Grand = lent mais meilleur",
                    )

                    embedding_model_name = embedding_models[selected_model_label][
                        "name"
                    ]
                    model_info = embedding_models[selected_model_label]

                    # Afficher les infos du mod√®le s√©lectionn√©
                    st.caption(
                        f"üì¶ Taille: {model_info['size']} | Vitesse: {model_info['speed']} | Qualit√©: {model_info['quality']}"
                    )
                    st.caption("üíæ Le mod√®le est t√©l√©charg√© UNE FOIS et mis en cache!")
                else:
                    embedding_model_name = "paraphrase-multilingual-MiniLM-L12-v2"  # D√©faut si pas disponible

        st.divider()

        # Warning si embeddings pas disponibles
        if not EMBEDDINGS_AVAILABLE:
            st.warning("‚ö†Ô∏è Embeddings non install√©s. Sections verrouill√©es üîí", icon="‚ö†Ô∏è")

        st.caption("üí° Explore les sections pour apprendre!")

    # === ROUTING ===

    if section == "üè† Accueil":
        render_home()

    elif section == "üì¶ Datasets":
        # Section d'exploration des datasets
        render_datasets_section(selected_dataset, use_extended)

    elif section in ["üìä TF-IDF", "üéØ BM25"]:
        # Charger le dataset
        with st.spinner("üîÑ Chargement du dataset..."):
            start_load = time.time()
            dataset = load_cached_dataset(selected_dataset, extended=use_extended)
            load_time = time.time() - start_load

            documents_texts = [doc["text"] for doc in dataset]
            documents_titles = [doc["title"] for doc in dataset]
            documents_categories = [doc["category"] for doc in dataset]

        # Cr√©er les engines
        if section == "üìä TF-IDF" or section == "üéØ BM25":
            with st.spinner("üßÆ Pr√©paration des moteurs de recherche..."):
                start_fit = time.time()
                tfidf_engine = create_tfidf_engine(
                    documents_texts, remove_stopwords=remove_stopwords
                )
                fit_time = time.time() - start_fit

        # Render la section appropri√©e
        if section == "üìä TF-IDF":
            render_tfidf_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                remove_stopwords,
                show_intermediate,
                load_time,
                fit_time,
            )

        elif section == "üéØ BM25":
            render_bm25_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                remove_stopwords,
            )

    elif section == "üß† Embeddings" or section == "üß† Embeddings üîí":
        if EMBEDDINGS_AVAILABLE:
            # Charger dataset et engines comme pour BM25
            with st.spinner("üîÑ Chargement du dataset..."):
                dataset = load_cached_dataset(selected_dataset, extended=use_extended)
                documents_texts = [doc["text"] for doc in dataset]
                documents_titles = [doc["title"] for doc in dataset]
                documents_categories = [doc.get("category", "Autre") for doc in dataset]

            # Cr√©er TF-IDF et BM25 engines (pour comparaison)
            with st.spinner("‚öôÔ∏è Initialisation des moteurs de recherche..."):
                tfidf_engine = create_tfidf_engine(documents_texts, remove_stopwords)
                bm25_engine = create_bm25_engine(documents_texts, remove_stopwords)

            # Appeler la vraie section Embeddings avec le mod√®le s√©lectionn√©
            render_embeddings_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                bm25_engine,
                remove_stopwords,
                embedding_model_name=embedding_model_name,  # NOUVEAU: mod√®le s√©lectionn√©!
            )
        else:
            st.title("üß† Embeddings Vectoriels üîí")
            st.error("""
            ### ‚ö†Ô∏è Module Non Disponible

            Les embeddings n√©cessitent **sentence-transformers** et **PyTorch**.

            **Pour installer:**
            ```bash
            pip install sentence-transformers torch transformers
            ```

            **Note:** L'installation peut prendre 5-10 minutes (plusieurs GB √† t√©l√©charger).

            **En attendant**, tu peux utiliser **TF-IDF** et **BM25** qui sont 100% fonctionnels! üöÄ
            """)

    elif section == "üìä Synth√®se" or section == "üìä Synth√®se üîí":
        if EMBEDDINGS_AVAILABLE:
            # Charger dataset et tous les engines
            with st.spinner("üîÑ Chargement du dataset..."):
                dataset = load_cached_dataset(selected_dataset, extended=use_extended)
                documents_texts = [doc["text"] for doc in dataset]
                documents_titles = [doc["title"] for doc in dataset]
                documents_categories = [doc.get("category", "Autre") for doc in dataset]

            # Cr√©er TOUS les engines pour la synth√®se
            with st.spinner("‚öôÔ∏è Initialisation de tous les moteurs..."):
                tfidf_engine = create_tfidf_engine(documents_texts, remove_stopwords)
                bm25_engine = create_bm25_engine(documents_texts, remove_stopwords)
                # L'embedding engine sera cr√©√© dans render_synthesis_section si n√©cessaire

            # Appeler la vraie section Synth√®se
            render_synthesis_section(
                dataset,
                documents_texts,
                documents_titles,
                documents_categories,
                tfidf_engine,
                bm25_engine,
                None,  # embedding_engine sera cr√©√© √† la demande
            )
        else:
            st.title("üìä Synth√®se Comparative üîí")
            st.error("""
            ### ‚ö†Ô∏è Module Non Disponible

            La synth√®se n√©cessite que **tous les moteurs** soient disponibles (TF-IDF, BM25, Embeddings).

            **Pour d√©bloquer**, installe d'abord les embeddings:
            ```bash
            pip install sentence-transformers torch transformers
            ```

            **En attendant**, compare **TF-IDF vs BM25** dans la section BM25 ‚Üí Comparaison! ‚öîÔ∏è
            """)

    # === FOOTER ===
    st.divider()
    st.markdown(
        """
    <div style="text-align: center; color: #666; padding: 1rem 0;">
        <p>Cr√©√© avec ‚ù§Ô∏è pour l'apprentissage de la recherche textuelle</p>
        <p style="font-size: 0.9rem;">üìö TF-IDF ‚Ä¢ üéØ BM25 ‚Ä¢ üß† Embeddings (√† venir)</p>
    </div>
    """,
        unsafe_allow_html=True,
    )


if __name__ == "__main__":
    main()
