"""
Section BM25 pour l'application Streamlit
Contient toutes les fonctions de rendu pour la partie BM25
"""

import streamlit as st
import numpy as np
import pandas as pd
import time as time_module  # Renamed to avoid conflict
import matplotlib.pyplot as plt

# Imports from src
from src.bm25_engine import BM25Engine
from src.tfidf_engine import TFIDFEngine
from src.visualizations import (
    plot_search_results,
    plot_saturation_effect,
    plot_length_normalization,
    plot_parameter_space_heatmap,
    plot_tfidf_bm25_comparison,
    plot_score_distributions,
)


# ============================================================================
# HELPER FUNCTION
# ============================================================================


# ============================================================================
# BM25 SECTION FUNCTIONS
# ============================================================================


def render_bm25_section(
    dataset,
    documents_texts,
    documents_titles,
    documents_categories,
    tfidf_engine,
    remove_stopwords,
):
    """Section BM25 compl√®te"""

    st.title("üéØ BM25: Best Matching 25 - TF-IDF Am√©lior√©")

    # Import de la fonction de navigation styl√©e
    from app import render_tab_navigation

    # Sub-navigation avec boutons styl√©s
    tabs_bm25 = [
        "üìñ Introduction",
        "üî¢ Concepts",
        "üîç Recherche",
        "üìä Exploration",
        "üéì Pas-√†-Pas",
        "‚öîÔ∏è Comparaison",
        "‚ö° Performance",
    ]
    tab = render_tab_navigation(tabs_bm25, "bm25_current_tab")

    if tab == "üìñ Introduction":
        render_bm25_intro()
    elif tab == "üî¢ Concepts":
        render_bm25_concepts(documents_texts, remove_stopwords)
    elif tab == "üîç Recherche":
        render_bm25_search(
            documents_texts, documents_titles, documents_categories, remove_stopwords
        )
    elif tab == "üìä Exploration":
        render_bm25_exploration(documents_texts, documents_titles, remove_stopwords)
    elif tab == "üéì Pas-√†-Pas":
        render_bm25_stepbystep(documents_texts, documents_titles, remove_stopwords)
    elif tab == "‚öîÔ∏è Comparaison":
        render_bm25_comparison(
            documents_texts, documents_titles, tfidf_engine, remove_stopwords
        )
    elif tab == "‚ö° Performance":
        render_bm25_performance(documents_texts, remove_stopwords)


def render_bm25_intro():
    """Introduction BM25 & Probl√®mes de TF-IDF - HYPER P√âDAGOGIQUE"""
    st.header("üìñ BM25: √âvolution Intelligente de TF-IDF")

    st.markdown("""
    ### üéØ Contexte Historique

    **TF-IDF** (ann√©es 1970) √©tait r√©volutionnaire pour son √©poque.
    **BM25** (1994) est son √©volution moderne, d√©velopp√©e par Stephen Robertson et Karen Sp√§rck Jones.

    BM25 = **B**est **M**atching **25** (25√®me it√©ration de l'algorithme!)
    """)

    st.divider()

    st.markdown("## ‚ùå Les 3 Probl√®mes Fondamentaux de TF-IDF")

    # === PROBL√àME #1: SATURATION ===
    with st.expander("**üî¥ Probl√®me #1: Saturation Lin√©aire du TF**", expanded=True):
        st.markdown("""
        ### üí° Le Probl√®me en D√©tail

        Dans TF-IDF, le score cro√Æt **lin√©airement** avec le nombre d'occurrences.
        Mais est-ce r√©aliste? ü§î
        """)

        # Exemple concret avec calculs
        st.markdown("""
        #### üìù Exemple Concret

        Imaginons 3 documents parlant de "Python":
        """)

        col1, col2, col3 = st.columns(3)

        with col1:
            st.info("""
            **üìÑ Doc A**

            - Longueur: 100 mots
            - "python": **1√ó fois**
            - TF = 1/100 = **0.01**

            *Article de blog mentionnant Python en passant*
            """)

        with col2:
            st.warning("""
            **üìÑ Doc B**

            - Longueur: 100 mots
            - "python": **10√ó fois**
            - TF = 10/100 = **0.10**

            *Article d√©di√© √† Python*
            """)

        with col3:
            st.error("""
            **üìÑ Doc C**

            - Longueur: 100 mots
            - "python": **50√ó fois**
            - TF = 50/100 = **0.50**

            *Spam avec r√©p√©titions*
            """)

        st.markdown("""
        ### ü§Ø Le Probl√®me

        Avec TF-IDF:
        - Doc B (10√ó) a un score **10√ó plus √©lev√©** que Doc A (1√ó)
        - Doc C (50√ó) a un score **5√ó plus √©lev√©** que Doc B (10√ó)

        **Mais en r√©alit√©:**
        - Apr√®s 10 occurrences, le mot n'apporte **plus d'information nouvelle**!
        - Doc C n'est pas 50√ó plus pertinent que Doc A
        - On veut un **effet de saturation** (plateau)
        """)

        # Graphique en colonnes
        col_g1, col_g2 = st.columns(2)

        with col_g1:
            # Graphique de saturation TF-IDF vs BM25
            fig_saturation = plot_saturation_effect(k1_values=[0.5, 1.2, 1.5, 2.0], max_freq=50)
            st.pyplot(fig_saturation)
            plt.close()

        with col_g2:
            st.markdown("""
            ### üìä Analyse du Graphique

            **Ligne rouge (TF-IDF):**
            - Croissance lin√©aire infinie
            - 100 occurrences = 100√ó le score de 1
            - **Irr√©aliste!** ‚ùå

            **Courbes color√©es (BM25):**
            - Croissance rapide au d√©but
            - Plateau apr√®s N occurrences
            - **R√©aliste!** ‚úÖ

            **Param√®tre k1:**
            - k1 faible ‚Üí saturation rapide
            - k1 √©lev√© ‚Üí saturation lente
            """)

    # === PROBL√àME #2: NORMALISATION ===
    with st.expander("**üü† Probl√®me #2: Normalisation Na√Øve par Longueur**"):
        st.markdown("""
        ### üí° Le Probl√®me en D√©tail

        TF-IDF normalise en divisant simplement par la longueur totale.
        R√©sultat: les documents longs sont **toujours p√©nalis√©s**.
        """)

        st.markdown("""
        #### üìù Exemple Concret

        Deux recettes parlant de "chocolat":
        """)

        col1, col2 = st.columns(2)

        with col1:
            st.info("""
            **üç´ Recette Courte (50 mots)**

            ```
            Mousse au chocolat simple:
            200g chocolat, 4 oeufs, sucre.
            Faire fondre chocolat.
            Monter blancs. M√©langer.
            [+ 42 mots de remplissage...]
            ```

            - "chocolat": **2 occurrences**
            - TF = 2/50 = **0.04** (4%)
            """)

        with col2:
            st.warning("""
            **üç´ Recette D√©taill√©e (500 mots)**

            ```
            Mousse au chocolat professionnelle:
            Introduction sur le chocolat (50 mots)
            Liste d√©taill√©e ingr√©dients (100 mots)
            √âtapes d√©taill√©es avec chocolat (200 mots)
            Astuces et variantes chocolat (150 mots)
            ```

            - "chocolat": **15 occurrences**
            - TF = 15/500 = **0.03** (3%)
            """)

        st.markdown("""
        ### ü§Ø Le Probl√®me

        **Avec TF-IDF:**
        - Recette courte (2√ó chocolat) ‚Üí TF = 0.04
        - Recette d√©taill√©e (15√ó chocolat) ‚Üí TF = 0.03
        - La recette d√©taill√©e a un **score PLUS BAS** ‚ùå

        **Ce qu'on veut:**
        - P√©naliser les docs longs... **mais pas toujours!**
        - Certains corpus ont naturellement des docs longs (articles scientifiques)
        - D'autres ont des docs courts (tweets, recettes)
        - On veut un **contr√¥le ajustable** via param√®tre **b**
        """)

        st.markdown("""
        ### üí° Solution BM25

        Le param√®tre **b** contr√¥le l'intensit√© de la p√©nalit√©:

        - **b = 0**: Aucune p√©nalit√© (ignore la longueur)
        - **b = 0.5**: P√©nalit√© l√©g√®re
        - **b = 0.75**: P√©nalit√© standard ‚≠ê (recommand√©)
        - **b = 1.0**: P√©nalit√© compl√®te (comme TF-IDF)

        Tu peux adapter selon ton corpus!
        """)

    # === PROBL√àME #3: PAS DE CONTR√îLE ===
    with st.expander("**üü° Probl√®me #3: Aucun Param√®tre Ajustable**"):
        st.markdown("""
        ### üí° Le Probl√®me

        TF-IDF est une formule **fig√©e**:
        """)

        st.latex(
            r"\text{TF-IDF} = \frac{f}{|D|} \times \log\left(\frac{N}{n(t)}\right)"
        )

        st.markdown("""
        **Cons√©quences:**
        - ‚ùå Impossible d'adapter selon le type de corpus
        - ‚ùå Impossible de tuner pour de meilleures performances
        - ‚ùå Un seul comportement pour tous les cas

        **Exemples de corpus diff√©rents:**

        | Type de Corpus | Comportement Optimal |
        |----------------|---------------------|
        | **Tweets** (courts) | Peu de normalisation (b faible) |
        | **Articles** (longs) | Normalisation forte (b √©lev√©) |
        | **Spam** (r√©p√©titions) | Saturation rapide (k1 faible) |
        | **Litt√©rature** (vari√©) | Saturation lente (k1 √©lev√©) |

        TF-IDF ne peut s'adapter √† aucun de ces cas! ‚ùå
        """)

    st.divider()

    # === SOLUTION BM25 ===
    st.markdown("## ‚úÖ BM25: La Solution Intelligente")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.success("""
        ### üéõÔ∏è Param√®tre k1

        **Contr√¥le la saturation du TF**

        **Valeurs typiques:**
        - 0.5 ‚Üí Saturation rapide
        - **1.5** ‚Üí Standard ‚≠ê
        - 2.0 ‚Üí Saturation lente
        - ‚àû ‚Üí Comme TF-IDF

        **Effet:**
        Apr√®s N occurrences, le score plafonne intelligemment!
        """)

    with col2:
        st.success("""
        ### ‚öñÔ∏è Param√®tre b

        **Contr√¥le la normalisation**

        **Valeurs typiques:**
        - 0.0 ‚Üí Aucune
        - **0.75** ‚Üí Standard ‚≠ê
        - 1.0 ‚Üí Compl√®te

        **Effet:**
        Ajuste la p√©nalit√© des documents longs selon ton corpus!
        """)

    with col3:
        st.success("""
        ### üìä IDF Am√©lior√©

        **Smoothing int√©gr√©**

        **Formule:**
        ```
        log((N - n + 0.5) /
            (n + 0.5))
        ```

        **Effet:**
        - √âvite divisions par z√©ro
        - Plus stable que TF-IDF
        - Meilleure gestion des mots rares
        """)

    st.divider()

    st.markdown("## üéØ Formule Compl√®te BM25")

    st.latex(r"""
    \text{BM25}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \times \frac{f(q_i, D) \times (k1 + 1)}{f(q_i, D) + k1 \times \left(1 - b + b \times \frac{|D|}{\text{avgdl}}\right)}
    """)

    st.markdown(r"""
    ### üìñ D√©composition de la Formule

    | Composant | Signification | R√¥le |
    |-----------|---------------|------|
    | **IDF(qi)** | Inverse Document Frequency | Raret√© du mot (avec smoothing) |
    | **f(qi, D)** | Fr√©quence du mot | Nombre d'occurrences dans le doc |
    | **k1** | Param√®tre saturation | Contr√¥le le plateau du TF |
    | **b** | Param√®tre normalisation | Contr√¥le la p√©nalit√© de longueur |
    | **\|D\|** | Longueur du document | Nombre de mots dans le doc |
    | **avgdl** | Longueur moyenne | Moyenne du corpus |

    ### üí° En R√©sum√©

    **TF-IDF:** Simple mais limit√© (ann√©es 1970)
    **BM25:** Intelligent et ajustable (1994 - encore utilis√© aujourd'hui!)

    BM25 est le **standard industriel** pour la recherche textuelle:
    - Utilis√© par Elasticsearch
    - Utilis√© par Apache Lucene/Solr
    - Base de millions de moteurs de recherche
    """)


def render_bm25_concepts(documents_texts, remove_stopwords):
    """Concepts BM25 d√©taill√©s - HYPER P√âDAGOGIQUE"""
    st.header("üî¢ Comprendre BM25 en Profondeur")

    st.markdown("""
    D√©cortiquons chaque composant de BM25 avec des **exemples concrets** et des **calculs chiffr√©s**!
    """)

    # === IDF AM√âLIOR√â ===
    with st.expander(
        "üìâ **Composant #1: IDF Am√©lior√© (avec smoothing)**", expanded=True
    ):
        st.markdown("""
        ### üí° L'IDF de TF-IDF avait des Probl√®mes

        **Formule TF-IDF IDF:**
        """)

        st.latex(r"\text{IDF}_{\text{TF-IDF}}(t) = \log\left(\frac{N}{n(t)}\right)")

        st.markdown("""
        **Probl√®mes:**
        1. ‚ö†Ô∏è **Division par z√©ro** si n(t) = 0 (mot absent du corpus)
        2. ‚ö†Ô∏è **Valeurs extr√™mes** pour les mots tr√®s rares
        3. ‚ö†Ô∏è **Pas de smoothing** pour stabiliser
        """)

        st.divider()

        st.markdown("""
        ### ‚úÖ BM25 IDF R√©sout Ces Probl√®mes

        **Formule BM25 IDF:**
        """)

        st.latex(
            r"\text{IDF}_{\text{BM25}}(q) = \log\left(\frac{N - n(q) + 0.5}{n(q) + 0.5}\right)"
        )

        st.markdown("""
        **Composants:**
        - **N** = nombre total de documents dans le corpus
        - **n(q)** = nombre de documents contenant le terme q
        - **+0.5** = **smoothing de Laplace** (√©vite divisions par z√©ro)
        """)

        st.markdown("""
        ### üìù Exemple Concret avec Calculs

        Corpus de **1000 documents**:
        """)

        # Tableau comparatif avec calculs
        import pandas as pd

        examples = [
            {"Mot": "le", "n(q)": 950, "Raret√©": "Tr√®s commun"},
            {"Mot": "cuisine", "n(q)": 300, "Raret√©": "Commun"},
            {"Mot": "python", "n(q)": 50, "Raret√©": "Rare"},
            {"Mot": "blockchain", "n(q)": 5, "Raret√©": "Tr√®s rare"},
        ]

        for ex in examples:
            n = ex["n(q)"]
            N = 1000
            # TF-IDF IDF
            idf_tfidf = np.log(N / n) if n > 0 else float("inf")
            # BM25 IDF
            idf_bm25 = np.log((N - n + 0.5) / (n + 0.5))

            ex["IDF TF-IDF"] = f"{idf_tfidf:.3f}"
            ex["IDF BM25"] = f"{idf_bm25:.3f}"

        df_idf = pd.DataFrame(examples)
        st.dataframe(df_idf, use_container_width=True)

        st.markdown("""
        ### üìä Observations

        **Pour les mots communs ("le"):**
        - TF-IDF: 0.054 (tr√®s proche de 0)
        - BM25: 0.053 (similaire)
        - ‚úÖ Peu de diff√©rence

        **Pour les mots rares ("blockchain"):**
        - TF-IDF: 5.298 (valeur √©lev√©e)
        - BM25: 5.298 (plus stable avec smoothing)
        - ‚úÖ BM25 mieux stabilis√©

        **Avantage du +0.5:**
        - √âvite les explosions de valeurs
        - Plus robuste aux mots tr√®s rares
        - Meilleure g√©n√©ralisation
        """)

        # === GRAPHIQUE COMPARATIF IDF ===
        st.divider()
        st.markdown("### üìä Visualisation: Impact du Smoothing")

        col_graph, col_analysis = st.columns([3, 2])

        with col_graph:
            import matplotlib.pyplot as plt

            fig, ax = plt.subplots(figsize=(10, 6))

            # Nombre total de documents
            N = 1000

            # Gamme de n(q): de 1 √† N (nombre de docs contenant le terme)
            n_values = np.arange(1, N + 1)

            # Calcul IDF TF-IDF
            idf_tfidf = np.log(N / n_values)

            # Calcul IDF BM25 (avec smoothing)
            idf_bm25 = np.log((N - n_values + 0.5) / (n_values + 0.5))

            # Tracer les courbes
            ax.plot(
                n_values,
                idf_tfidf,
                "b-",
                linewidth=2.5,
                label="IDF TF-IDF (classique)",
                alpha=0.8,
            )
            ax.plot(
                n_values,
                idf_bm25,
                "r-",
                linewidth=2.5,
                label="IDF BM25 (avec smoothing +0.5)",
                alpha=0.8,
            )

            # Zones d'int√©r√™t
            # Mots tr√®s rares (n < 10)
            ax.axvspan(0, 10, alpha=0.1, color="red", label="Mots tr√®s rares")
            # Mots communs (n > 800)
            ax.axvspan(800, N, alpha=0.1, color="green", label="Mots tr√®s communs")

            # Annotations pour des exemples
            examples_n = [5, 50, 300, 950]
            examples_labels = ["blockchain", "python", "cuisine", "le"]

            for n, label in zip(examples_n, examples_labels):
                idf_tf = np.log(N / n)
                idf_bm = np.log((N - n + 0.5) / (n + 0.5))

                # Marquer sur la courbe TF-IDF
                ax.scatter(
                    [n],
                    [idf_tf],
                    color="blue",
                    s=80,
                    zorder=5,
                    edgecolor="black",
                    linewidth=1.5,
                )
                ax.text(
                    n,
                    idf_tf + 0.3,
                    f'"{label}"',
                    fontsize=9,
                    ha="center",
                    color="blue",
                    fontweight="bold",
                )

                # Marquer sur la courbe BM25
                ax.scatter(
                    [n],
                    [idf_bm],
                    color="red",
                    s=80,
                    zorder=5,
                    edgecolor="black",
                    linewidth=1.5,
                )

            ax.set_xlabel(
                "Nombre de documents contenant le terme n(q)",
                fontsize=12,
                fontweight="bold",
            )
            ax.set_ylabel("Score IDF", fontsize=12, fontweight="bold")
            ax.set_title(
                "Comparaison IDF: TF-IDF vs BM25 (Corpus de 1000 docs)",
                fontsize=13,
                fontweight="bold",
                pad=15,
            )

            ax.legend(fontsize=10, loc="upper right")
            ax.grid(True, alpha=0.3)
            ax.set_xlim(0, N)
            ax.set_ylim(-1, 6)

            # Ligne horizontale √† y=0
            ax.axhline(y=0, color="black", linestyle="--", alpha=0.3, linewidth=1)

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with col_analysis:
            st.markdown("""
            ### üîç Analyse du Graphique

            **Courbe bleue (TF-IDF):**
            - D√©cro√Æt rapidement pour les mots rares
            - **Probl√®me:** Peut devenir n√©gatif si n > N/2 ‚ö†Ô∏è
            - Pas de stabilisation

            **Courbe rouge (BM25):**
            - Forme similaire mais **plus stable**
            - Le **+0.5** lisse la courbe
            - Reste toujours positif üíö
            - √âvite les valeurs extr√™mes

            **Zones color√©es:**
            - üî¥ **Rouge:** Mots tr√®s rares (< 10 docs)
              - IDF √©lev√© (~5-6)
              - Forte diff√©renciation

            - üü¢ **Vert:** Mots tr√®s communs (> 800 docs)
              - IDF proche de 0
              - Faible importance

            **üí° Points cl√©s:**

            Les deux formules donnent des r√©sultats **tr√®s similaires** pour la plupart des mots, mais BM25 est plus robuste aux cas extr√™mes!

            **Exemple "blockchain" (n=5):**
            - TF-IDF: ~5.30
            - BM25: ~5.30
            - ‚úÖ Quasi identique

            **Avantage BM25:**
            Le smoothing √©vite les comportements instables pour les mots absents ou extr√™mement rares.
            """)

    # === SATURATION DU TF ===
    with st.expander("üéõÔ∏è **Composant #2: Saturation du TF (Param√®tre k1)**"):
        st.markdown("""
        ### üí° Pourquoi Saturer le TF?

        **Observation r√©aliste:**
        Apr√®s **10 occurrences**, un mot n'apporte **plus beaucoup d'info nouvelle**.

        - 1 occurrence ‚Üí Le doc parle du sujet ‚úÖ
        - 10 occurrences ‚Üí Le doc parle VRAIMENT du sujet ‚úÖ‚úÖ
        - 100 occurrences ‚Üí Le doc... parle toujours du sujet (mais pas 100√ó plus!) ‚ö†Ô∏è
        """)

        st.markdown("""
        ### üî¢ Formule du TF Satur√©
        """)

        st.latex(r"\text{TF}_{\text{BM25}} = \frac{f \times (k1 + 1)}{f + k1}")

        st.markdown("""
        **Composants:**
        - **f** = fr√©quence du terme dans le document
        - **k1** = param√®tre contr√¥lant la vitesse de saturation
        """)

        st.markdown("""
        ### üìù Exemple Concret: Mot "Python"

        Testons diff√©rentes valeurs de **k1**:
        """)

        # Calculs pour diff√©rents k1
        frequencies = [1, 2, 5, 10, 20, 50, 100]
        k1_values = [0.5, 1.2, 1.5, 2.0]

        data = []
        for f in frequencies:
            row = {"Occurrences (f)": f}
            for k1 in k1_values:
                tf_bm25 = (f * (k1 + 1)) / (f + k1)
                row[f"k1={k1}"] = f"{tf_bm25:.3f}"
            data.append(row)

        df_saturation = pd.DataFrame(data)
        st.dataframe(df_saturation, use_container_width=True)

        st.markdown("""
        ### üìä Observations Cl√©s

        **Avec k1 = 0.5 (saturation rapide):**
        - 10 occ ‚Üí 0.909
        - 100 occ ‚Üí 0.993
        - Plafonne tr√®s vite! (bon pour √©viter le spam)

        **Avec k1 = 1.5 (standard ‚≠ê):**
        - 10 occ ‚Üí 1.304
        - 100 occ ‚Üí 1.485
        - √âquilibre r√©aliste

        **Avec k1 = 2.0 (saturation lente):**
        - 10 occ ‚Üí 1.375
        - 100 occ ‚Üí 1.970
        - Plus de croissance (bon pour textes vari√©s)

        **k1 ‚Üí ‚àû (comme TF-IDF):**
        - Croissance lin√©aire sans limite
        """)

        # Graphique de saturation
        col_g1, col_g2 = st.columns([3, 2])

        with col_g1:
            import matplotlib.pyplot as plt

            fig, ax = plt.subplots(figsize=(8, 5))

            # Fr√©quences de 0 √† 100
            freqs = np.linspace(0, 100, 200)

            # TF-IDF (lin√©aire)
            tf_tfidf = freqs
            ax.plot(
                freqs,
                tf_tfidf,
                "r-",
                linewidth=2,
                label="TF-IDF (lin√©aire)",
                linestyle="--",
                alpha=0.7,
            )

            # BM25 avec diff√©rents k1
            k1_vals = [
                (0.5, "#3498db"),
                (1.2, "#e74c3c"),
                (1.5, "#2ecc71"),
                (2.0, "#f39c12"),
            ]
            for k1, color in k1_vals:
                tf_bm25 = (freqs * (k1 + 1)) / (freqs + k1)
                label = f"BM25 (k1={k1})" + (" ‚≠ê" if k1 == 1.5 else "")
                ax.plot(
                    freqs,
                    tf_bm25,
                    color=color,
                    linewidth=2.5 if k1 == 1.5 else 2,
                    label=label,
                )

            ax.set_xlabel("Nombre d'occurrences (f)", fontsize=11)
            ax.set_ylabel("Score TF", fontsize=11)
            ax.set_title(
                "Effet de Saturation: TF-IDF vs BM25", fontsize=12, fontweight="bold"
            )
            ax.legend(fontsize=9, loc="lower right")
            ax.grid(True, alpha=0.3)
            ax.set_xlim(0, 100)
            ax.set_ylim(0, 20)

            # Annotations
            ax.axhline(y=1.5, color="green", linestyle=":", alpha=0.5, linewidth=1)
            ax.text(85, 1.7, "Plateau k1=1.5", fontsize=9, color="green")

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with col_g2:
            st.markdown("""
            ### üìà Analyse du Graphique

            **Axe X:** Nombre d'occurrences
            **Axe Y:** Score TF r√©sultant

            **Ligne rouge pointill√©e (TF-IDF):**
            - Monte ind√©finiment ‚¨ÜÔ∏è
            - 100 occ = score de 100
            - **Probl√®me: spam!** ‚ùå

            **Courbes BM25 (satur√©es):**
            - **Bleue (k1=0.5):** Plateau ~1.0
            - **Rouge (k1=1.2):** Plateau ~1.2
            - **Verte (k1=1.5) ‚≠ê:** Plateau ~1.5
            - **Orange (k1=2.0):** Plateau ~2.0

            **üí° Observation:**
            Apr√®s 20-30 occurrences, les courbes BM25 **plafonnent** ‚Üí √©vite la sur-pond√©ration!

            **üéØ Recommandation:**
            k1=1.5 est le standard pour la plupart des corpus!
            """)

    # === NORMALISATION ===
    with st.expander("‚öñÔ∏è **Composant #3: Normalisation de Longueur (Param√®tre b)**"):
        st.markdown("""
        ### üí° Le Probl√®me des Documents Longs

        **Question:** Un document de 1000 mots devrait-il √™tre p√©nalis√©
        par rapport √† un document de 100 mots?

        **R√©ponse:** **√áa d√©pend du corpus!** ü§î

        - **Tweets** (courts naturellement) ‚Üí Peu de p√©nalit√©
        - **Articles scientifiques** (longs naturellement) ‚Üí Forte p√©nalit√©
        - **Recettes** (longueur mixte) ‚Üí P√©nalit√© mod√©r√©e
        """)

        st.markdown("""
        ### üî¢ Formule de Normalisation
        """)

        st.latex(r"\text{norm} = 1 - b + b \times \frac{|D|}{\text{avgdl}}")

        st.markdown("""
        **Composants:**
        - **|D|** = longueur du document actuel (en mots)
        - **avgdl** = longueur moyenne du corpus (average document length)
        - **b** = intensit√© de la p√©nalit√© (0 = aucune, 1 = compl√®te)
        """)

        st.markdown("""
        ### üìù Exemple Concret

        Corpus avec **avgdl = 100 mots** (moyenne):
        """)

        # Calculs pour diff√©rents b
        doc_lengths = [50, 100, 200, 500, 1000]
        b_values = [0.0, 0.5, 0.75, 1.0]
        avgdl = 100

        data = []
        for length in doc_lengths:
            row = {"Longueur doc": f"{length} mots"}
            for b in b_values:
                norm = 1 - b + b * (length / avgdl)
                row[f"b={b}"] = f"{norm:.3f}"
            data.append(row)

        df_norm = pd.DataFrame(data)
        st.dataframe(df_norm, use_container_width=True)

        st.markdown("""
        ### üìä Interpr√©tation

        **Facteur de normalisation > 1** = P√©nalit√© (doc plus long que la moyenne)
        **Facteur de normalisation = 1** = Neutre (doc de longueur moyenne)
        **Facteur de normalisation < 1** = Boost (doc plus court que la moyenne)

        **Avec b = 0 (aucune normalisation):**
        - Facteur = 1.0 pour tous les docs
        - La longueur est **ignor√©e**
        - Bon pour corpus homog√®nes

        **Avec b = 0.75 (standard ‚≠ê):**
        - Doc 50 mots ‚Üí 0.625 (boost de +60%)
        - Doc 200 mots ‚Üí 1.750 (p√©nalit√© de -43%)
        - Doc 1000 mots ‚Üí 8.500 (p√©nalit√© de -88%)
        - √âquilibre raisonnable

        **Avec b = 1.0 (normalisation compl√®te):**
        - P√©nalit√© maximale pour les docs longs
        - Comme TF-IDF (division par longueur)
        """)

        # Cr√©er un mini corpus pour calculer avgdl
        bm25_demo = BM25Engine(documents_texts[:10], remove_stopwords=remove_stopwords)

        col_g1, col_g2 = st.columns([3, 2])

        with col_g1:
            import matplotlib.pyplot as plt

            fig, ax = plt.subplots(figsize=(8, 5))

            # Longueurs de documents de 10 √† 500 mots
            doc_lengths = np.linspace(10, 500, 200)
            avgdl_val = bm25_demo.avgdl

            # Diff√©rentes valeurs de b
            b_vals = [
                (0.0, "#95a5a6"),
                (0.5, "#3498db"),
                (0.75, "#2ecc71"),
                (1.0, "#e74c3c"),
            ]

            for b, color in b_vals:
                norm_factors = 1 - b + b * (doc_lengths / avgdl_val)
                label = f"b={b}" + (" ‚≠ê" if b == 0.75 else "")
                ax.plot(
                    doc_lengths,
                    norm_factors,
                    color=color,
                    linewidth=2.5 if b == 0.75 else 2,
                    label=label,
                )

            # Ligne de r√©f√©rence (facteur = 1)
            ax.axhline(
                y=1.0,
                color="black",
                linestyle="--",
                alpha=0.5,
                linewidth=1,
                label="Facteur neutre (1.0)",
            )

            # Ligne verticale √† avgdl
            ax.axvline(
                x=avgdl_val,
                color="orange",
                linestyle=":",
                alpha=0.7,
                linewidth=2,
                label=f"avgdl ({avgdl_val:.0f} mots)",
            )

            ax.set_xlabel("Longueur du document (mots)", fontsize=11)
            ax.set_ylabel("Facteur de normalisation", fontsize=11)
            ax.set_title(
                "Effet de Normalisation par Longueur (Param√®tre b)",
                fontsize=12,
                fontweight="bold",
            )
            ax.legend(fontsize=9, loc="upper left")
            ax.grid(True, alpha=0.3)
            ax.set_xlim(10, 500)
            ax.set_ylim(0, 5)

            # Annotations
            ax.text(
                avgdl_val + 20,
                0.2,
                "Longueur moyenne",
                fontsize=9,
                color="orange",
                rotation=0,
            )
            ax.text(
                400,
                0.5,
                "‚Üê Docs courts\n   (boost)",
                fontsize=8,
                color="green",
                ha="right",
            )
            ax.text(
                400,
                4.5,
                "‚Üê Docs longs\n   (p√©nalit√©)",
                fontsize=8,
                color="red",
                ha="right",
            )

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with col_g2:
            st.markdown(f"""
            ### üìà Analyse du Graphique

            **Corpus actuel:**
            - avgdl = {bm25_demo.avgdl:.1f} mots

            **Ligne grise (b=0):**
            - Facteur = 1.0 constant
            - **Aucune p√©nalit√©**

            **Ligne bleue (b=0.5):**
            - P√©nalit√© mod√©r√©e

            **Ligne verte (b=0.75) ‚≠ê:**
            - Standard recommand√©
            - √âquilibre p√©nalit√©/boost

            **Ligne rouge (b=1.0):**
            - P√©nalit√© maximale
            - Comme TF-IDF classique

            **üí° Observation:**
            - **Docs < avgdl** ‚Üí boost (facteur < 1)
            - **Docs > avgdl** ‚Üí p√©nalit√© (facteur > 1)
            - Plus b est √©lev√©, plus l'effet est fort!

            **üéØ Recommandation:**
            b=0.75 pour la plupart des corpus!
            """)

    # === FORMULE COMPL√àTE ===
    with st.expander("üéØ **Formule Compl√®te BM25**"):
        st.markdown("""
        ### üî• La Grande Formule (tout ensemble!)
        """)

        st.latex(r"""
        \text{BM25}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \times \frac{f(q_i, D) \times (k1 + 1)}{f(q_i, D) + k1 \times \left(1 - b + b \times \frac{|D|}{\text{avgdl}}\right)}
        """)

        st.markdown("""
        ### üìñ D√©cortiquons la Formule

        **Œ£ (Somme):** On additionne pour **chaque mot** de la query

        **IDF(qi):** Raret√© du mot i dans le corpus (avec smoothing)

        **Num√©rateur:** f(qi, D) √ó (k1 + 1)
        ‚Üí Fr√©quence du mot, l√©g√®rement boost√©e

        **D√©nominateur:** f(qi, D) + k1 √ó [1 - b + b √ó |D|/avgdl]
        ‚Üí Fr√©quence + facteur de saturation √ó normalisation
        """)

        st.markdown("""
        ### üéì Algorithme en Pseudo-Code

        ```python
        def BM25(document, query, k1=1.5, b=0.75):
            score = 0

            for mot in query:
                # 1. Calculer IDF
                idf = log((N - n + 0.5) / (n + 0.5))

                # 2. Compter fr√©quence
                f = count(mot, document)

                # 3. Calculer normalisation
                norm = 1 - b + b * (len(document) / avgdl)

                # 4. Calculer TF satur√©
                tf = (f * (k1 + 1)) / (f + k1 * norm)

                # 5. Multiplier IDF √ó TF
                score += idf * tf

            return score
        ```
        """)

        st.success("""
        ### ‚úÖ Avantages de BM25

        1. **Saturation intelligente** via k1 (√©vite le spam)
        2. **Normalisation ajustable** via b (adapte au corpus)
        3. **IDF stable** avec smoothing (robuste)
        4. **Param√®tres tunables** (optimisation possible)
        5. **Standard industriel** (utilis√© partout!)
        """)


def render_bm25_search(
    documents_texts, documents_titles, documents_categories, remove_stopwords
):
    """Recherche interactive BM25"""
    st.header("üîç Recherche Interactive BM25")

    st.markdown("""
    Teste BM25 avec tes propres param√®tres!
    """)

    # Utiliser un formulaire pour soumission avec Enter
    with st.form("bm25_search_form", clear_on_submit=False):
        col1, col2, col3 = st.columns([2, 1, 1])

        with col1:
            query = st.text_input(
                "üîé Votre recherche:",
                value="plat italien fromage",  # Valeur par d√©faut!
                placeholder="Ex: plat italien, film science-fiction, guerre mondiale...",
                key="bm25_query_input",
                help='üí° **Exemples:** "plat italien fromage" | "science-fiction vaisseau espace" | "guerre conflit mondial arm√©e" | "football champion coupe"',
            )

        with col2:
            k1 = st.slider(
                "k1 (saturation)",
                min_value=0.0,
                max_value=3.0,
                value=1.5,
                step=0.1,
                help="‚öôÔ∏è Contr√¥le la saturation du TF. **Standard = 1.5** | Plus √©lev√© = moins de saturation | Plus bas = saturation rapide",
                key="bm25_k1_slider",
            )

        with col3:
            b = st.slider(
                "b (normalisation)",
                min_value=0.0,
                max_value=1.0,
                value=0.75,
                step=0.05,
                help="‚öôÔ∏è Contr√¥le la p√©nalit√© de longueur. **Standard = 0.75** | 0 = aucune | 1 = compl√®te",
                key="bm25_b_slider",
            )

        top_k = st.slider(
            "Nombre de r√©sultats:",
            3,
            20,
            5,
            key="bm25_topk_slider",
            help="Nombre de documents les plus pertinents √† afficher",
        )

        # Bouton de soumission (Enter fonctionne aussi!)
        submitted = st.form_submit_button("üöÄ Rechercher avec BM25!", type="primary")

    if submitted and query:
        with st.spinner("üîç Recherche BM25 en cours..."):
            # Cr√©er engine BM25 avec les param√®tres
            bm25_engine = BM25Engine(
                documents_texts, k1=k1, b=b, remove_stopwords=remove_stopwords
            )

            results = bm25_engine.search(query, top_k=top_k)

            if len(results) == 0 or all(score == 0 for _, score in results):
                st.warning("üòï Aucun r√©sultat. Essaie d'autres mots!")
            else:
                st.success(f"‚úÖ {len(results)} r√©sultats BM25 trouv√©s!")

                # === ANALYSE DES PARAM√àTRES ===
                st.markdown("### ‚öôÔ∏è Interpr√©tation de tes Param√®tres")

                col1, col2, col3 = st.columns(3)

                with col1:
                    # Analyse k1
                    if k1 < 1.0:
                        k1_interpretation = "**Saturation rapide** üöÄ (anti-spam)"
                        k1_color = "üü¢"
                    elif k1 < 1.8:
                        k1_interpretation = "**Standard** ‚≠ê (√©quilibr√©)"
                        k1_color = "üü°"
                    else:
                        k1_interpretation = (
                            "**Saturation lente** üêå (favorise r√©p√©titions)"
                        )
                        k1_color = "üî¥"

                    st.info(f"""
                    **k1 = {k1}** {k1_color}

                    {k1_interpretation}

                    Impact: Les mots plafonnent apr√®s ~{int(k1 * 10)} occurrences
                    """)

                with col2:
                    # Analyse b
                    if b < 0.5:
                        b_interpretation = (
                            "**Faible normalisation** (favorise docs longs)"
                        )
                        b_color = "üü¢"
                    elif b < 0.85:
                        b_interpretation = "**Normalisation standard** ‚≠ê"
                        b_color = "üü°"
                    else:
                        b_interpretation = (
                            "**Forte normalisation** (p√©nalise docs longs)"
                        )
                        b_color = "üî¥"

                    st.info(f"""
                    **b = {b}** {b_color}

                    {b_interpretation}

                    avgdl = {bm25_engine.avgdl:.1f} mots
                    """)

                with col3:
                    # Stats query
                    query_words = query.lower().split()
                    st.info(f"""
                    **Query:** {len(query_words)} mots

                    Mots: {", ".join(query_words[:3])}{"..." if len(query_words) > 3 else ""}

                    Corpus: {len(documents_texts)} docs
                    """)

                st.divider()

                # === VISUALISATION R√âSULTATS ===
                st.markdown("### üìä Visualisation des Scores")

                col_g1, col_g2 = st.columns([3, 2])  # Plus d'espace pour le graphique

                with col_g1:
                    fig_results = plot_search_results(results, documents_titles, query)
                    st.pyplot(fig_results)

                with col_g2:
                    st.markdown("### üìà Analyse des Scores")

                    all_scores = [score for _, score in results]
                    max_score = max(all_scores)
                    min_score = min(all_scores)
                    avg_score = np.mean(all_scores)

                    st.markdown(f"""
                    **Statistiques:**
                    - ü•á Score max: **{max_score:.4f}**
                    - ü•â Score min: **{min_score:.4f}**
                    - üìä Score moyen: **{avg_score:.4f}**
                    - üìè √âcart: **{(max_score - min_score):.4f}**

                    **Observations:**
                    """)

                    # Analyses automatiques
                    if max_score > avg_score * 3:
                        st.success(
                            "‚úÖ **Excellente s√©paration!** Le meilleur r√©sultat se d√©marque clairement."
                        )
                    elif max_score > avg_score * 1.5:
                        st.info(
                            "üí° **Bonne s√©paration.** Les r√©sultats sont bien diff√©renci√©s."
                        )
                    else:
                        st.warning(
                            "‚ö†Ô∏è **Faible s√©paration.** Les documents ont des scores similaires. Essaie de modifier k1 ou b."
                        )

                    if min_score < 0.1:
                        st.info(
                            "üìâ Les derniers r√©sultats ont des scores tr√®s faibles (< 0.1). Ils contiennent peu de mots de ta query."
                        )

                # === R√âSULTATS D√âTAILL√âS ===
                st.markdown("### üéØ Top R√©sultats D√©taill√©s")

                for rank, (doc_idx, score) in enumerate(results[:5], 1):
                    # Calcul du pourcentage par rapport au max
                    score_pct = (score / max_score * 100) if max_score > 0 else 0

                    with st.expander(
                        f"#{rank} - {documents_titles[doc_idx]} | BM25: {score:.3f} ({score_pct:.0f}%)"
                    ):
                        st.caption(f"üìÇ Cat√©gorie: {documents_categories[doc_idx]}")
                        st.write(documents_texts[doc_idx][:300] + "...")

                        # Info sur la longueur du doc
                        doc_length = len(documents_texts[doc_idx].split())
                        length_ratio = doc_length / bm25_engine.avgdl

                        col_info1, col_info2, col_info3 = st.columns(3)

                        with col_info1:
                            st.metric("Longueur", f"{doc_length} mots")
                        with col_info2:
                            st.metric("vs. Moyenne", f"{length_ratio:.2f}√ó")
                        with col_info3:
                            if length_ratio > 1.5:
                                st.metric("Type", "Long üìú")
                            elif length_ratio < 0.7:
                                st.metric("Type", "Court üìã")
                            else:
                                st.metric("Type", "Moyen üìÑ")

                        if st.checkbox(
                            f"üîç Voir calcul d√©taill√© #{rank}",
                            key=f"bm25_explain_{rank}",
                        ):
                            explanation = bm25_engine.explain(query, doc_idx)

                            st.markdown("""
                            #### üìê D√©tails du Calcul BM25
                            """)

                            # Afficher les valeurs cl√©s
                            col1, col2, col3 = st.columns(3)

                            with col1:
                                st.metric(
                                    "avgdl (corpus)", f"{explanation['avgdl']:.1f} mots"
                                )
                            with col2:
                                st.metric(
                                    "Longueur doc", f"{explanation['doc_length']} mots"
                                )
                            with col3:
                                st.metric(
                                    "Facteur norm", f"{explanation['norm_factor']:.3f}"
                                )

                            st.markdown(f"""
                            **Interpr√©tation du facteur de normalisation:**
                            - Valeur: **{explanation["norm_factor"]:.3f}**
                            - Si > 1: Document **p√©nalis√©** (plus long que la moyenne)
                            - Si = 1: Document de longueur **moyenne**
                            - Si < 1: Document **boost√©** (plus court que la moyenne)

                            **Score final BM25:** **{explanation["total_score"]:.4f}**
                            """)


def render_bm25_exploration(documents_texts, documents_titles, remove_stopwords):
    """Exploration & Tuning BM25"""
    st.header("üìä Exploration & Tuning des Param√®tres")

    st.markdown("""
    ### üéõÔ∏è Laboratoire de Tuning BM25

    Explore l'impact des param√®tres **k1** et **b** sur les scores!

    Cette heatmap montre le **score moyen** des top 5 r√©sultats pour diff√©rentes combinaisons de param√®tres.
    Plus la zone est rouge/chaude, meilleures sont les s√©parations de scores!
    """)

    test_query = st.text_input(
        "Query de test:",
        value="recette italienne",
        key="bm25_tuning_query",
        help='üí° Exemples: "plat italien" | "cuisine asiatique" | "dessert chocolat"',
    )

    if test_query:
        with st.spinner(
            "üî• Calcul de la heatmap pour toutes les combinaisons de param√®tres..."
        ):
            # Grille de valeurs √† tester
            k1_values = np.linspace(0.5, 3.0, 8)  # 8 valeurs de k1
            b_values = np.linspace(0.0, 1.0, 8)  # 8 valeurs de b

            # Matrice pour stocker les scores moyens
            score_matrix = np.zeros((len(b_values), len(k1_values)))

            # Calculer les scores pour chaque combinaison
            for i, b_val in enumerate(b_values):
                for j, k1_val in enumerate(k1_values):
                    # Cr√©er un engine BM25 avec ces param√®tres
                    engine = BM25Engine(
                        documents_texts[:100],  # Limiter √† 100 docs pour la rapidit√©
                        k1=k1_val,
                        b=b_val,
                        remove_stopwords=remove_stopwords,
                    )

                    # Rechercher
                    results = engine.search(test_query, top_k=5)

                    # Score moyen des top 5
                    if results:
                        avg_score = np.mean([score for _, score in results])
                        score_matrix[i, j] = avg_score
                    else:
                        score_matrix[i, j] = 0.0

        # === VISUALISATION HEATMAP ===
        col_heatmap, col_analysis = st.columns([3, 2])

        with col_heatmap:
            import matplotlib.pyplot as plt

            fig, ax = plt.subplots(figsize=(10, 8))

            # Heatmap avec annotations
            im = ax.imshow(score_matrix, cmap="YlOrRd", aspect="auto")

            # Axes
            ax.set_xticks(np.arange(len(k1_values)))
            ax.set_yticks(np.arange(len(b_values)))
            ax.set_xticklabels([f"{k1:.2f}" for k1 in k1_values], fontsize=9)
            ax.set_yticklabels([f"{b:.2f}" for b in b_values], fontsize=9)

            # Labels
            ax.set_xlabel("k1 (Saturation du TF)", fontsize=12, fontweight="bold")
            ax.set_ylabel(
                "b (Normalisation de longueur)", fontsize=12, fontweight="bold"
            )
            ax.set_title(
                f'Heatmap BM25: Impact de k1 et b\nQuery: "{test_query}"',
                fontsize=13,
                fontweight="bold",
                pad=15,
            )

            # Annotations des valeurs
            for i in range(len(b_values)):
                for j in range(len(k1_values)):
                    ax.text(
                        j,
                        i,
                        f"{score_matrix[i, j]:.2f}",
                        ha="center",
                        va="center",
                        color="black",
                        fontsize=8,
                    )

            # Marquer les valeurs standards (k1=1.5, b=0.75)
            k1_std_idx = np.argmin(np.abs(k1_values - 1.5))
            b_std_idx = np.argmin(np.abs(b_values - 0.75))
            ax.add_patch(
                plt.Rectangle(
                    (k1_std_idx - 0.5, b_std_idx - 0.5),
                    1,
                    1,
                    fill=False,
                    edgecolor="lime",
                    linewidth=3,
                )
            )
            ax.text(
                k1_std_idx,
                b_std_idx - 0.7,
                "‚≠ê",
                ha="center",
                fontsize=16,
                color="lime",
            )

            # Colorbar
            cbar = plt.colorbar(im, ax=ax)
            cbar.set_label("Score BM25 moyen (top 5)", fontsize=10)

            plt.tight_layout()
            st.pyplot(fig)
            plt.close()

        with col_analysis:
            st.markdown("### üîç Analyse de la Heatmap")

            # Trouver les meilleurs param√®tres
            best_idx = np.unravel_index(np.argmax(score_matrix), score_matrix.shape)
            best_b = b_values[best_idx[0]]
            best_k1 = k1_values[best_idx[1]]
            best_score = score_matrix[best_idx]

            # Valeurs standard
            std_score = score_matrix[b_std_idx, k1_std_idx]

            st.markdown(f"""
            **üèÜ Meilleure combinaison:**
            - k1 = **{best_k1:.2f}**
            - b = **{best_b:.2f}**
            - Score moyen = **{best_score:.3f}**

            **‚≠ê Valeurs standard (carr√© vert):**
            - k1 = **{k1_values[k1_std_idx]:.2f}**
            - b = **{b_values[b_std_idx]:.2f}**
            - Score moyen = **{std_score:.3f}**

            ---

            **üìä Observations:**
            """)

            # Analyses automatiques
            if best_score > std_score * 1.1:
                st.success(f"""
                ‚úÖ **Optimisation possible!**

                Les valeurs optimales donnent {((best_score / std_score - 1) * 100):.1f}% de meilleure s√©paration que les valeurs standard.
                """)
            else:
                st.info("""
                üí° **Standard = Optimal**

                Les valeurs par d√©faut (k1=1.5, b=0.75) fonctionnent d√©j√† tr√®s bien pour cette query!
                """)

            # Analyse par axe
            avg_by_k1 = np.mean(score_matrix, axis=0)
            avg_by_b = np.mean(score_matrix, axis=1)

            best_k1_overall = k1_values[np.argmax(avg_by_k1)]
            best_b_overall = b_values[np.argmax(avg_by_b)]

            st.markdown(f"""
            **üéØ Recommandations:**

            **Axe k1 (saturation):**
            - Valeur optimale moyenne: **{best_k1_overall:.2f}**
            - {"‚úÖ Saturation faible (< 1.0)" if best_k1_overall < 1.0 else "‚úÖ Saturation mod√©r√©e (1.0-2.0)" if best_k1_overall < 2.0 else "‚ö†Ô∏è Saturation √©lev√©e (> 2.0)"}

            **Axe b (normalisation):**
            - Valeur optimale moyenne: **{best_b_overall:.2f}**
            - {"‚úÖ Pas de normalisation (< 0.3)" if best_b_overall < 0.3 else "‚úÖ Normalisation mod√©r√©e (0.3-0.8)" if best_b_overall < 0.8 else "‚ö†Ô∏è Forte normalisation (> 0.8)"}
            """)

            st.warning("""
            ‚ö†Ô∏è **Note:**

            Ces r√©sultats d√©pendent de:
            - La query test√©e
            - Le corpus utilis√©
            - La longueur des documents

            Teste plusieurs queries pour trouver les meilleurs param√®tres globaux!
            """)


def render_bm25_stepbystep(documents_texts, documents_titles, remove_stopwords):
    """Exemple pas-√†-pas BM25 - HYPER D√âTAILL√â"""
    st.header("üéì Calcul BM25 Pas-√†-Pas (Exemple Complet)")

    st.markdown("""
    Suivons **TOUTES les √©tapes** du calcul BM25, de A √† Z, avec des **exemples concrets**!

    On va d√©cortiquer chaque formule et voir comment BM25 classe les documents.
    """)

    # === S√âLECTION DOCUMENTS ===
    st.markdown("## üìÑ Documents d'Exemple")

    sample_indices = list(range(min(3, len(documents_texts))))
    sample_texts = [documents_texts[i] for i in sample_indices]
    sample_titles = [documents_titles[i] for i in sample_indices]

    for idx, (title, text) in enumerate(zip(sample_titles, sample_texts)):
        with st.expander(f"üìÑ **Document {idx + 1}:** {title}"):
            st.write(text)
            st.caption(f"Longueur: {len(text.split())} mots")

    st.divider()

    # === QUERY ===
    query = st.text_input(
        "üîé Entre ta Query:",
        value="italien fromage",
        key="bm25_tutorial",
        help='üí° Teste avec: "italien fromage" | "chocolat dessert" | "poisson grill√©" | "asiatique √©pic√©"',
    )

    if query:
        # === PARAM√àTRES ===
        st.markdown("## ‚öôÔ∏è Param√®tres BM25")

        col1, col2 = st.columns(2)
        with col1:
            k1_tutorial = st.number_input(
                "k1 (saturation):",
                min_value=0.0,
                max_value=3.0,
                value=1.5,
                step=0.1,
                key="bm25_tutorial_k1",
                help="Contr√¥le la saturation du TF. Standard = 1.5",
            )
        with col2:
            b_tutorial = st.number_input(
                "b (normalisation):",
                min_value=0.0,
                max_value=1.0,
                value=0.75,
                step=0.05,
                key="bm25_tutorial_b",
                help="Contr√¥le la p√©nalit√© de longueur. Standard = 0.75",
            )

        st.divider()

        # Cr√©er l'engine BM25
        mini_bm25 = BM25Engine(
            sample_texts,
            k1=k1_tutorial,
            b=b_tutorial,
            remove_stopwords=remove_stopwords,
        )

        # Preprocessing de la query
        from src.bm25_engine import preprocess_text

        query_words = preprocess_text(query, remove_stopwords=remove_stopwords)

        # === √âTAPE 0: STATS CORPUS ===
        with st.expander("**üìä √âtape 0: Statistiques du Mini-Corpus**", expanded=False):
            st.markdown("""
            ### Avant de calculer BM25, analysons notre corpus!
            """)

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("Nombre de documents (N)", mini_bm25.N)
            with col2:
                st.metric("Vocabulaire", len(mini_bm25.vocabulary))
            with col3:
                st.metric("Longueur moyenne (avgdl)", f"{mini_bm25.avgdl:.1f} mots")

            # Tableau des longueurs
            lengths_data = []
            for idx, text in enumerate(sample_texts):
                doc_length = len(text.split())
                ratio = doc_length / mini_bm25.avgdl
                lengths_data.append(
                    {
                        "Document": sample_titles[idx][:30],
                        "Longueur": doc_length,
                        "vs. Moyenne": f"{ratio:.2f}√ó",
                    }
                )

            df_lengths = pd.DataFrame(lengths_data)
            st.dataframe(df_lengths, use_container_width=True)

            st.info(f"""
            üí° **avgdl** est crucial pour BM25! Les documents plus longs que {mini_bm25.avgdl:.1f} mots seront p√©nalis√©s (si b > 0).
            """)

        # === √âTAPE 1: IDF ===
        with st.expander(
            "**üìâ √âtape 1: Calcul des IDF (Inverse Document Frequency)**",
            expanded=False,
        ):
            st.markdown("""
            ### Formule BM25 IDF (avec smoothing)
            """)

            st.latex(
                r"\text{IDF}(t) = \log\left(\frac{N - n(t) + 0.5}{n(t) + 0.5}\right)"
            )

            st.markdown(
                """
            O√π:
            - **N** = nombre total de documents (ici: {})
            - **n(t)** = nombre de docs contenant le terme t
            - **+0.5** = smoothing de Laplace
            """.format(mini_bm25.N)
            )

            # Calculer IDF pour chaque mot de la query
            idf_data = []
            for word in query_words:
                if word in mini_bm25.vocabulary:
                    n_t = mini_bm25.doc_freqs.get(word, 0)
                    idf = np.log((mini_bm25.N - n_t + 0.5) / (n_t + 0.5))

                    idf_data.append(
                        {
                            "Mot": word,
                            "n(t)": n_t,
                            "Calcul": f"log(({mini_bm25.N} - {n_t} + 0.5) / ({n_t} + 0.5))",
                            "IDF": f"{idf:.4f}",
                        }
                    )
                else:
                    idf_data.append(
                        {"Mot": word, "n(t)": 0, "Calcul": "Mot absent", "IDF": "N/A"}
                    )

            df_idf = pd.DataFrame(idf_data)
            st.dataframe(df_idf, use_container_width=True)

            st.markdown("""
            ### üí° Interpr√©tation

            - **IDF √©lev√©** ‚Üí Mot rare ‚Üí Plus important!
            - **IDF faible** ‚Üí Mot commun ‚Üí Moins important
            - Le smoothing (+0.5) √©vite les divisions par z√©ro et stabilise les valeurs
            """)

        # === √âTAPE 2: FR√âQUENCES ===
        with st.expander("**üî¢ √âtape 2: Comptage des Fr√©quences**", expanded=False):
            st.markdown("""
            ### Comptons combien de fois chaque mot de la query appara√Æt dans chaque document!
            """)

            freq_data = []
            for doc_idx, text in enumerate(sample_texts):
                row = {"Document": sample_titles[doc_idx][:30]}
                doc_words = preprocess_text(text, remove_stopwords=remove_stopwords)

                for word in query_words:
                    count = doc_words.count(word)
                    row[word] = count

                freq_data.append(row)

            df_freq = pd.DataFrame(freq_data)
            st.dataframe(df_freq, use_container_width=True)

            st.info("""
            üìå **Note:** Ce sont les fr√©quences brutes (nombre d'occurrences).
            BM25 va les **saturer** avec le param√®tre k1!
            """)

        # === √âTAPE 3: NORMALISATION ===
        with st.expander("**‚öñÔ∏è √âtape 3: Facteurs de Normalisation**", expanded=False):
            st.markdown("""
            ### Formule de Normalisation
            """)

            st.latex(r"\text{norm}(D) = 1 - b + b \times \frac{|D|}{\text{avgdl}}")

            st.markdown(f"""
            Param√®tres:
            - **b** = {b_tutorial} (intensit√© de la p√©nalit√©)
            - **avgdl** = {mini_bm25.avgdl:.1f} mots
            """)

            norm_data = []
            for doc_idx, text in enumerate(sample_texts):
                doc_length = len(text.split())
                norm_factor = (
                    1 - b_tutorial + b_tutorial * (doc_length / mini_bm25.avgdl)
                )

                norm_data.append(
                    {
                        "Document": sample_titles[doc_idx][:30],
                        "|D| (longueur)": doc_length,
                        "Calcul": f"1 - {b_tutorial} + {b_tutorial} √ó ({doc_length}/{mini_bm25.avgdl:.1f})",
                        "Facteur norm": f"{norm_factor:.3f}",
                    }
                )

            df_norm = pd.DataFrame(norm_data)
            st.dataframe(df_norm, use_container_width=True)

            st.markdown("""
            ### üí° Interpr√©tation

            - **norm > 1** ‚Üí Document **p√©nalis√©** (plus long que la moyenne)
            - **norm = 1** ‚Üí Document de longueur moyenne
            - **norm < 1** ‚Üí Document **boost√©** (plus court que la moyenne)

            Ce facteur sera utilis√© dans le d√©nominateur de BM25!
            """)

        # === √âTAPE 4: TF SATUR√â ===
        with st.expander("**üéõÔ∏è √âtape 4: TF Satur√© (avec k1)**", expanded=False):
            st.markdown("""
            ### Formule du TF Satur√© BM25
            """)

            st.latex(
                r"\text{TF}_{\text{BM25}} = \frac{f \times (k1 + 1)}{f + k1 \times \text{norm}}"
            )

            st.markdown(f"""
            O√π:
            - **f** = fr√©quence du mot dans le doc
            - **k1** = {k1_tutorial} (contr√¥le la saturation)
            - **norm** = facteur de normalisation (calcul√© √† l'√©tape 3)
            """)

            # Calculer TF satur√© pour chaque mot dans chaque doc
            tf_data = []
            for doc_idx, text in enumerate(sample_texts):
                doc_words = preprocess_text(text, remove_stopwords=remove_stopwords)
                doc_length = len(text.split())
                norm_factor = (
                    1 - b_tutorial + b_tutorial * (doc_length / mini_bm25.avgdl)
                )

                row = {"Document": sample_titles[doc_idx][:30]}

                for word in query_words:
                    f = doc_words.count(word)
                    tf_bm25 = (f * (k1_tutorial + 1)) / (f + k1_tutorial * norm_factor)
                    row[f"{word} (f={f})"] = f"{tf_bm25:.4f}"

                tf_data.append(row)

            df_tf = pd.DataFrame(tf_data)
            st.dataframe(df_tf, use_container_width=True)

            st.markdown("""
            ### üí° Observation Cl√©

            Contrairement √† TF-IDF (o√π TF = f/longueur), ici le TF **plafonne**!

            - Si f = 0 ‚Üí TF = 0
            - Si f = 1 ‚Üí TF ‚âà 1.0
            - Si f = 10 ‚Üí TF ‚âà 1.3 (saturation!)
            - Si f = 100 ‚Üí TF ‚âà 1.5 (plateau atteint!)

            **C'est le c≈ìur de BM25!** üéØ
            """)

        # === √âTAPE 5: BM25 FINAL ===
        with st.expander("**üéØ √âtape 5: Score BM25 Final (IDF √ó TF)**", expanded=False):
            st.markdown("""
            ### Formule Compl√®te BM25
            """)

            st.latex(r"""
            \text{BM25}(D) = \sum_{t \in Q} \text{IDF}(t) \times \frac{f(t, D) \times (k1 + 1)}{f(t, D) + k1 \times \text{norm}(D)}
            """)

            st.markdown("""
            On **multiplie IDF √ó TF** pour chaque mot, puis on **additionne**!
            """)

            # Calculer BM25 complet
            bm25_data = []
            for doc_idx, text in enumerate(sample_texts):
                doc_words = preprocess_text(text, remove_stopwords=remove_stopwords)
                doc_length = len(text.split())
                norm_factor = (
                    1 - b_tutorial + b_tutorial * (doc_length / mini_bm25.avgdl)
                )

                total_score = 0
                details = []

                for word in query_words:
                    if word in mini_bm25.vocabulary:
                        # IDF
                        n_t = mini_bm25.doc_freqs.get(word, 0)
                        idf = np.log((mini_bm25.N - n_t + 0.5) / (n_t + 0.5))

                        # TF satur√©
                        f = doc_words.count(word)
                        tf = (f * (k1_tutorial + 1)) / (f + k1_tutorial * norm_factor)

                        # Score du mot
                        word_score = idf * tf
                        total_score += word_score

                        details.append(
                            f"{word}: {idf:.3f} √ó {tf:.3f} = {word_score:.4f}"
                        )

                bm25_data.append(
                    {
                        "Document": sample_titles[doc_idx][:30],
                        "D√©tail": " + ".join(details)
                        if details
                        else "Aucun mot trouv√©",
                        "Score BM25": f"{total_score:.4f}",
                    }
                )

            df_bm25 = pd.DataFrame(bm25_data)
            st.dataframe(df_bm25, use_container_width=True, height=200)

            st.success("""
            ‚úÖ **Voil√† le score BM25 final!**
            Plus le score est √©lev√©, plus le document est pertinent pour la query.
            """)

        # === √âTAPE 6: CLASSEMENT ===
        with st.expander("**üèÜ √âtape 6: Classement Final**", expanded=True):
            st.markdown("""
            ### Classement par Score BM25 D√©croissant
            """)

            results = mini_bm25.search(query, top_k=3)

            if len(results) == 0:
                st.warning("üòï Aucun r√©sultat trouv√©!")
            else:
                for rank, (doc_idx, score) in enumerate(results, 1):
                    if rank == 1:
                        medal = "ü•á"
                    elif rank == 2:
                        medal = "ü•à"
                    else:
                        medal = "ü•â"

                    st.markdown(f"""
                    {medal} **#{rank} - {sample_titles[doc_idx]}**
                    Score BM25: **{score:.4f}**
                    """)

                    # Snippet
                    st.caption(sample_texts[doc_idx][:150] + "...")

                st.divider()

                st.markdown("""
                ### üéì Conclusion

                Nous avons calcul√© BM25 **de A √† Z**:

                1. ‚úÖ **IDF** avec smoothing (raret√© des mots)
                2. ‚úÖ **Fr√©quences** brutes (comptage)
                3. ‚úÖ **Normalisation** par longueur (facteur b)
                4. ‚úÖ **TF satur√©** (effet de plateau k1)
                5. ‚úÖ **Multiplication** IDF √ó TF pour chaque mot
                6. ‚úÖ **Classement** des documents

                **BM25 > TF-IDF** car il √©vite la saturation lin√©aire et permet de tuner les param√®tres! üöÄ
                """)


def render_bm25_comparison(
    documents_texts, documents_titles, tfidf_engine, remove_stopwords
):
    """Comparaison TF-IDF vs BM25 - ENRICHIE"""
    st.header("‚öîÔ∏è TF-IDF vs BM25: Le Duel!")

    st.markdown("""
    ### üéØ Objectif

    Comparons les **deux algorithmes** sur la **m√™me requ√™te** pour voir:
    - Quels documents sont retrouv√©s par chacun
    - Comment les scores diff√®rent
    - Quel algorithme performe mieux
    """)

    query_compare = st.text_input(
        "üîé Requ√™te de comparaison:",
        value="recette italienne p√¢tes fromage",
        key="compare_query",
        help="üí° Teste avec plusieurs mots pour voir la diff√©rence!",
    )

    top_k_compare = st.slider("Nombre de r√©sultats:", 5, 20, 10, key="compare_topk")

    if query_compare and st.button(
        "‚öîÔ∏è Lancer la Comparaison!", type="primary", key="compare_btn"
    ):
        with st.spinner("‚öîÔ∏è Comparaison en cours..."):
            start_tfidf = time_module.time()
            tfidf_results = tfidf_engine.search(query_compare, top_k=top_k_compare)
            time_tfidf = (time_module.time() - start_tfidf) * 1000  # ms

            start_bm25 = time_module.time()
            bm25_engine = BM25Engine(
                documents_texts, k1=1.5, b=0.75, remove_stopwords=remove_stopwords
            )
            bm25_results = bm25_engine.search(query_compare, top_k=top_k_compare)
            time_bm25 = (time_module.time() - start_bm25) * 1000  # ms

            # === M√âTRIQUES RAPIDES ===
            st.markdown("## üìä M√©triques Globales")

            col1, col2, col3, col4 = st.columns(4)

            tfidf_indices = set([idx for idx, _ in tfidf_results])
            bm25_indices = set([idx for idx, _ in bm25_results])
            overlap = len(tfidf_indices.intersection(bm25_indices))

            col1.metric("‚è±Ô∏è TF-IDF", f"{time_tfidf:.2f} ms")
            col2.metric("‚è±Ô∏è BM25", f"{time_bm25:.2f} ms")
            col3.metric(
                "üìä Overlap",
                f"{overlap}/{top_k_compare}",
                f"{(overlap / top_k_compare * 100):.0f}%",
            )
            col4.metric(
                "üéØ Concordance",
                "√âlev√©e"
                if overlap > top_k_compare * 0.7
                else "Moyenne"
                if overlap > top_k_compare * 0.4
                else "Faible",
            )

            st.divider()

            # === VISUALISATION COMPARATIVE ===
            st.markdown("## üìà Comparaison Visuelle des Scores")

            col_g1, col_g2 = st.columns(2)

            with col_g1:
                # Graphique de comparaison TF-IDF vs BM25
                fig_comparison = plot_tfidf_bm25_comparison(
                    tfidf_results,
                    bm25_results,
                    documents_titles,
                    query_compare,
                    top_k=top_k_compare
                )
                st.pyplot(fig_comparison)
                plt.close()

            with col_g2:
                st.markdown("### üìä Analyse du Graphique")

                # Analyses statistiques
                tfidf_scores = [score for _, score in tfidf_results]
                bm25_scores = [score for _, score in bm25_results]

                tfidf_max = max(tfidf_scores)
                bm25_max = max(bm25_scores)
                tfidf_range = max(tfidf_scores) - min(tfidf_scores)
                bm25_range = max(bm25_scores) - min(bm25_scores)

                st.markdown(f"""
                **TF-IDF:**
                - Score max: **{tfidf_max:.4f}**
                - √âcart: **{tfidf_range:.4f}**

                **BM25:**
                - Score max: **{bm25_max:.4f}**
                - √âcart: **{bm25_range:.4f}**

                **Observations:**
                """)

                if bm25_range > tfidf_range * 1.2:
                    st.success(
                        "‚úÖ **BM25 a une meilleure s√©paration** des scores! Les r√©sultats sont plus diff√©renci√©s."
                    )
                elif tfidf_range > bm25_range * 1.2:
                    st.info(
                        "üí° **TF-IDF a une meilleure s√©paration** pour cette query."
                    )
                else:
                    st.info("üí° **S√©paration similaire** entre les deux algorithmes.")

            st.divider()

            # === ANALYSE DES DIFF√âRENCES ===
            st.markdown("## üîç Analyse des Diff√©rences")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### üî¥ Uniques √† TF-IDF")
                tfidf_unique = tfidf_indices - bm25_indices
                if len(tfidf_unique) > 0:
                    for idx in list(tfidf_unique)[:3]:
                        tfidf_score = next(
                            score for doc_idx, score in tfidf_results if doc_idx == idx
                        )
                        st.markdown(
                            f"- **{documents_titles[idx][:40]}** (score: {tfidf_score:.4f})"
                        )
                    st.caption(f"Total: {len(tfidf_unique)} documents uniques")
                else:
                    st.info("Aucun document unique!")

            with col2:
                st.markdown("### üü¢ Uniques √† BM25")
                bm25_unique = bm25_indices - tfidf_indices
                if len(bm25_unique) > 0:
                    for idx in list(bm25_unique)[:3]:
                        bm25_score = next(
                            score for doc_idx, score in bm25_results if doc_idx == idx
                        )
                        st.markdown(
                            f"- **{documents_titles[idx][:40]}** (score: {bm25_score:.4f})"
                        )
                    st.caption(f"Total: {len(bm25_unique)} documents uniques")
                else:
                    st.info("Aucun document unique!")

            st.divider()

            # === DISTRIBUTION DES SCORES ===
            st.markdown("## üìä Distribution des Scores")

            col_dist1, col_dist2 = st.columns(2)

            with col_dist1:
                # Histogrammes de distribution des scores
                fig_distributions = plot_score_distributions(tfidf_scores, bm25_scores)
                st.pyplot(fig_distributions)
                plt.close()

            with col_dist2:
                st.markdown("### üìà Interpr√©tation")

                st.markdown("""
                **Histogrammes:**
                - Montrent la **r√©partition** des scores
                - TF-IDF (rouge) vs BM25 (vert)

                **Id√©al:**
                - Distribution **√©tal√©e** (bonne s√©paration)
                - Pic √† gauche (faibles scores)
                - Queue √† droite (bons r√©sultats)
                """)

                # Calcul de la variance pour mesurer la dispersion
                import numpy as np

                var_tfidf = np.var(tfidf_scores)
                var_bm25 = np.var(bm25_scores)

                if var_bm25 > var_tfidf * 1.2:
                    st.success(
                        "‚úÖ **BM25 a une meilleure dispersion** ‚Üí R√©sultats plus diff√©renci√©s"
                    )
                elif var_tfidf > var_bm25 * 1.2:
                    st.info("üí° **TF-IDF a une meilleure dispersion** pour cette query")
                else:
                    st.info("üí° **Dispersion similaire**")

            st.divider()

            # === CONCLUSION ===
            st.markdown("## üéì Conclusion")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                ### üî¥ TF-IDF

                **Avantages:**
                - ‚úÖ Simple √† comprendre
                - ‚úÖ Rapide √† calculer
                - ‚úÖ Pas de param√®tres

                **Inconv√©nients:**
                - ‚ùå Saturation lin√©aire
                - ‚ùå Normalisation rigide
                - ‚ùå Pas ajustable
                """)

            with col2:
                st.markdown("""
                ### üü¢ BM25

                **Avantages:**
                - ‚úÖ Saturation intelligente (k1)
                - ‚úÖ Normalisation ajustable (b)
                - ‚úÖ IDF am√©lior√© (smoothing)
                - ‚úÖ Standard industriel

                **Inconv√©nients:**
                - ‚ö†Ô∏è L√©g√®rement plus complexe
                - ‚ö†Ô∏è N√©cessite tuning des param√®tres
                """)

            overlap_pct = (overlap / top_k_compare) * 100
            if overlap_pct > 70:
                st.success(f"""
                ‚úÖ **Accord √©lev√© ({overlap_pct:.0f}%):** Les deux algorithmes sont coh√©rents!
                BM25 apporte surtout une **meilleure s√©paration** des scores.
                """)
            elif overlap_pct > 40:
                st.info(f"""
                üí° **Accord mod√©r√© ({overlap_pct:.0f}%):** Les algorithmes diff√®rent!
                BM25 trouve des documents que TF-IDF manque (et vice-versa).
                """)
            else:
                st.warning(f"""
                ‚ö†Ô∏è **Accord faible ({overlap_pct:.0f}%):** R√©sultats tr√®s diff√©rents!
                Cela peut indiquer que **BM25 est plus adapt√©** √† ce corpus.
                """)


def render_bm25_performance(documents_texts, remove_stopwords):
    """Performance BM25 - HYPER D√âTAILL√âE"""
    st.header("‚ö° Performances BM25: Analyse Compl√®te")

    st.markdown("""
    Analysons en profondeur les **performances de BM25** et comparons-les avec TF-IDF!
    """)

    # === COMPLEXIT√â ALGORITHMIQUE ===
    st.markdown("## üßÆ Complexit√© Algorithmique")

    st.markdown("""
    **Question importante:** BM25 est-il plus lent que TF-IDF? ü§î
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.info("""
        ### üî¥ TF-IDF

        **Preprocessing (indexation):**
        - Compter les mots: O(n √ó m)
        - Calculer IDF: O(v)
        - Calculer TF-IDF: O(n √ó v)

        **Recherche:**
        - Vectoriser query: O(|q|)
        - Cosine similarity: O(n √ó v)

        **Total:** O(n √ó m + n √ó v)
        """)

    with col2:
        st.success("""
        ### üü¢ BM25

        **Preprocessing (indexation):**
        - Compter les mots: O(n √ó m)
        - Calculer avgdl: O(n)
        - Calculer IDF: O(v)

        **Recherche:**
        - Calculer BM25: O(n √ó |q|)

        **Total:** O(n √ó m + n √ó |q|)

        ‚úÖ **Identique!**
        """)

    st.markdown("""
    ### üí° Pourquoi M√™me Complexit√©?

    Les calculs suppl√©mentaires de BM25 sont en **O(1)** par terme:
    - **norm_factor** = `1 - b + b √ó (|D| / avgdl)` ‚Üí **O(1)**
    - **TF satur√©** = `f √ó (k1 + 1) / (f + k1 √ó norm)` ‚Üí **O(1)**

    Ces multiplications/divisions sont **n√©gligeables** par rapport au comptage des mots!

    **Conclusion:** BM25 n'est **PAS** plus lent que TF-IDF en pratique! üöÄ
    """)

    st.divider()

    # === M√âTRIQUES DU CORPUS ACTUEL ===
    st.markdown("## üìä M√©triques du Corpus Actuel")

    # Mesurer le temps de chargement
    start_load = time_module.time()
    n_docs = len(documents_texts)
    total_words = sum(len(doc.split()) for doc in documents_texts)
    avg_length = total_words / n_docs if n_docs > 0 else 0
    time_load = (time_module.time() - start_load) * 1000

    # Mesurer l'indexation BM25
    start_index = time_module.time()
    bm25_engine = BM25Engine(
        documents_texts, k1=1.5, b=0.75, remove_stopwords=remove_stopwords
    )
    time_index = (time_module.time() - start_index) * 1000

    vocab_size = len(bm25_engine.vocabulary)

    col1, col2, col3, col4 = st.columns(4)

    col1.metric("üìö Documents", f"{n_docs:,}")
    col2.metric("üìñ Vocabulaire", f"{vocab_size:,}")
    col3.metric("üìè Longueur moy.", f"{avg_length:.1f} mots")
    col4.metric("üí¨ Total mots", f"{total_words:,}")

    st.divider()

    col_t1, col_t2, col_t3 = st.columns(3)

    col_t1.metric("‚è±Ô∏è Chargement", f"{time_load:.2f} ms")
    col_t2.metric("‚è±Ô∏è Indexation BM25", f"{time_index:.2f} ms")

    # Efficacit√©
    docs_per_sec = (n_docs / time_index * 1000) if time_index > 0 else 0
    if docs_per_sec > 1000:
        efficiency = "Ultra rapide! üöÄ"
        col_t3.metric("üöÄ Efficacit√©", f"{docs_per_sec:.0f} docs/s", delta="Excellent")
    elif docs_per_sec > 100:
        efficiency = "Rapide! ‚úÖ"
        col_t3.metric("‚ö° Efficacit√©", f"{docs_per_sec:.0f} docs/s", delta="Bon")
    else:
        efficiency = "Lent... ‚ö†Ô∏è"
        col_t3.metric("üêå Efficacit√©", f"{docs_per_sec:.0f} docs/s", delta="Am√©liorer")

    st.info(f"""
    üí° **Interpr√©tation:** {efficiency}
    BM25 a index√© {n_docs:,} documents en **{time_index:.2f} ms** ({docs_per_sec:.0f} docs/s).
    """)

    st.divider()

    # === EXPLICATION COMPLEXIT√â ===
    st.markdown("## üìñ Comprendre la Complexit√© O(n √ó m)")

    st.markdown("""
    ### Que signifient **n** et **m**?

    - **n** = nombre de documents dans le corpus
    - **m** = longueur moyenne d'un document (en mots)
    - **v** = taille du vocabulaire (mots uniques)
    - **|q|** = longueur de la query
    """)

    st.markdown(f"""
    ### Pour ton corpus actuel:

    - **n** = {n_docs:,} documents
    - **m** = {avg_length:.0f} mots/doc (moyenne)
    - **v** = {vocab_size:,} mots uniques

    **Complexit√© d'indexation:** O({n_docs:,} √ó {avg_length:.0f}) = O({n_docs * avg_length:,.0f}) op√©rations
    """)

    with st.expander("üîç Voir le D√©tail des Op√©rations"):
        st.markdown(f"""
        ### √âtapes de l'Indexation BM25

        **1. Tokenisation (parcourir tous les mots):**
        - {n_docs:,} docs √ó {avg_length:.0f} mots = **{n_docs * avg_length:,.0f} mots** √† traiter
        - Complexit√©: **O(n √ó m)**

        **2. Construction du vocabulaire:**
        - Ajouter chaque mot unique dans un dictionnaire
        - Complexit√©: **O(n √ó m)** (pire cas)
        - R√©sultat: **{vocab_size:,} mots uniques**

        **3. Calcul de avgdl (longueur moyenne):**
        - Somme des longueurs / nombre de docs
        - Complexit√©: **O(n)**
        - R√©sultat: **avgdl = {bm25_engine.avgdl:.1f} mots**

        **4. Comptage des documents contenant chaque mot (pour IDF):**
        - Pour chaque mot, compter dans combien de docs il appara√Æt
        - Complexit√©: **O(n √ó v)** (pire cas)

        **Total:** O(n √ó m + n √ó v) ‚âà **O(n √ó m)** (car g√©n√©ralement m > v pour un doc)
        """)

    st.markdown(r"""
    ### üìà Impact de Doubler n ou m

    | Action | Impact sur Temps | Exemple |
    |--------|------------------|---------|
    | **n √ó 2** (doubler les docs) | **Temps √ó 2** | 1000 ‚Üí 2000 docs |
    | **m √ó 2** (docs 2√ó plus longs) | **Temps √ó 2** | 100 ‚Üí 200 mots/doc |
    | **v √ó 2** (vocabulaire 2√ó plus grand) | Impact faible | 5000 ‚Üí 10000 mots |
    | **\|q\| √ó 2** (query 2√ó plus longue) | Impact faible (recherche only) | 3 ‚Üí 6 mots |

    **Conclusion:** Le nombre de documents **n** et leur longueur **m** sont les facteurs cl√©s!
    """)

    st.divider()

    # === BENCHMARKS AUTOMATIQUES ===
    st.markdown("## üèÅ Benchmarks Automatiques Multi-Datasets")

    st.markdown("""
    Testons BM25 sur **diff√©rents datasets** pour voir l'impact de la taille du corpus!
    """)

    # Checkbox pour inclure les datasets √©tendus
    include_extended_bm25 = st.checkbox(
        "üì¶ Inclure les datasets √©tendus (plus long: ~2-3 minutes)",
        value=False,
        help="Teste aussi les versions √©tendues des datasets pour voir l'impact sur les performances",
        key="bm25_bench_extended",
    )

    if include_extended_bm25:
        st.warning("""
        ‚ö†Ô∏è **Attention:** Avec les datasets √©tendus, les benchmarks prendront **2-3 minutes**.

        On testera:
        - üçù Recettes: **50 ‚Üí 200** docs
        - üé¨ Films: **50 ‚Üí 200** docs
        - üìñ Livres: **100 ‚Üí 801** docs
        - üìö Wikipedia: **100 ‚Üí 1000** docs
        """)
    else:
        st.info("""
        On testera les datasets en mode normal (~30 secondes):
        - üçù Recettes: **50** docs
        - üé¨ Films: **50** docs
        - üìñ Livres: **100** docs
        - üìö Wikipedia: **100** docs
        """)

    if st.button("üöÄ Lancer les Benchmarks!", type="primary", key="bm25_bench_btn"):
        spinner_text = (
            "‚è≥ Benchmarks en cours... (2-3 minutes)"
            if include_extended_bm25
            else "‚è≥ Benchmarks en cours... (30 secondes)"
        )

        with st.spinner(spinner_text):
            from src.data_loader import load_dataset

            benchmark_results = []

            # D√©finir les datasets selon le mode
            if include_extended_bm25:
                test_configs = [
                    ("recettes", False, "Recettes (50 docs)"),
                    ("films", False, "Films (50 docs)"),
                    ("livres", False, "Livres (100 docs)"),
                    ("recettes", True, "Recettes √©tendu (200 docs)"),
                    ("films", True, "Films √©tendu (200 docs)"),
                    ("wikipedia", False, "Wikipedia (100 docs)"),
                    ("livres", True, "Livres √©tendu (801 docs)"),
                    ("wikipedia", True, "Wikipedia √©tendu (1000 docs)"),
                ]
            else:
                # Mode rapide: seulement les datasets normaux
                test_configs = [
                    ("recettes", False, "Recettes (50 docs)"),
                    ("films", False, "Films (50 docs)"),
                    ("livres", False, "Livres (100 docs)"),
                    ("wikipedia", False, "Wikipedia (100 docs)"),
                ]

            for dataset_name, extended, label in test_configs:
                try:
                    # Charger le dataset
                    start = time_module.time()
                    dataset = load_dataset(dataset_name, extended=extended)
                    time_load_bench = (time_module.time() - start) * 1000

                    if len(dataset) == 0:
                        continue

                    texts = [doc["text"] for doc in dataset]
                    n_bench = len(texts)

                    # Indexation BM25
                    start = time_module.time()
                    bm25_bench = BM25Engine(
                        texts, k1=1.5, b=0.75, remove_stopwords=remove_stopwords
                    )
                    time_index_bench = (time_module.time() - start) * 1000

                    # Recherche test
                    test_query = "test recherche exemple"
                    start = time_module.time()
                    _ = bm25_bench.search(test_query, top_k=5)
                    time_search = (time_module.time() - start) * 1000

                    vocab_bench = len(bm25_bench.vocabulary)

                    benchmark_results.append(
                        {
                            "Dataset": label,
                            "Docs": n_bench,
                            "Vocab": vocab_bench,
                            "Load (s)": f"{time_load_bench / 1000:.3f}",
                            "Index (s)": f"{time_index_bench / 1000:.3f}",
                            "Search (s)": f"{time_search / 1000:.3f}",
                            "Total (s)": f"{(time_load_bench + time_index_bench) / 1000:.3f}",
                            "_total_numeric": (time_load_bench + time_index_bench)
                            / 1000,
                            "_docs_numeric": n_bench,
                        }
                    )

                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erreur avec {dataset_name}: {str(e)}")
                    continue

            if len(benchmark_results) > 0:
                # Afficher les r√©sultats
                st.markdown("### üìä R√©sultats des Benchmarks")

                df_bench = pd.DataFrame(benchmark_results)
                df_display = df_bench.drop(columns=["_total_numeric", "_docs_numeric"])
                st.dataframe(df_display, use_container_width=True, hide_index=True)

                st.markdown("---")

                # Graphique: Temps vs Nombre de docs (style TF-IDF)
                st.markdown(
                    "### üìà Graphique: Temps d'Indexation vs Nombre de Documents"
                )

                col_graph, col_analysis = st.columns([2, 1])

                with col_graph:
                    import matplotlib.pyplot as plt

                    x = [r["_docs_numeric"] for r in benchmark_results]
                    y = [r["_total_numeric"] for r in benchmark_results]
                    labels = [r["Dataset"] for r in benchmark_results]

                    fig, ax = plt.subplots(figsize=(8, 5))

                    # Scatter plot
                    ax.scatter(x, y, s=100, alpha=0.6, color="#2ca02c")

                    # Labels pour chaque point
                    for i, label in enumerate(labels):
                        ax.annotate(
                            label.split("(")[0].strip(),
                            (x[i], y[i]),
                            xytext=(5, 5),
                            textcoords="offset points",
                            fontsize=8,
                        )

                    # Ligne de tendance
                    if len(x) > 1:
                        z = np.polyfit(x, y, 1)
                        p = np.poly1d(z)
                        ax.plot(x, p(x), "r--", alpha=0.8, label="Tendance lin√©aire")
                        ax.legend()

                    ax.set_xlabel("Nombre de Documents")
                    ax.set_ylabel("Temps Total (s)")
                    ax.set_title("Performance BM25: Temps vs Taille du Corpus")
                    ax.grid(True, alpha=0.3)

                    plt.tight_layout()
                    st.pyplot(fig)

                with col_analysis:
                    st.markdown("**üîç Analyse:**")

                    fastest = min(benchmark_results, key=lambda x: x["_total_numeric"])
                    slowest = max(benchmark_results, key=lambda x: x["_total_numeric"])

                    st.markdown(f"""
                    **‚ö° Plus rapide:**
                    {fastest["Dataset"]}
                    - {fastest["Total (s)"]}s
                    - {fastest["Docs"]} docs

                    **üêå Plus lent:**
                    {slowest["Dataset"]}
                    - {slowest["Total (s)"]}s
                    - {slowest["Docs"]} docs

                    **üí° Observation:**

                    La ligne rouge montre la tendance **lin√©aire** ‚Üí confirme la complexit√© O(n√óm)!

                    **Impact de la taille:**
                    - Passer de 50 √† 200 docs ‚Üí ~4√ó plus lent
                    - Passer de 100 √† 1000 docs ‚Üí ~10√ó plus lent

                    C'est **proportionnel** au nombre de documents!
                    """)

                st.success("""
                ‚úÖ **Conclusion des Benchmarks:**

                BM25 est **rapide et scalable** pour des corpus de taille petite √† moyenne!

                - **50-100 docs:** Quasi instantan√© (< 0.1s) ‚ö°
                - **200 docs:** Tr√®s rapide (< 0.2s) üöÄ
                - **800-1000 docs:** Rapide (< 1s) üëå
                - **> 10000 docs:** Optimisations recommand√©es (index invers√©, cache, etc.)

                **üí° √Ä retenir:** La croissance est **lin√©aire** ‚Üí pr√©visible et fiable!

                **üÜö Comparaison avec TF-IDF:**
                - L√©g√®rement plus lent (normalisation par longueur)
                - Mais **meilleurs r√©sultats** sur des docs de longueurs vari√©es!
                """)

            else:
                st.error("‚ùå Aucun benchmark n'a pu √™tre ex√©cut√©!")

    st.divider()

    # === OPTIMISATIONS ===
    st.markdown("## üîß Optimisations Possibles")

    st.markdown("""
    Pour de **tr√®s gros corpus** (millions de documents), voici des optimisations possibles:
    """)

    col_opt1, col_opt2 = st.columns(2)

    with col_opt1:
        st.markdown("""
        ### 1Ô∏è‚É£ Index Invers√©

        **Principe:** Stocker pour chaque mot la liste des documents qui le contiennent.

        **Avantage:** Ne parcourir que les docs pertinents (pas tout le corpus)!

        **Gain:** O(n) ‚Üí O(k) o√π k = docs contenant les mots de la query

        ---

        ### 2Ô∏è‚É£ Matrices Creuses (Sparse)

        **Principe:** Ne stocker que les valeurs non-nulles.

        **Avantage:** √âconomie m√©moire massive!

        **Gain:** M√©moire O(n √ó v) ‚Üí O(nnz) o√π nnz = valeurs non-nulles

        ---

        ### 3Ô∏è‚É£ Cache de Preprocessing

        **Principe:** Sauvegarder l'index BM25 sur disque.

        **Avantage:** Pas besoin de r√©indexer √† chaque run!

        **Gain:** Temps de d√©marrage divis√© par 10-100√ó
        """)

    with col_opt2:
        st.markdown("""
        ### 4Ô∏è‚É£ Batch Processing

        **Principe:** Traiter les documents par lots parall√®les.

        **Avantage:** Utiliser tous les CPU cores!

        **Gain:** Temps divis√© par le nombre de cores (4-16√ó)

        ---

        ### 5Ô∏è‚É£ Approximations (ANN)

        **Principe:** Approximate Nearest Neighbors (LSH, HNSW).

        **Avantage:** Recherche ultra-rapide (log n au lieu de n)!

        **Gain:** O(n) ‚Üí O(log n) pour la recherche

        ---

        ### 6Ô∏è‚É£ Elasticsearch / Solr

        **Principe:** Utiliser un moteur d√©di√© (bas√© sur BM25!)

        **Avantage:** Toutes les optimisations ci-dessus + distribution!

        **Gain:** Scalabilit√© jusqu'√† des milliards de docs
        """)

    st.success("""
    ‚úÖ **Pour ce projet p√©dagogique:**
    L'impl√©mentation actuelle est suffisante pour des corpus de **quelques milliers de documents**.
    Pour de la production, utilise **Elasticsearch** ou **Apache Solr** (qui impl√©mentent BM25 nativement)!

    ---

    Compare les **performances r√©elles** de TF-IDF vs BM25 sur 100 documents!
    """)

    if st.button("üöÄ Lancer le Benchmark!", type="primary", key="bm25_benchmark_btn"):
        with st.spinner("‚è±Ô∏è Benchmarking en cours..."):
            # TF-IDF
            start = time_module.time()
            tfidf_engine = TFIDFEngine(
                documents_texts[:100], remove_stopwords=remove_stopwords
            )
            tfidf_engine.fit()
            tfidf_time = time_module.time() - start

            # BM25
            start = time_module.time()
            bm25_engine = BM25Engine(
                documents_texts[:100], remove_stopwords=remove_stopwords
            )
            bm25_time = time_module.time() - start

            st.success("‚úÖ Benchmark termin√©!")

            col1, col2, col3 = st.columns(3)
            col1.metric("‚è±Ô∏è TF-IDF", f"{tfidf_time:.4f}s")
            col2.metric("‚è±Ô∏è BM25", f"{bm25_time:.4f}s")

            # Diff√©rence avec indicateur
            diff = abs(bm25_time - tfidf_time)
            diff_percent = (diff / tfidf_time) * 100 if tfidf_time > 0 else 0
            col3.metric("üìä Diff√©rence", f"{diff:.4f}s", f"{diff_percent:.1f}%")

            st.info(
                "üí° **Conclusion:** Les deux algos ont la m√™me complexit√©! BM25 apporte de meilleurs r√©sultats sans p√©nalit√© de performance!"
            )


# ============================================================================
# MAIN APP
# ============================================================================
