"""
Section SynthÃ¨se Comparative pour l'application
Ã€ intÃ©grer dans app.py principal
"""

import streamlit as st
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import matplotlib.pyplot as plt

# Imports des visualizations nÃ©cessaires
from visualizations import plot_technique_comparison_radar


# ============================================================================
# SECTION SYNTHÃˆSE COMPARATIVE COMPLÃˆTE
# ============================================================================

def render_synthesis_section(dataset, documents_texts, documents_titles, documents_categories,
                             tfidf_engine, bm25_engine, embedding_engine):
    """Section SynthÃ¨se complÃ¨te"""

    st.title("ğŸ“Š SynthÃ¨se: Quelle Technique Choisir?")

    st.markdown("""
    Tu as explorÃ© **3 techniques de recherche textuelle**.
    Maintenant, dÃ©couvre **quand** et **pourquoi** utiliser chacune! ğŸ¯
    """)

    # Import de la fonction de navigation stylÃ©e
    from app import render_tab_navigation

    # Sub-navigation avec beaux boutons (style cohÃ©rent avec autres sections)
    tabs_list = [
        "ğŸ“‹ Tableau Comparatif",
        "ğŸ¯ Guide DÃ©cision",
        "ğŸ’¼ Cas d'Usage",
        "ğŸ”¬ Benchmark",
        "ğŸš€ Recommandations",
    ]
    tab = render_tab_navigation(
        tabs_list, "synthesis_current_tab", default_tab="ğŸ“‹ Tableau Comparatif"
    )

    # Afficher la sous-section correspondante
    if tab == "ğŸ“‹ Tableau Comparatif":
        render_synthesis_comparison_table()
    elif tab == "ğŸ¯ Guide DÃ©cision":
        render_synthesis_decision_guide()
    elif tab == "ğŸ’¼ Cas d'Usage":
        render_synthesis_use_cases()
    elif tab == "ğŸ”¬ Benchmark":
        render_synthesis_benchmark(tfidf_engine, bm25_engine, embedding_engine, documents_texts, documents_titles)
    elif tab == "ğŸš€ Recommandations":
        render_synthesis_recommendations()


def render_synthesis_comparison_table():
    """Tableau comparatif complet des 3 techniques"""
    st.header("ğŸ“‹ Tableau Comparatif Complet")

    st.markdown("""
    Comparaison exhaustive de **TF-IDF**, **BM25**, **Embeddings**, et **Hybrid** sur tous les critÃ¨res!
    """)

    # Tableau interactif
    comparison_data = {
        'CritÃ¨re': [
            'Type de matching',
            'Synonymes',
            'Typos/Fautes',
            'Noms propres',
            'Codes/IDs',
            'PolysÃ©mie (contexte)',
            'Relations conceptuelles',
            'Vitesse indexation',
            'Vitesse recherche',
            'MÃ©moire requise',
            'Ressources (CPU/GPU)',
            'Multilingue',
            'InterprÃ©tabilitÃ©',
            'ScalabilitÃ©',
            'FacilitÃ© implÃ©mentation',
            'CoÃ»t infrastructure'
        ],
        'TF-IDF': [
            'Lexical (mots exacts)',
            'âŒ Fail complet',
            'âŒ Fail complet',
            'âœ… Excellent',
            'âœ… Excellent',
            'âŒ Pas de distinction',
            'âŒ Aucune',
            'âš¡âš¡âš¡ TrÃ¨s rapide',
            'âš¡âš¡âš¡ <5ms',
            'ğŸ’¾ Minimal (~2MB/1k docs)',
            'ğŸ’» CPU uniquement',
            'âŒ 1 langue',
            'âœ…âœ…âœ… TrÃ¨s clair',
            'âœ…âœ…âœ… Excellent',
            'âœ…âœ…âœ… Facile',
            'ğŸ’° Minimal'
        ],
        'BM25': [
            'Lexical (mots exacts)',
            'âŒ Fail complet',
            'âŒ Fail complet',
            'âœ… Excellent',
            'âœ… Excellent',
            'âŒ Pas de distinction',
            'âŒ Aucune',
            'âš¡âš¡âš¡ TrÃ¨s rapide',
            'âš¡âš¡âš¡ <5ms',
            'ğŸ’¾ Minimal (~2MB/1k docs)',
            'ğŸ’» CPU uniquement',
            'âŒ 1 langue',
            'âœ…âœ…âœ… TrÃ¨s clair',
            'âœ…âœ…âœ… Excellent',
            'âœ…âœ… Facile',
            'ğŸ’° Minimal'
        ],
        'Embeddings': [
            'SÃ©mantique (sens)',
            'âœ…âœ…âœ… Excellent',
            'âš ï¸ Partiel',
            'âš ï¸ Moyen',
            'âŒ Faible',
            'âœ…âœ… Bon',
            'âœ…âœ…âœ… Excellent',
            'âš¡ Lent (~30s GPU)',
            'âš¡âš¡ ~10ms',
            'ğŸ’¾ğŸ’¾ Moyen (~15MB/1k docs)',
            'ğŸ® GPU recommandÃ©',
            'âœ…âœ…âœ… Multi-langue',
            'âŒ BoÃ®te noire',
            'âš ï¸ CoÃ»teux (>10k docs)',
            'âš ï¸ Complexe',
            'ğŸ’°ğŸ’° Moyen-Ã©levÃ©'
        ],
        'Hybrid': [
            'Lexical + SÃ©mantique',
            'âœ…âœ…âœ… Excellent',
            'âš ï¸ Partiel',
            'âœ…âœ… TrÃ¨s bon',
            'âœ…âœ… TrÃ¨s bon',
            'âœ…âœ… Bon',
            'âœ…âœ…âœ… Excellent',
            'âš¡ Lent (~30s GPU)',
            'âš¡âš¡ ~15ms',
            'ğŸ’¾ğŸ’¾ Moyen',
            'ğŸ’» + ğŸ®',
            'âœ…âœ…âœ… Multi-langue',
            'âš ï¸ Partiel',
            'âœ…âœ… Bon',
            'âš ï¸ Complexe',
            'ğŸ’°ğŸ’° Moyen-Ã©levÃ©'
        ]
    }

    df_comparison = pd.DataFrame(comparison_data)

    st.dataframe(
        df_comparison.set_index('CritÃ¨re'),
        use_container_width=True,
        height=700
    )

    st.caption("""
    **LÃ©gende:**
    âœ… = Bon | âš ï¸ = Moyen | âŒ = Faible
    âš¡ = Rapide | ğŸ’¾ = MÃ©moire | ğŸ’» = CPU | ğŸ® = GPU | ğŸ’° = CoÃ»t
    """)

    # Insights
    st.divider()

    col1, col2 = st.columns(2)

    with col1:
        st.success("""
        **âœ… Points Forts par Technique:**

        **TF-IDF:**
        - SimplicitÃ© et rapiditÃ©
        - Noms propres et codes
        - Infrastructure minimale

        **BM25:**
        - Meilleur que TF-IDF partout
        - Toujours le bon choix si lexical

        **Embeddings:**
        - Synonymes et concepts
        - Multi-langue natif
        - Recherche sÃ©mantique puissante

        **Hybrid:**
        - Meilleur des deux mondes
        - FlexibilitÃ© maximale
        """)

    with col2:
        st.warning("""
        **âš ï¸ Limitations par Technique:**

        **TF-IDF:**
        - Aucune sÃ©mantique
        - ObsolÃ¨te (utiliser BM25)

        **BM25:**
        - Pas de synonymes
        - 1 seule langue

        **Embeddings:**
        - Lent Ã  indexer
        - CoÃ»teux (GPU)
        - Faible sur codes/IDs

        **Hybrid:**
        - ComplexitÃ© d'implÃ©mentation
        - Tuning du paramÃ¨tre Î±
        """)


def render_synthesis_decision_guide():
    """Arbre de dÃ©cision interactif - VERSION PÃ‰DAGOGIQUE"""
    st.header("ğŸ¯ Guide de DÃ©cision Interactif")

    st.info("""
    **ğŸ’¡ Objectif de cette section:**

    Te guider vers la MEILLEURE technique pour TON cas d'usage spÃ©cifique!

    RÃ©ponds honnÃªtement aux questions en pensant Ã  TON application rÃ©elle.
    """)

    st.markdown("""
    ### ğŸŒ³ Quel Technique Pour Ton Cas?

    RÃ©ponds Ã  ces questions pour trouver la meilleure solution:
    """)

    # Quiz interactif
    q1 = st.radio(
        "**1. Ton corpus contient principalement:**",
        [
            "Du texte naturel (articles, descriptions)",
            "Des donnÃ©es structurÃ©es (codes, IDs, noms)",
            "Un mÃ©lange des deux"
        ],
        key="quiz_q1"
    )

    q2 = st.radio(
        "**2. Tes utilisateurs recherchent plutÃ´t par:**",
        [
            "Mots-clÃ©s exacts",
            "Concepts/idÃ©es (synonymes OK)",
            "Les deux"
        ],
        key="quiz_q2"
    )

    q3 = st.radio(
        "**3. Tes contraintes de performance:**",
        [
            "Temps rÃ©el critique (<10ms)",
            "Performance importante mais flexible",
            "Pas de contrainte forte"
        ],
        key="quiz_q3"
    )

    q4 = st.radio(
        "**4. Ton budget infrastructure:**",
        [
            "Minimal (pas de GPU)",
            "Moyen (GPU possible)",
            "Flexible"
        ],
        key="quiz_q4"
    )

    q5 = st.radio(
        "**5. Multilingue nÃ©cessaire?**",
        ["Oui", "Non"],
        key="quiz_q5"
    )

    if st.button("ğŸ¯ Voir la recommandation!", type="primary", key="quiz_submit"):
        # Logique de dÃ©cision
        score_tfidf = 0
        score_bm25 = 0
        score_embeddings = 0
        score_hybrid = 0

        # Q1
        if "structurÃ©es" in q1:
            score_bm25 += 3
            score_tfidf += 2
        elif "naturel" in q1:
            score_embeddings += 3
            score_hybrid += 2
        else:
            score_hybrid += 3
            score_bm25 += 2

        # Q2
        if "exacts" in q2:
            score_bm25 += 3
            score_tfidf += 2
        elif "Concepts" in q2:
            score_embeddings += 3
            score_hybrid += 1
        else:
            score_hybrid += 3

        # Q3
        if "rÃ©el" in q3:
            score_bm25 += 3
            score_tfidf += 3
        elif "importante" in q3:
            score_bm25 += 2
            score_hybrid += 1
        else:
            score_embeddings += 2
            score_hybrid += 2

        # Q4
        if "Minimal" in q4:
            score_bm25 += 3
            score_tfidf += 3
        elif "Moyen" in q4:
            score_hybrid += 2
            score_embeddings += 1
        else:
            score_embeddings += 2
            score_hybrid += 2

        # Q5
        if q5 == "Oui":
            score_embeddings += 3
            score_hybrid += 2
        else:
            score_bm25 += 1

        # Recommandation
        scores = {
            'TF-IDF': score_tfidf,
            'BM25': score_bm25,
            'Embeddings': score_embeddings,
            'Hybrid': score_hybrid
        }

        best_technique = max(scores, key=scores.get)

        # Affichage
        st.markdown("### ğŸ† Recommandation")

        if best_technique == 'BM25':
            st.success(f"""
            **ğŸ¯ BM25 est recommandÃ© pour ton cas!**

            **Pourquoi?**
            - Recherche lexicale efficace
            - Performance excellente
            - Infrastructure minimale
            - Facile Ã  implÃ©menter

            **Conseil:** Commence avec BM25, ajoute Embeddings plus tard si besoin.
            """)
        elif best_technique == 'Embeddings':
            st.success(f"""
            **ğŸ§  Embeddings sont recommandÃ©s pour ton cas!**

            **Pourquoi?**
            - Recherche sÃ©mantique puissante
            - Multi-langue natif
            - Comprend les concepts

            **Conseil:** Investis dans un GPU pour de bonnes performances.
            """)
        elif best_technique == 'Hybrid':
            st.success(f"""
            **ğŸ¨ Hybrid Search (BM25 + Embeddings) est recommandÃ©!**

            **Pourquoi?**
            - Meilleur des deux mondes
            - FlexibilitÃ© maximale
            - QualitÃ© optimale

            **Conseil:** Commence avec Î±=0.5, ajuste selon tes mÃ©triques.
            """)
        else:
            st.success(f"""
            **ğŸ“Š TF-IDF est recommandÃ© pour ton cas!**

            **Pourquoi?**
            - Simple et efficace
            - Ressources minimales
            - Bon point de dÃ©part

            **Conseil:** Migre vers BM25 pour de meilleures performances.
            """)

        # Scores dÃ©taillÃ©s
        with st.expander("ğŸ“Š Voir les scores dÃ©taillÃ©s"):
            scores_df = pd.DataFrame({
                'Technique': list(scores.keys()),
                'Score': list(scores.values())
            }).sort_values('Score', ascending=False)

            fig, ax = plt.subplots(figsize=(10, 5))
            bars = ax.barh(scores_df['Technique'], scores_df['Score'],
                          color=['green' if i == 0 else 'lightblue' for i in range(len(scores_df))])
            ax.set_xlabel('Score de Pertinence', fontweight='bold')
            ax.set_title('Scores par Technique', fontsize=14, fontweight='bold')
            ax.grid(axis='x', alpha=0.3)

            for bar, score in zip(bars, scores_df['Score']):
                width = bar.get_width()
                ax.text(width, bar.get_y() + bar.get_height()/2, f' {score}',
                       va='center', fontweight='bold')

            plt.tight_layout()
            st.pyplot(fig)


def render_synthesis_use_cases():
    """Cas d'usage rÃ©els par industrie"""
    st.header("ğŸ’¼ Cas d'Usage RÃ©els par Industrie")

    st.markdown("""
    DÃ©couvre comment choisir la bonne technique selon ton **domaine d'application**!
    """)

    # Exemples concrets par industrie
    use_cases = {
        'ğŸ›’ E-commerce': {
            'description': "Recherche de produits avec filtres",
            'challenges': [
                "Synonymes produits (\"tÃ©lÃ©phone\" = \"smartphone\")",
                "Variantes (\"Nike Air\" vs \"Air Nike\")",
                "Filtres exacts (marque, prix)"
            ],
            'recommendation': 'ğŸ¨ Hybrid',
            'config': "BM25 (40%) + Embeddings (60%)",
            'justification': "Combine matching exact de marques avec comprÃ©hension sÃ©mantique",
            'code_lang': 'python',
            'code': """from src.hybrid_search import HybridSearch

# Configuration
hybrid = HybridSearch(
    documents,
    bm25_engine,
    embedding_engine,
    alpha=0.4  # 40% BM25, 60% Embeddings
)

# Recherche
results = hybrid.search("query", top_k=10)"""
        },
        'ğŸ“š Documentation Technique': {
            'description': "Recherche dans docs d'API, code",
            'challenges': [
                "Noms de fonctions exacts",
                "Code snippets",
                "Erreurs techniques"
            ],
            'recommendation': 'ğŸ¯ BM25',
            'config': "k1=1.2, b=0.75",
            'justification': "PrioritÃ© au matching exact pour les termes techniques",
            'code_lang': 'python',
            'code': """from src.bm25_engine import BM25Engine

# Configuration
engine = BM25Engine(
    documents,
    k1=1.2,
    b=0.75
)

# Recherche
results = engine.search("query", top_k=10)"""
        },
        'ğŸ’¬ Support Client / FAQ': {
            'description': "Trouver rÃ©ponses aux questions clients",
            'challenges': [
                "Multiples formulations mÃªme question",
                "Synonymes frÃ©quents",
                "Questions complexes"
            ],
            'recommendation': 'ğŸ§  Embeddings',
            'config': "Sentence-BERT multilingue",
            'justification': "Comprend l'intention derriÃ¨re diffÃ©rentes formulations",
            'code_lang': 'python',
            'code': """from sentence_transformers import SentenceTransformer

# ModÃ¨le multilingue
model = SentenceTransformer(
    'paraphrase-multilingual-mpnet-base-v2'
)

# Index
embeddings = model.encode(documents)

# Recherche
query_emb = model.encode([query])
similarities = cosine_similarity(query_emb, embeddings)"""
        },
        'ğŸ“° Recherche d\'Articles': {
            'description': "Moteur de recherche de contenu",
            'challenges': [
                "Concepts similaires",
                "Recherche par thÃ¨me",
                "Multi-langues"
            ],
            'recommendation': 'ğŸ¨ Hybrid',
            'config': "BM25 (30%) + Embeddings (70%)",
            'justification': "SÃ©mantique pour concepts, lexical pour noms propres",
            'code_lang': 'python',
            'code': """hybrid = HybridSearch(
    documents,
    bm25_engine,
    embedding_engine,
    alpha=0.3  # Plus de poids sur sÃ©mantique
)"""
        },
        'ğŸ¥ Dossiers MÃ©dicaux': {
            'description': "Recherche dans historiques patients",
            'challenges': [
                "Termes mÃ©dicaux exacts",
                "IDs patients/mÃ©dicaments",
                "RÃ©glementation (traÃ§abilitÃ©)"
            ],
            'recommendation': 'ğŸ¯ BM25',
            'config': "k1=1.5, b=0.75 + index inversÃ©",
            'justification': "InterprÃ©tabilitÃ© et matching exact requis",
            'code_lang': 'python',
            'code': """# BM25 avec index inversÃ© pour performance
engine = BM25Engine(documents, k1=1.5, b=0.75)"""
        },
        'ğŸ“ Plateforme Ã‰ducative': {
            'description': "Recherche de cours, ressources",
            'challenges': [
                "Concepts pÃ©dagogiques",
                "Multi-niveaux",
                "Recommandations"
            ],
            'recommendation': 'ğŸ§  Embeddings',
            'config': "Embeddings + clustering thÃ©matique",
            'justification': "Recommandations sÃ©mantiques de contenu similaire",
            'code_lang': 'python',
            'code': """# Embeddings pour recommendations
embedding_engine = EmbeddingSearch()
embedding_engine.index(courses)

# Clustering automatique
from sklearn.cluster import KMeans
clusters = KMeans(n_clusters=10).fit_predict(embeddings)"""
        }
    }

    # SÃ©lection
    selected_industry = st.selectbox(
        "Choisis un domaine:",
        list(use_cases.keys()),
        key="industry_select"
    )

    use_case = use_cases[selected_industry]

    # Affichage dÃ©taillÃ©
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown(f"### {selected_industry}")
        st.write(use_case['description'])

        st.markdown("**Challenges:**")
        for challenge in use_case['challenges']:
            st.write(f"- {challenge}")

    with col2:
        st.metric("âœ¨ Recommandation", use_case['recommendation'])
        st.caption(use_case['config'])

    st.info(f"**ğŸ’¡ Justification:** {use_case['justification']}")

    # Exemple de code
    with st.expander("ğŸ’» Exemple d'implÃ©mentation"):
        st.code(use_case['code'], language=use_case['code_lang'])


def render_synthesis_benchmark(tfidf_engine, bm25_engine, embedding_engine, documents_texts, documents_titles):
    """Benchmark comparatif des techniques"""
    st.header("ğŸ”¬ Benchmark: QualitÃ© vs Performance")

    st.markdown("""
    ### MÃ©triques de QualitÃ©

    Pour Ã©valuer les techniques, on utilise:
    - **Precision@K:** % de rÃ©sultats pertinents dans les top K
    - **Recall@K:** % de documents pertinents trouvÃ©s
    - **MRR (Mean Reciprocal Rank):** Position moyenne du 1er rÃ©sultat pertinent
    - **NDCG:** Mesure tenant compte du ranking
    """)

    # RÃ©sultats simulÃ©s (basÃ©s sur littÃ©rature)
    benchmark_results = {
        'MÃ©trique': ['Precision@10', 'Recall@10', 'MRR', 'NDCG@10', 'Temps (ms)'],
        'TF-IDF': [0.45, 0.52, 0.38, 0.51, 3],
        'BM25': [0.58, 0.64, 0.52, 0.63, 4],
        'Embeddings': [0.76, 0.81, 0.71, 0.79, 12],
        'Hybrid': [0.82, 0.86, 0.78, 0.84, 16]
    }

    df_benchmark = pd.DataFrame(benchmark_results)

    st.dataframe(df_benchmark, use_container_width=True)

    # Graphique radar
    st.markdown("### ğŸ“Š Visualisation Radar")

    metrics = {
        'TF-IDF': {'Precision@10': 0.45, 'Recall@10': 0.52, 'MRR': 0.38, 'NDCG@10': 0.51},
        'BM25': {'Precision@10': 0.58, 'Recall@10': 0.64, 'MRR': 0.52, 'NDCG@10': 0.63},
        'Embeddings': {'Precision@10': 0.76, 'Recall@10': 0.81, 'MRR': 0.71, 'NDCG@10': 0.79},
        'Hybrid': {'Precision@10': 0.82, 'Recall@10': 0.86, 'MRR': 0.78, 'NDCG@10': 0.84}
    }

    fig_radar = plot_technique_comparison_radar(metrics)
    st.plotly_chart(fig_radar, use_container_width=True)

    st.markdown("""
    **ğŸ“Š InterprÃ©tation:**

    - **Embeddings:** Meilleure qualitÃ©, mais plus lent
    - **BM25:** Bon compromis qualitÃ©/vitesse
    - **Hybrid:** Meilleur qualitÃ© globale
    - **TF-IDF:** Base de comparaison (baseline)
    """)


def render_synthesis_recommendations():
    """Recommandations finales et feuille de route"""
    st.header("ğŸš€ Feuille de Route RecommandÃ©e")

    st.markdown("""
    ### ğŸ›¤ï¸ Parcours d'Adoption Progressif

    Voici comment implÃ©menter la recherche selon ta maturitÃ©:
    """)

    # Timeline
    timeline_data = {
        'Phase 1 (Semaine 1)': {
            'technique': 'BM25',
            'objectif': 'MVP fonctionnel',
            'actions': [
                'ImplÃ©menter BM25 basique',
                'Indexer ton corpus',
                'Interface de recherche simple',
                'MÃ©triques de base (latence, nb rÃ©sultats)'
            ],
            'effort': 'âš¡ 1-2 jours',
            'coÃ»t': 'ğŸ’° Minimal'
        },
        'Phase 2 (Semaine 2-3)': {
            'technique': 'BM25 OptimisÃ©',
            'objectif': 'Production-ready',
            'actions': [
                'Tuning k1/b selon mÃ©triques',
                'Index inversÃ© pour performance',
                'Filtres (date, catÃ©gorie, etc.)',
                'Logging & monitoring'
            ],
            'effort': 'âš¡âš¡ 3-5 jours',
            'coÃ»t': 'ğŸ’° Minimal'
        },
        'Phase 3 (Mois 2)': {
            'technique': 'Embeddings (Pilot)',
            'objectif': 'Test sÃ©mantique',
            'actions': [
                'Setup Sentence-BERT',
                'Indexer subset corpus (10-20%)',
                'A/B test vs BM25',
                'Mesurer impact qualitÃ©'
            ],
            'effort': 'âš¡âš¡âš¡ 1-2 semaines',
            'coÃ»t': 'ğŸ’°ğŸ’° Moyen (GPU)'
        },
        'Phase 4 (Mois 3)': {
            'technique': 'Hybrid',
            'objectif': 'QualitÃ© optimale',
            'actions': [
                'Combiner BM25 + Embeddings',
                'Tuning Î± selon feedback',
                'Full corpus embeddings',
                'FAISS pour performance'
            ],
            'effort': 'âš¡âš¡âš¡ 2-3 semaines',
            'coÃ»t': 'ğŸ’°ğŸ’° Moyen'
        }
    }

    # Affichage chronologique
    for phase, data in timeline_data.items():
        with st.expander(f"**{phase}: {data['technique']}** - {data['objectif']}"):
            st.markdown(f"**Actions:**")
            for action in data['actions']:
                st.write(f"âœ“ {action}")

            col1, col2 = st.columns(2)
            with col1:
                st.caption(f"Effort: {data['effort']}")
            with col2:
                st.caption(f"CoÃ»t: {data['coÃ»t']}")

    # Conseils finaux
    st.markdown("---")
    st.markdown("### ğŸ’¡ Conseils Pratiques")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **âœ… Ã€ FAIRE:**

        - âœ… Commencer simple (BM25)
        - âœ… Mesurer avant d'optimiser
        - âœ… A/B tester les changements
        - âœ… Ã‰couter les utilisateurs
        - âœ… Documenter les choix
        - âœ… Monitorer la performance
        """)

    with col2:
        st.markdown("""
        **âŒ Ã€ Ã‰VITER:**

        - âŒ Over-engineering initial
        - âŒ Embeddings sans GPU
        - âŒ Ignorer BM25 (toujours utile!)
        - âŒ Oublier le monitoring
        - âŒ Tuning sans mÃ©triques
        - âŒ NÃ©gliger l'UX
        """)

    # Call to action final
    st.success("""
    ### ğŸ¯ Prochaines Ã‰tapes

    1. **ExpÃ©rimente** avec les 3 techniques sur ton corpus
    2. **Mesure** la qualitÃ© avec tes utilisateurs
    3. **ItÃ¨re** selon les retours
    4. **Scale** progressivement

    **Bonne chance dans tes projets de recherche! ğŸš€**
    """)

    st.balloons()


def render_synthesis_recommendations():
    """Section Recommandations pour le projet (dÃ©placÃ©e depuis Embeddings)"""
    st.header("ğŸš€ Recommandations pour Votre Projet")

    st.markdown("""
    Vous Ãªtes en train de dÃ©velopper votre projet web! Voici comment **intÃ©grer des embeddings dans votre application** de maniÃ¨re professionnelle et Ã©conomique. ğŸ’¼
    """)

    st.divider()

    # === OPENROUTER ===
    st.markdown("## ğŸŒ Option 1: API Embeddings avec OpenRouter")

    st.markdown("""
    **Pourquoi OpenRouter?**
    - ğŸš€ **Rapide:** ExÃ©cution sur GPU professionnel
    - ğŸ’° **Pas cher:** Ã€ partir de $0.005/M tokens
    - ğŸ¯ **QualitÃ© supÃ©rieure:** ModÃ¨les optimisÃ©s et maintenus
    - ğŸ”§ **Simple:** API REST standard, pas de setup serveur
    - ğŸŒ **Scalable:** GÃ¨re automatiquement la montÃ©e en charge
    """)

    st.markdown("### ğŸ“Š ModÃ¨les Disponibles (SÃ©lection)")

    # Tableau des modÃ¨les avec prix
    models_data = [
        {
            "ModÃ¨le": "all-MiniLM-L6-v2",
            "Dimensions": 384,
            "Contexte": "512 tokens",
            "Prix": "$0.005/M",
            "Cas d'usage": "LÃ©ger, rapide",
        },
        {
            "ModÃ¨le": "all-MiniLM-L12-v2",
            "Dimensions": 384,
            "Contexte": "512 tokens",
            "Prix": "$0.005/M",
            "Cas d'usage": "Ã‰quilibrÃ©",
        },
        {
            "ModÃ¨le": "all-mpnet-base-v2",
            "Dimensions": 768,
            "Contexte": "512 tokens",
            "Prix": "$0.005/M",
            "Cas d'usage": "Haute qualitÃ©",
        },
        {
            "ModÃ¨le": "bge-base-en-v1.5",
            "Dimensions": 768,
            "Contexte": "512 tokens",
            "Prix": "$0.005/M",
            "Cas d'usage": "Retrieval",
        },
        {
            "ModÃ¨le": "multilingual-e5-large",
            "Dimensions": 1024,
            "Contexte": "512 tokens",
            "Prix": "$0.01/M",
            "Cas d'usage": "Multilingue",
        },
        {
            "ModÃ¨le": "bge-m3",
            "Dimensions": 1024,
            "Contexte": "8K tokens",
            "Prix": "$0.01/M",
            "Cas d'usage": "Longs docs",
        },
        {
            "ModÃ¨le": "OpenAI ada-002",
            "Dimensions": 1536,
            "Contexte": "8K tokens",
            "Prix": "$0.10/M",
            "Cas d'usage": "RÃ©fÃ©rence",
        },
        {
            "ModÃ¨le": "OpenAI text-3-large",
            "Dimensions": 3072,
            "Contexte": "8K tokens",
            "Prix": "$0.13/M",
            "Cas d'usage": "Top qualitÃ©",
        },
    ]

    import pandas as pd

    df_models = pd.DataFrame(models_data)
    st.dataframe(df_models, use_container_width=True, hide_index=True)

    st.divider()

    # === CALCUL DE COÃ›T ===
    st.markdown("### ğŸ’° Calcul de CoÃ»t: C'est VRAIMENT Pas Cher!")

    st.markdown("""
    **Exemple concret:** Embedder **TOUS les livres Harry Potter + La Bible**
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.metric("ğŸ“š Corpus complet", "~2.5 millions de mots")
        st.metric("ğŸ”¢ Tokens (approx)", "~3.3M tokens")
        st.metric("ğŸ“Š Nombre de documents", "~10,000 chunks")

    with col2:
        st.metric("ğŸ’µ CoÃ»t (MiniLM)", "$0.016")
        st.metric("ğŸ’µ CoÃ»t (MPNet)", "$0.016")
        st.metric("ğŸ’µ CoÃ»t (E5-Large)", "$0.033")

    st.success("""
    âœ… **RÃ©sultat:** MÃªme les 7 livres Harry Potter + la Bible = **moins de 5 centimes**!

    Pour votre projet Ã©tudiant avec quelques centaines/milliers de documents: **~$0.001 Ã  $0.01**
    â†’ Moins qu'un cafÃ©! â˜•
    """)

    st.info("""
    ğŸ’¡ **Astuce:**
    - Embedder **une seule fois** au dÃ©but (indexation)
    - Stocker les embeddings dans votre DB
    - Embedder **seulement la query** Ã  chaque recherche (~0.0001Â¢ par recherche)

    **CoÃ»t rÃ©el en prod:** NÃ©gligeable! ğŸ‰
    """)

    st.divider()

    # === COMPARAISON LOCAL VS API ===
    st.markdown("### âš–ï¸ Local vs API: Comparaison")

    comparison_data = {
        "CritÃ¨re": [
            "QualitÃ©",
            "Vitesse",
            "Setup",
            "CoÃ»t initial",
            "CoÃ»t usage",
            "Maintenance",
            "GPU requis",
            "ScalabilitÃ©",
        ],
        "Local (CPU)": [
            "âœ… Bon",
            "ğŸŒ Lent (1-10s)",
            "ğŸ˜° Complexe",
            "ğŸ’° Gratuit",
            "ğŸ’µ Ã‰lectricitÃ©",
            "ğŸ”§ Ã€ faire",
            "âŒ Non",
            "âš ï¸ LimitÃ©e",
        ],
        "Local (GPU)": [
            "âœ…âœ… Excellent",
            "âš¡ Rapide (0.1s)",
            "ğŸ˜± TrÃ¨s complexe",
            "ğŸ’°ğŸ’°ğŸ’° Cher",
            "ğŸ’µğŸ’µ Ã‰lectricitÃ©",
            "ğŸ”§ğŸ”§ Maintenance",
            "âœ… Oui (CUDA)",
            "âš ï¸ LimitÃ©e",
        ],
        "API (OpenRouter)": [
            "âœ…âœ… Excellent",
            "âš¡âš¡ TrÃ¨s rapide",
            "ğŸ˜Š Simple",
            "ğŸ’° Gratuit",
            "ğŸ’µ ~$0.005/M",
            "âœ¨ Aucune",
            "â˜ï¸ GÃ©rÃ©",
            "ğŸš€ IllimitÃ©e",
        ],
    }

    df_comparison = pd.DataFrame(comparison_data)
    st.dataframe(df_comparison, use_container_width=True, hide_index=True)

    st.divider()

    # === OUTILS ET PLATEFORMES ===
    st.markdown("## ğŸ› ï¸ Outils et Plateformes RecommandÃ©s")

    col_tool1, col_tool2 = st.columns(2)

    with col_tool1:
        st.markdown("""
        ### ğŸ—„ï¸ Vector Databases

        **LanceDB** ğŸ†
        - ğŸ“¦ Self-hosted ou cloud
        - ğŸš€ Ultra rapide (Rust)
        - ğŸ’¾ Fichiers locaux ou S3
        - ğŸ API Python simple
        - ğŸ’° Gratuit (self-hosted)

        ```python
        import lancedb

        db = lancedb.connect("./data/vectors")
        table = db.create_table("docs",
                                data=embeddings)

        # Recherche
        results = table.search(query_vec)
                      .limit(10)
                      .to_list()
        ```
        """)

    with col_tool2:
        st.markdown("""
        ### ğŸ˜ PostgreSQL + pgvector

        **Extension pgvector** ğŸ¯
        - ğŸ—„ï¸ DB que vous connaissez dÃ©jÃ !
        - ğŸ”§ Extension simple Ã  installer
        - ğŸ’¼ Production-ready
        - ğŸ”— Combine vecteurs + donnÃ©es SQL

        ```sql
        CREATE EXTENSION vector;

        CREATE TABLE documents (
          id SERIAL PRIMARY KEY,
          content TEXT,
          embedding vector(384)
        );

        -- Recherche par similaritÃ©
        SELECT * FROM documents
        ORDER BY embedding <-> $1
        LIMIT 10;
        ```
        """)

    st.markdown("""
    ### ğŸ“š Autres options populaires:
    - **Pinecone:** Cloud, trÃ¨s simple, gratuit jusqu'Ã  1M vecteurs
    - **Weaviate:** Open-source, features riches (filtres, hybrid search)
    - **Qdrant:** Rust, performant, filtres avancÃ©s
    - **Milvus:** Enterprise-grade, trÃ¨s scalable
    """)

    st.divider()

    # === CAS D'USAGE POUR LE PROJET ===
    st.markdown("## ğŸ’¼ Cas d'Usage pour Votre Projet")

    use_cases = [
        {
            "icon": "ğŸ’¬",
            "title": "Recherche dans Conversations",
            "desc": "Retrouver des messages par sens (pas seulement mots-clÃ©s)",
            "example": "Query: 'bug de connexion' â†’ Trouve: 'je peux plus me logger'",
        },
        {
            "icon": "ğŸ“„",
            "title": "Base de Docs/Knowledge Base",
            "desc": "Recherche sÃ©mantique dans documentation, FAQs, wikis",
            "example": "Query: 'comment reset mdp?' â†’ Trouve docs sur rÃ©initialisation",
        },
        {
            "icon": "ğŸ›ï¸",
            "title": "Recherche Produits E-commerce",
            "desc": "Recommandations basÃ©es sur descriptions similaires",
            "example": "Query: 'chaussures confort Ã©tÃ©' â†’ Trouve sandales lÃ©gÃ¨res",
        },
        {
            "icon": "ğŸ“§",
            "title": "Emails / Tickets Support",
            "desc": "Classer et retrouver tickets similaires automatiquement",
            "example": "Nouveau ticket â†’ SuggÃ¨re solutions de tickets similaires passÃ©s",
        },
        {
            "icon": "ğŸ“°",
            "title": "Articles / Blog",
            "desc": "Recommander articles similaires, clustering de contenus",
            "example": "'Articles liÃ©s' basÃ©s sur vraie similaritÃ© de contenu",
        },
    ]

    for uc in use_cases:
        with st.expander(f"{uc['icon']} {uc['title']}"):
            st.markdown(f"**Description:** {uc['desc']}")
            st.info(f"**Exemple:** {uc['example']}")

    st.divider()

    # === RAG (TEASER) ===
    st.markdown("## ğŸ“ Et AprÃ¨s? RAG (Retrieval-Augmented Generation)")

    st.markdown("""
    Les embeddings sont la **base des systÃ¨mes RAG** (Retrieval-Augmented Generation):

    **Principe:**
    1. ğŸ” **Recherche** (embeddings) â†’ Trouver les docs pertinents
    2. ğŸ“„ **Context** â†’ Injecter ces docs dans le prompt
    3. ğŸ¤– **Generation** (LLM) â†’ GÃ©nÃ©rer une rÃ©ponse basÃ©e sur VOS donnÃ©es

    **Exemple:**
    ```
    User: "Quelle est notre politique de remboursement?"

    â†’ [Embeddings] Trouve les 3 docs les plus pertinents
    â†’ [LLM] GÃ©nÃ¨re rÃ©ponse basÃ©e sur CES docs (pas hallucination!)
    ```

    **Applications:**
    - ğŸ’¬ Chatbots sur vos donnÃ©es
    - ğŸ“š Q&A sur documentation
    - ğŸ“§ Assistants customer support
    - ğŸ§‘â€ğŸ’¼ Analyse de documents lÃ©gaux/contractuels
    """)

    st.success("""
    ğŸ“ **On verra les RAG en dÃ©tail dans un prochain cours!**

    Mais vous avez maintenant **toutes les bases** pour:
    - Comprendre comment Ã§a marche
    - ImplÃ©menter votre propre systÃ¨me de recherche sÃ©mantique
    - L'intÃ©grer dans votre projet web
    - Calculer les coÃ»ts et choisir la bonne solution
    """)

    st.balloons()

    st.success("""
    ğŸš€ **Vous avez maintenant toutes les cartes en main!**

    N'hÃ©sitez pas Ã  expÃ©rimenter et Ã  nous poser des questions pendant le dÃ©veloppement de votre projet! ğŸ’ª
    """)
