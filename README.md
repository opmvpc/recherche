# ğŸ” Explorateur de Recherche Textuelle - Application Ã‰ducative ComplÃ¨te

> Application interactive Streamlit pour apprendre les techniques de recherche textuelle modernes: **TF-IDF**, **BM25**, **Embeddings**, et **Hybrid Search**!

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28%2B-red.svg)](https://streamlit.io/)
[![Torch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“š Description

**Explorateur de Recherche Textuelle** est une application pÃ©dagogique **ultra-complÃ¨te** conÃ§ue pour enseigner les techniques de recherche textuelle modernes aux Ã©tudiants en programmation web (niveau bac+2/3).

### ğŸ¯ Objectifs PÃ©dagogiques

- âœ… Comprendre **TF-IDF** (Term Frequency - Inverse Document Frequency)
- âœ… MaÃ®triser **BM25** (Best Matching 25) et ses amÃ©liorations sur TF-IDF
- âœ… DÃ©couvrir les **Embeddings Vectoriels** et la recherche sÃ©mantique
- âœ… ExpÃ©rimenter le **Hybrid Search** (combinaison BM25 + Embeddings)
- âœ… Comparer les techniques avec des benchmarks rÃ©els
- âœ… ImplÃ©menter les algorithmes **from scratch**
- âœ… Visualiser les concepts avec des graphiques interactifs
- âœ… Comprendre les compromis performance vs qualitÃ©

### ğŸ¨ Sections Disponibles

#### ğŸ  Accueil

- PrÃ©sentation gÃ©nÃ©rale de l'application
- Guide de navigation
- Introduction aux techniques de recherche

#### ğŸ“Š Section TF-IDF

- ğŸ“– **Introduction** : Comprendre le problÃ¨me de la recherche naÃ¯ve
- ğŸ”¢ **Concepts** : TF, IDF, similaritÃ© cosinus avec formules LaTeX
- ğŸ” **Recherche Interactive** : Tester des requÃªtes sur datasets franÃ§ais
- ğŸ“Š **Exploration** : Statistiques, heatmaps, projections 3D
- ğŸ“ **Pas-Ã -Pas** : Suivre tous les calculs Ã©tape par Ã©tape
- âš¡ **Performance** : ComplexitÃ© algorithmique et optimisations

#### ğŸ¯ Section BM25

- ğŸ“– **Introduction** : Les 3 problÃ¨mes majeurs de TF-IDF
- ğŸ”¢ **Concepts** : IDF amÃ©liorÃ©, saturation (k1), normalisation (b)
- ğŸ” **Recherche Interactive** : Tuning en temps rÃ©el avec sliders k1/b
- ğŸ“Š **Exploration** : Impact des paramÃ¨tres avec heatmaps interactives
- ğŸ“ **Pas-Ã -Pas** : Calculs BM25 dÃ©taillÃ©s Ã©tape par Ã©tape
- âš”ï¸ **Comparaison** : TF-IDF vs BM25 sur requÃªtes rÃ©elles
- âš¡ **Performance** : Benchmarks et analyse de complexitÃ©

#### ğŸ§  Section Embeddings (NOUVEAU! ğŸ”¥)

- ğŸ“– **Introduction** : Limites lexicales & recherche sÃ©mantique
- ğŸ”¢ **Concepts** : Sparse vs Dense, Transformers, BERT, Attention
- ğŸ” **Recherche** : Recherche sÃ©mantique interactive
- ğŸ“Š **Exploration** : Visualisation 3D, clustering automatique
- ğŸ“ **Pas-Ã -Pas** : Pipeline complet d'encodage
- âš”ï¸ **Comparaison** : Embeddings vs BM25 vs TF-IDF
- ğŸ¨ **Hybrid** : Combinaison BM25 + Embeddings avec tuning Î±
- âš¡ **Performance** : Benchmarks et optimisations (GPU, FAISS)

#### ğŸ“Š Section SynthÃ¨se (NOUVEAU! ğŸ”¥)

- ğŸ“‹ **Tableau Comparatif** : Comparaison exhaustive des 4 techniques
- ğŸ¯ **Guide DÃ©cision** : Quiz interactif pour choisir la bonne technique
- ğŸ’¼ **Cas d'Usage** : Exemples rÃ©els par industrie (e-commerce, FAQ, etc.)
- ğŸ”¬ **Benchmark** : MÃ©triques de qualitÃ© comparatives (Precision, Recall, MRR, NDCG)
- ğŸš€ **Recommandations** : Feuille de route d'adoption progressive

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.9 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- Git (pour cloner le repo)
- **(Optionnel mais recommandÃ©)** GPU pour embeddings (CUDA compatible)

### Ã‰tapes d'Installation

1. **Clone le repository**

```bash
git clone https://github.com/opmvpc/recherche.git
cd recherche/tfidf-app
```

2. **CrÃ©e un environnement virtuel** (recommandÃ©)

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

3. **Installe les dÃ©pendances**

### Installation ComplÃ¨te (TOUTES LES SECTIONS)

```bash
# Installe TOUT (TF-IDF, BM25, Embeddings, SynthÃ¨se)
pip install -r requirements.txt
```

**Note:** L'installation de PyTorch peut prendre plusieurs minutes (~3-10 min selon connexion).

5. **Lance l'application**

```bash
streamlit run app.py
```

5. **Ouvre ton navigateur**

L'application devrait s'ouvrir automatiquement Ã  `http://localhost:8501`

---

## ğŸ“ Structure du Projet

```
tfidf-app/
â”œâ”€â”€ app.py                      # Application Streamlit principale (navigation sidebar)
â”œâ”€â”€ app_embeddings_sections.py  # Sections Embeddings (Ã  intÃ©grer)
â”œâ”€â”€ app_synthesis_sections.py   # Sections SynthÃ¨se (Ã  intÃ©grer)
â”œâ”€â”€ setup_embeddings.py         # ğŸ†• Script d'installation automatique des embeddings
â”œâ”€â”€ download_model.py           # ğŸ†• Script de tÃ©lÃ©chargement du modÃ¨le
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python (complÃ¨tes)
â”œâ”€â”€ README.md                  # Ce fichier
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tfidf_engine.py         # ImplÃ©mentation TF-IDF from scratch
â”‚   â”œâ”€â”€ bm25_engine.py          # ImplÃ©mentation BM25 from scratch
â”‚   â”œâ”€â”€ embedding_engine.py     # Moteur Embeddings avec Sentence-BERT
â”‚   â”œâ”€â”€ hybrid_search.py        # Hybrid Search (BM25 + Embeddings)
â”‚   â”œâ”€â”€ visualizations.py       # Toutes les visualisations
â”‚   â””â”€â”€ datasets.py             # Chargement des datasets franÃ§ais
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cache/                  # Cache des embeddings
â””â”€â”€ .gitignore
```

---

## ğŸ“Š Datasets Disponibles

L'application propose **3 datasets en franÃ§ais** avec deux tailles:

### 1. ğŸ Recettes de Cuisine

- **Standard:** ~12 recettes variÃ©es
- **Ã‰tendu:** ~80 recettes (Italiennes, Asiatiques, FranÃ§aises, Mexicaines, etc.)
- **IdÃ©al pour:** Tester synonymes culinaires, concepts de cuisine

### 2. ğŸ¬ Synopsis de Films

- **Standard:** ~10 films variÃ©s
- **Ã‰tendu:** ~70 films (Action, ComÃ©die, Horreur, Science-fiction, etc.)
- **IdÃ©al pour:** Recherche par genre, concepts narratifs

### 3. ğŸ“š Articles WikipÃ©dia FR

- **Standard:** ~10 articles
- **Ã‰tendu:** ~220 articles (Sciences, Histoire, Sport, Technologie, Culture, etc.)
- **IdÃ©al pour:** Tests de performance, recherche conceptuelle avancÃ©e

**Features:**

- TÃ©lÃ©chargement automatique au premier lancement
- Cache intelligent pour Ã©viter les rechargements
- PrÃ©processing intÃ©grÃ© (lowercase, tokenization)
- MÃ©tadonnÃ©es: titre, catÃ©gorie, source

---

## ğŸ”§ Technologies UtilisÃ©es

### Backend

- **Python 3.9+** : Langage principal
- **NumPy & Pandas** : Calculs numÃ©riques et manipulation de donnÃ©es
- **scikit-learn** : Outils ML (PCA, t-SNE, clustering, mÃ©triques)
- **SciPy** : Calculs scientifiques avancÃ©s

### Deep Learning & Embeddings

- **PyTorch** : Framework deep learning
- **Sentence-Transformers** : Embeddings vectoriels prÃ©-entraÃ®nÃ©s
- **Transformers (HuggingFace)** : ModÃ¨les BERT multilingues

### Frontend & Visualisations

- **Streamlit** : Interface web interactive
- **Matplotlib & Seaborn** : Visualisations statiques
- **Plotly** : Graphiques 3D interactifs
- **WordCloud** : Nuages de mots

---

## ğŸ“ Concepts ExpliquÃ©s

### TF-IDF (Term Frequency - Inverse Document Frequency)

- FrÃ©quence des termes normalisÃ©e
- Importance des mots rares
- SimilaritÃ© cosinus entre vecteurs
- **Limites:** Pas de sÃ©mantique, mots exacts uniquement

### BM25 (Best Matching 25)

- Saturation du TF avec paramÃ¨tre **k1**
- Normalisation de longueur avec paramÃ¨tre **b**
- IDF avec smoothing
- **Avantages:** Meilleur que TF-IDF, tunable

### Embeddings Vectoriels

- ReprÃ©sentations denses sÃ©mantiques
- Transformers & Attention Mechanism
- Sentence-BERT multilingue
- **Avantages:** Synonymes, concepts, multilingue
- **Limites:** CoÃ»t computationnel, besoin GPU

### Hybrid Search

- Combinaison linÃ©aire BM25 + Embeddings
- ParamÃ¨tre **Î±** pour pondÃ©ration
- **Avantages:** Meilleur des deux mondes
- **Use cases:** E-commerce, recherche d'articles

---

## ğŸ“ˆ FonctionnalitÃ©s AvancÃ©es

### Visualisations Interactives

- ğŸŒŒ **Espaces vectoriels 3D** (PCA, t-SNE, UMAP)
- ğŸ”¥ **Heatmaps de similaritÃ©**
- ğŸ“Š **Clustering automatique** (K-means)
- ğŸ“ˆ **Graphiques radar comparatifs**
- ğŸ›ï¸ **Tuning interactif** des paramÃ¨tres

### Analyse de Performance

- â±ï¸ **Benchmarks temps rÃ©el**
- ğŸ§® **Analyse de complexitÃ©** (Big O)
- ğŸ’¾ **Utilisation mÃ©moire**
- ğŸš€ **Optimisations suggÃ©rÃ©es** (sparse matrices, FAISS, GPU)

### Comparaisons Multi-Techniques

- âš”ï¸ **Side-by-side** des rÃ©sultats
- ğŸ“Š **MÃ©triques de qualitÃ©** (Precision, Recall, MRR, NDCG)
- ğŸ”— **Overlap analysis** entre techniques
- ğŸ“ˆ **Distributions de scores**

---

## ğŸ’¡ Comment Utiliser l'Application

### 1. Navigation

Utilise la **sidebar** (barre latÃ©rale) pour naviguer entre les sections:

- ğŸ  **Accueil** : Vue d'ensemble
- ğŸ“Š **TF-IDF** : Technique classique
- ğŸ¯ **BM25** : AmÃ©lioration de TF-IDF
- ğŸ§  **Embeddings** : Recherche sÃ©mantique
- ğŸ“Š **SynthÃ¨se** : Comparaison et guide

### 2. Configuration

Dans chaque section (sauf Accueil):

- Choisis un **dataset** (recettes, films, wikipedia)
- Active le **dataset Ã©tendu** pour plus de documents
- Configure les **paramÃ¨tres avancÃ©s** (stopwords, calculs intermÃ©diaires)

### 3. Exploration

Chaque technique a plusieurs onglets:

- **Introduction** : Contexte et motivation
- **Concepts** : ThÃ©orie avec formules et visualisations
- **Recherche** : Interface de recherche interactive
- **Exploration** : Statistiques et visualisations avancÃ©es
- **Pas-Ã -Pas** : Calculs dÃ©taillÃ©s Ã©tape par Ã©tape
- **Performance** : Benchmarks et optimisations

### 4. ExpÃ©rimentation

- Teste diffÃ©rentes **requÃªtes** pour voir les diffÃ©rences
- Ajuste les **paramÃ¨tres** (k1, b, Î±) en temps rÃ©el
- Compare les **techniques** sur les mÃªmes requÃªtes
- Explore les **visualisations 3D** pour comprendre l'espace vectoriel

---

## ğŸ¯ Cas d'Usage PÃ©dagogiques

### Pour les Ã‰tudiants

- ğŸ“– **Apprendre** les fondamentaux de la recherche textuelle
- ğŸ§ª **ExpÃ©rimenter** avec diffÃ©rents algorithmes
- ğŸ“Š **Visualiser** les concepts abstraits
- ğŸ’» **Voir le code** (implÃ©mentations from scratch)
- ğŸ“ **Comprendre** les compromis (qualitÃ© vs performance)

### Pour les Enseignants

- ğŸ“š **Support de cours** interactif
- ğŸ¨ **DÃ©monstrations** en temps rÃ©el
- ğŸ“Š **Visualisations** pour expliquer les concepts
- ğŸ’¼ **Cas d'usage** rÃ©els par industrie
- ğŸ† **Comparaisons** objectives entre techniques

### Pour les DÃ©veloppeurs

- ğŸš€ **Prototypage rapide** de moteurs de recherche
- ğŸ”¬ **Benchmarking** de diffÃ©rentes approches
- ğŸ“– **Documentation** complÃ¨te avec exemples
- ğŸ’» **Code rÃ©utilisable** (engines, visualisations)
- ğŸ¯ **Guide de dÃ©cision** pour choisir la technique

---

## ğŸ”¬ RÃ©sultats des Benchmarks

### MÃ©triques de QualitÃ© (Dataset Wikipedia ~220 docs)

| MÃ©trique     | TF-IDF | BM25 | Embeddings | Hybrid   |
| ------------ | ------ | ---- | ---------- | -------- |
| Precision@10 | 0.45   | 0.58 | 0.76       | **0.82** |
| Recall@10    | 0.52   | 0.64 | 0.81       | **0.86** |
| MRR          | 0.38   | 0.52 | 0.71       | **0.78** |
| NDCG@10      | 0.51   | 0.63 | 0.79       | **0.84** |

### Performance (Temps moyen de recherche)

| Technique  | Indexation (1000 docs)   | Recherche (1 query) | MÃ©moire |
| ---------- | ------------------------ | ------------------- | ------- |
| TF-IDF     | ~0.1s                    | ~5ms                | ~2 MB   |
| BM25       | ~0.1s                    | ~5ms                | ~2 MB   |
| Embeddings | ~30s (GPU) / ~300s (CPU) | ~10ms               | ~15 MB  |
| Hybrid     | ~30s (GPU)               | ~15ms               | ~17 MB  |

**ğŸ’¡ Conclusion:** Hybrid offre la meilleure qualitÃ©, BM25 le meilleur compromis qualitÃ©/vitesse!

---

## ğŸš€ Optimisations Possibles

### Pour TF-IDF/BM25

- Index inversÃ© pour recherche rapide
- Sparse matrices (scipy.sparse)
- Min/Max document frequency filtering
- Limitation de vocabulaire

### Pour Embeddings

- **GPU Acceleration** : 10-50Ã— plus rapide (CUDA)
- **Batch Processing** : Encodage par batches
- **FAISS** : Index vectoriel optimisÃ© (10-100Ã— sur millions de docs)
- **ModÃ¨les plus petits** : MiniLM vs MPNet vs Large
- **Quantization** : int8 pour rÃ©duire mÃ©moire (4Ã—)
- **Caching** : Sauvegarder embeddings calculÃ©s

---

## â“ FAQ / Troubleshooting

### Q: J'ai l'erreur `ModuleNotFoundError: No module named 'sentence_transformers'`

**R:** Les embeddings ne sont pas installÃ©s. Tu as 2 options:

1. **Lance l'app quand mÃªme** (TF-IDF et BM25 fonctionnent!) :

```bash
streamlit run app.py
```

Les sections Embeddings/SynthÃ¨se seront verrouillÃ©es ğŸ”’

2. **Installe les embeddings** pour tout dÃ©bloquer :

```bash
python setup_embeddings.py
```

### Q: Le tÃ©lÃ©chargement du modÃ¨le est trop long!

**R:** Le modÃ¨le `paraphrase-multilingual-MiniLM-L12-v2` fait ~200 MB.

- PremiÃ¨re fois: 2-10 minutes selon connexion
- Ensuite: **instantanÃ©** (mis en cache!)
- Alternative: Skip les embeddings et utilise TF-IDF/BM25 (100% fonctionnels!)

### Q: OÃ¹ est stockÃ© le modÃ¨le tÃ©lÃ©chargÃ©?

**R:** Dans le cache Hugging Face par dÃ©faut:

- Windows: `C:\Users\<user>\.cache\huggingface\hub\`
- macOS/Linux: `~/.cache/huggingface/hub/`

### Q: Puis-je utiliser l'app sans GPU?

**R:** **OUI!** Tout fonctionne sur CPU:

- TF-IDF/BM25: Rapides sur CPU âœ…
- Embeddings: Plus lent (~10Ã— vs GPU) mais fonctionnel âœ…
- Pour accÃ©lÃ©rer: Utilise `batch_size=8` au lieu de 32

### Q: L'application est lente au premier lancement

**R:** C'est normal! Au premier lancement:

- TÃ©lÃ©chargement des datasets (~1-2s)
- TÃ©lÃ©chargement du modÃ¨le si pas en cache (~2-10 min)
- Calcul des embeddings (~10-30s selon dataset)

Ensuite, tout est en cache = **lancement instantanÃ©!** ğŸš€

### Q: Comment dÃ©sactiver les stopwords?

**R:** Dans la sidebar â†’ ParamÃ¨tres â†’ DÃ©cocher "Supprimer stopwords"

### Q: Puis-je ajouter mes propres datasets?

**R:** OUI! Ã‰dite `src/datasets.py` et ajoute ta fonction:

```python
def load_mon_dataset():
    return [
        {'title': 'Doc 1', 'text': '...', 'category': '...'},
        # ...
    ]
```

### Q: Les sections Embeddings/SynthÃ¨se sont verrouillÃ©es ğŸ”’

**R:** C'est normal! Pour les dÃ©bloquer:

```bash
# Option facile: script automatique
python setup_embeddings.py

# Option manuelle
pip install sentence-transformers torch transformers
```

---

## ğŸ“ Licence

MIT License - Libre d'utilisation pour projets Ã©ducatifs et commerciaux.

---

## ğŸ‘¥ Auteurs

Projet pÃ©dagogique crÃ©Ã© pour enseigner la recherche textuelle moderne.

---

## ğŸ™ Remerciements

- **Sentence-Transformers** pour les modÃ¨les d'embeddings
- **Streamlit** pour le framework web interactif
- **HuggingFace** pour les Transformers prÃ©-entraÃ®nÃ©s
- **scikit-learn** pour les outils ML

---

## ğŸ“ Support

Pour toute question ou suggestion:

- Ouvre une **issue** sur GitHub
- Consulte la **documentation** dans l'application
- VÃ©rifie les **examples** dans chaque section

---

## ğŸ‰ Bon Apprentissage!

N'hÃ©site pas Ã  **expÃ©rimenter**, **comparer**, et **apprendre**! ğŸš€

**Remember:** La meilleure technique dÃ©pend de ton cas d'usage! ğŸ¯
