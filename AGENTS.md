# MISSION: CrÃ©er une Application Streamlit Ã‰ducative sur TF-IDF

## ğŸ¯ CONTEXTE

Tu es un agent de programmation chargÃ© de crÃ©er une application Streamlit pÃ©dagogique
pour enseigner les techniques de recherche textuelle Ã  des Ã©tudiants en programmation web.

**Phase actuelle:** TF-IDF uniquement (d'autres techniques seront ajoutÃ©es plus tard: BM25, embeddings, etc.)

**Public cible:** Ã‰tudiants francophones en dÃ©veloppement web (niveau bac+2/3)

**Ton objectif:** CrÃ©er une application interactive qui explique TF-IDF de maniÃ¨re
complÃ¨te, claire et imagÃ©e, avec des visualisations et des exemples concrets.

---

## ğŸ—ï¸ ARCHITECTURE DE L'APPLICATION

### Structure de fichiers attendue:

```
tfidf-app/
â”œâ”€â”€ app.py                    # Application Streamlit principale
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tfidf_engine.py      # ImplÃ©mentation TF-IDF from scratch
â”‚   â”œâ”€â”€ visualizations.py    # Toutes les fonctions de visualisation
â”‚   â””â”€â”€ datasets.py          # Chargement et gestion des datasets
â”œâ”€â”€ data/
â”‚   â””â”€â”€ .gitkeep            # Les datasets seront tÃ©lÃ©chargÃ©s au runtime
â””â”€â”€ README.md               # Documentation du projet
```

### Technologies imposÃ©es:

- Python 3.9+
- Streamlit (interface)
- NumPy, Pandas (calculs)
- Matplotlib, Seaborn, Plotly (visualisations)
- scikit-learn (pour comparaison uniquement, pas pour l'implÃ©mentation principale)
- requests (pour fetch des datasets)

---

## ğŸ“š CONTENU PÃ‰DAGOGIQUE REQUIS

L'application doit expliquer TF-IDF en suivant cette progression:

### 1. Introduction - Le ProblÃ¨me

- Pourquoi la recherche simple par mots-clÃ©s ne suffit pas
- Exemple concret d'un Ã©chec de recherche naÃ¯ve
- Visualisation du problÃ¨me

### 2. Term Frequency (TF)

- **Intuition:** "Si un mot apparaÃ®t souvent, le doc parle de ce sujet"
- **Formule:** `TF(mot, doc) = nombre_occurrences / total_mots_doc`
- **Pourquoi normaliser?** Comparaison doc court vs doc long
- **Exemple calculÃ© Ã©tape par Ã©tape** (avec 3-4 docs simples)
- **ProblÃ¨me:** Les mots communs ("le", "la") polluent les rÃ©sultats
- **Visualisation:** Graphique Ã  barres des TF par document

### 3. Inverse Document Frequency (IDF)

- **Intuition:** "Un mot rare est plus informatif qu'un mot commun"
- **Formule:** `IDF(mot) = log(nb_total_docs / nb_docs_contenant_mot)`
- **Pourquoi le log?** Compression de l'Ã©chelle (visualiser l'effet)
- **Exemple calculÃ©** avec mots communs vs rares
- **Visualisation:**
  - Courbe IDF en fonction de la frÃ©quence documentaire
  - Word cloud oÃ¹ la taille = IDF

### 4. TF-IDF CombinÃ©

- **Formule:** `TF-IDF = TF Ã— IDF`
- **Signification:** Mots frÃ©quents localement mais rares globalement
- **Calcul complet sur un exemple** (style tableau Excel)
- **Visualisation:** Heatmap TF-IDF (docs en lignes, mots en colonnes)

### 5. Cosine Similarity

- **Intuition gÃ©omÃ©trique:** Documents = vecteurs, on mesure l'angle
- **Formule:** `cos(Î¸) = (AÂ·B) / (||A|| Ã— ||B||)`
- **Pourquoi pas juste additionner?** Normalisation par longueur
- **Calcul Ã©tape par Ã©tape:** dot product, normes, division
- **Visualisation:**
  - ReprÃ©sentation 3D des vecteurs (avec PCA si nÃ©cessaire)
  - Matrice de similaritÃ© (heatmap)

### 6. Recherche ComplÃ¨te

- Interface de recherche interactive
- Affichage des scores Ã©tape par Ã©tape
- Comparaison des rÃ©sultats avec/sans IDF

---

## ğŸ¨ VISUALISATIONS REQUISES

Pour chaque concept, implÃ©mente ces visualisations:

### Visualisations TF:

1. **Bar chart:** FrÃ©quence des mots par document
2. **Comparaison:** Doc court vs doc long (avant/aprÃ¨s normalisation)

### Visualisations IDF:

1. **Courbe:** IDF en fonction du nombre de documents contenant le mot
2. **Comparaison:** Avec/sans logarithme (montrer l'effet)
3. **Word cloud:** Taille proportionnelle Ã  l'IDF

### Visualisations TF-IDF:

1. **Heatmap:** Matrice complÃ¨te (docs Ã— mots)
2. **Top mots:** Bar chart des mots les plus importants par document

### Visualisations SimilaritÃ©:

1. **Scatter plot 3D:** Documents projetÃ©s en 3D (interactif avec Plotly)
2. **Heatmap de similaritÃ©:** Tous les docs vs tous les docs
3. **RÃ©sultats de recherche:** Bar chart des scores de similaritÃ© avec la query

### Style des visualisations:

- Palette de couleurs cohÃ©rente (ex: "viridis" ou "YlOrRd")
- Annotations sur les graphiques (valeurs, labels)
- Titres explicites et descriptions
- LÃ©gendes claires
- Responsive (adaptÃ©s Ã  la largeur de l'Ã©cran)

---

## ğŸ“Š DATASETS EN FRANÃ‡AIS

Utilise des datasets **amusants et variÃ©s** en franÃ§ais. Suggestions:

### Dataset 1: Recettes de Cuisine (LÃ©ger, ~30 recettes)

```python
# Ã€ rÃ©cupÃ©rer via l'API Marmiton ou crÃ©er un petit corpus
# CatÃ©gories: Italiennes, Asiatiques, FranÃ§aises, Mexicaines, etc.
# Permet de tester des queries comme "plat italien", "cuisine Ã©picÃ©e"
```

### Dataset 2: Synopsis de Films (Moyen, ~100 films)

```python
# AlloCinÃ© API ou IMDb (traduit)
# Genres variÃ©s: Action, ComÃ©die, Horreur, Science-fiction
# Queries: "film drÃ´le", "espace vaisseau", "super-hÃ©ros"
```

### Dataset 3: Articles WikipÃ©dia FR (Plus gros, ~200 articles)

```python
# Sujets variÃ©s via l'API Wikipedia
# ThÃ¨mes: Sciences, Histoire, Sport, Technologie, Culture
# Queries: "guerre mondiale", "intelligence artificielle", "football"
```

**ImplÃ©mentation requise:**

- Fonction de tÃ©lÃ©chargement avec cache (ne pas retÃ©lÃ©charger Ã  chaque run)
- PrÃ©processing: lowercase, suppression ponctuation basique
- MÃ©tadonnÃ©es: titre, catÃ©gorie, source
- Option de filtrer par catÃ©gorie

**Code attendu:**

```python
# src/datasets.py
def load_dataset(name='recettes', use_cache=True, sample_size=None):
    """
    Charge un dataset avec cache

    Args:
        name: 'recettes', 'films', ou 'wikipedia'
        use_cache: Utiliser le cache si disponible
        sample_size: Nombre de docs Ã  charger (None = tous)

    Returns:
        List[Dict]: [{'title': str, 'text': str, 'category': str}, ...]
    """
    pass
```

---

## ğŸ¯ INTERFACE STREAMLIT

### Structure de la page (sidebar + main):

**Sidebar:**

- SÃ©lection du dataset
- ParamÃ¨tres avancÃ©s (optionnels):
  - Taille du dataset
  - Afficher les calculs intermÃ©diaires
  - ThÃ¨me de couleur des graphiques

**Main Area - Tabs:**

#### Tab 1: ğŸ“– Introduction

- Explication du problÃ¨me
- Exemple d'Ã©chec de recherche naÃ¯ve
- PrÃ©sentation de TF-IDF comme solution

#### Tab 2: ğŸ”¢ Concepts TF-IDF

**Sous-sections avec st.expander:**

- Term Frequency (TF)
  - Explication thÃ©orique
  - Formule avec LaTeX: `st.latex(r"TF = \frac{count}{total}")`
  - Exemple calculÃ©
  - Visualisation
- Inverse Document Frequency (IDF)
  - MÃªme structure
- TF-IDF CombinÃ©
  - MÃªme structure
- Cosine Similarity
  - MÃªme structure

#### Tab 3: ğŸ” Recherche Interactive

- Input de recherche (query)
- Bouton "Rechercher"
- Affichage des rÃ©sultats:
  - Top 5 documents avec scores
  - Snippet du texte (premiers 200 caractÃ¨res)
  - Option d'afficher le calcul dÃ©taillÃ©
- Visualisations:
  - Bar chart des scores
  - Heatmap de similaritÃ© (query vs tous les docs)

#### Tab 4: ğŸ“Š Exploration du Corpus

- Statistiques du dataset:
  - Nombre de documents
  - Vocabulaire (nombre de mots uniques)
  - Distribution de longueur des documents
- Visualisations globales:
  - Top 20 mots par IDF
  - Matrice TF-IDF complÃ¨te (heatmap)
  - Projection 2D/3D des documents

#### Tab 5: ğŸ“ Exemple Pas-Ã -Pas

- Prendre 3 documents du dataset
- Query prÃ©dÃ©finie
- DÃ©rouler TOUT le calcul Ã©tape par Ã©tape:
  1. Calcul des TF (tableau)
  2. Calcul des IDF (tableau)
  3. Multiplication â†’ TF-IDF (tableau)
  4. Vectorisation de la query
  5. Cosine similarity (calculs dÃ©taillÃ©s)
  6. Classement final
- Utiliser des dataframes Pandas pour l'affichage

---

## ğŸ’» IMPLÃ‰MENTATION TF-IDF

**ImpÃ©ratif:** ImplÃ©menter TF-IDF **from scratch** (sans utiliser TfidfVectorizer de sklearn)

```python
# src/tfidf_engine.py

class TFIDFEngine:
    """
    ImplÃ©mentation pÃ©dagogique de TF-IDF
    Doit conserver tous les Ã©tats intermÃ©diaires pour visualisation
    """

    def __init__(self, documents: List[str]):
        """
        Args:
            documents: Liste de textes
        """
        self.documents = documents
        self.vocabulary = None
        self.tf_matrix = None  # Shape: (n_docs, n_vocab)
        self.idf_vector = None  # Shape: (n_vocab,)
        self.tfidf_matrix = None  # Shape: (n_docs, n_vocab)

    def fit(self):
        """Calcule TF, IDF, et TF-IDF pour tous les documents"""
        pass

    def compute_tf(self, doc_index: int) -> Dict[str, float]:
        """Calcule TF pour un document"""
        pass

    def compute_idf(self) -> Dict[str, float]:
        """Calcule IDF pour tout le vocabulaire"""
        pass

    def compute_tfidf(self):
        """Combine TF et IDF"""
        pass

    def search(self, query: str, top_k: int = 5) -> List[Tuple[int, float]]:
        """
        Recherche les documents les plus similaires

        Returns:
            List of (doc_index, similarity_score) sorted by score desc
        """
        pass

    def get_explanation(self, query: str, doc_index: int) -> Dict:
        """
        Retourne tous les calculs intermÃ©diaires pour expliquer un score

        Returns:
            {
                'tf_doc': Dict[str, float],
                'tf_query': Dict[str, float],
                'idf': Dict[str, float],
                'tfidf_doc': Dict[str, float],
                'tfidf_query': Dict[str, float],
                'dot_product': float,
                'norm_doc': float,
                'norm_query': float,
                'cosine_similarity': float
            }
        """
        pass
```

**Fonctions utilitaires requises:**

```python
def preprocess_text(text: str) -> List[str]:
    """
    Preprocessing simple:
    - Lowercase
    - Suppression ponctuation
    - Split sur espaces
    - Optionnel: suppression stopwords FR
    """
    pass

def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """Calcule la similaritÃ© cosinus entre deux vecteurs"""
    pass
```

---

## ğŸ¨ GUIDELINES VISUELLES

### Palette de couleurs:

```python
PRIMARY_COLOR = "#1f77b4"      # Bleu
SECONDARY_COLOR = "#ff7f0e"    # Orange
SUCCESS_COLOR = "#2ca02c"      # Vert
WARNING_COLOR = "#d62728"      # Rouge
NEUTRAL_COLOR = "#7f7f7f"      # Gris

# Pour les heatmaps
HEATMAP_COLORSCALE = "YlOrRd"  # Jaune â†’ Orange â†’ Rouge
```

### Style Streamlit:

```python
st.set_page_config(
    page_title="TF-IDF Explorer",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)
```

### Markdown & LaTeX:

- Utiliser `st.latex()` pour les formules mathÃ©matiques
- Utiliser des emojis dans les titres (ğŸ“Š, ğŸ”, ğŸ’¡, etc.)
- Code blocks avec syntax highlighting
- Callouts avec `st.info()`, `st.success()`, `st.warning()`

### Exemples de texte pÃ©dagogique:

```python
st.markdown("""
### ğŸ’¡ Pourquoi normaliser avec TF?

Imagine deux documents:

- **Doc A (10 mots):** Le mot "chat" apparaÃ®t **2 fois**
- **Doc B (100 mots):** Le mot "chat" apparaÃ®t **3 fois**

Sans normalisation, Doc B semble plus pertinent (3 > 2).

**Mais!** Doc A consacre 20% de son contenu au mot "chat" (2/10),
tandis que Doc B seulement 3% (3/100).

**Doc A est donc plus "Ã  propos" du chat!** ğŸ¯
""")
```

---

## ğŸ§ª FONCTIONNALITÃ‰S INTERACTIVES

### 1. Comparaison TF vs TF-IDF:

- Toggle pour activer/dÃ©sactiver l'IDF
- Montrer visuellement la diffÃ©rence de ranking

### 2. Sliders pour paramÃ¨tres:

```python
# Exemple
min_df = st.slider(
    "FrÃ©quence minimale du document (min_df)",
    min_value=1,
    max_value=10,
    value=1,
    help="Ignorer les mots apparaissant dans moins de X documents"
)
```

### 3. Exemple de query prÃ©dÃ©finies:

```python
example_queries = {
    "recettes": ["plat italien", "cuisine Ã©picÃ©e", "dessert chocolat"],
    "films": ["science-fiction espace", "comÃ©die romantique", "super-hÃ©ros action"],
    "wikipedia": ["guerre mondiale", "intelligence artificielle", "football champion"]
}

selected_example = st.selectbox("Ou choisissez un exemple:", [""] + example_queries[dataset_name])
if selected_example:
    query = selected_example
```

### 4. Export des rÃ©sultats:

- Bouton pour tÃ©lÃ©charger les rÃ©sultats en CSV
- Bouton pour tÃ©lÃ©charger les visualisations en PNG

---

## ğŸ“‹ REQUIREMENTS.TXT

CrÃ©e un fichier `requirements.txt` avec ces dÃ©pendances (versions minimales):

```txt
streamlit>=1.28.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.17.0
scikit-learn>=1.3.0
requests>=2.31.0
scipy>=1.11.0
```

---

## ğŸ“ README.MD

CrÃ©e un README complet avec:

1. **Titre et description**
2. **Installation:**

```bash
   pip install -r requirements.txt
```

3. **Lancement:**

```bash
   streamlit run app.py
```

4. **Structure du projet**
5. **Datasets utilisÃ©s**
6. **Concepts expliquÃ©s**
7. **Captures d'Ã©cran** (placeholder pour l'instant)
8. **Auteur et licence**

---

## âš ï¸ CONTRAINTES IMPORTANTES

### Tu NE PEUX PAS exÃ©cuter de commandes:

- Ne pas utiliser `subprocess`, `os.system()`, ou Ã©quivalent
- Ã€ la fin de chaque message, liste les commandes que je dois exÃ©cuter
- Format:

```bash
  # Commandes Ã  exÃ©cuter:
  pip install -r requirements.txt
  streamlit run app.py
```

### Code quality:

- Type hints partout
- Docstrings pour toutes les fonctions
- Comments explicatifs pour la logique complexe
- Gestion des erreurs (try/except)
- Loading spinners (`st.spinner()`) pour les opÃ©rations longues

### Performance:

- Utiliser `@st.cache_data` pour le chargement des datasets
- Utiliser `@st.cache_resource` pour l'engine TF-IDF
- Ã‰viter les recalculs inutiles

### UX:

- Messages de chargement clairs
- Gestion des cas d'erreur (dataset vide, query vide, etc.)
- Tooltips (`help=` parameter) pour les Ã©lÃ©ments complexes
- Progress bars pour les opÃ©rations longues

---

## ğŸ¯ LIVRABLES ATTENDUS

Ã€ la fin, tu dois avoir crÃ©Ã©:

1. âœ… `app.py` - Application Streamlit complÃ¨te et fonctionnelle
2. âœ… `src/tfidf_engine.py` - ImplÃ©mentation TF-IDF from scratch
3. âœ… `src/visualizations.py` - Toutes les fonctions de visualisation
4. âœ… `src/datasets.py` - Gestion des datasets
5. âœ… `requirements.txt` - DÃ©pendances
6. âœ… `README.md` - Documentation
7. âœ… Liste des commandes Ã  exÃ©cuter

---

## ğŸ’¬ COMMUNICATION

Ã€ chaque message:

1. Explique ce que tu vas faire
2. CrÃ©e/modifie les fichiers
3. Termine par une section "ğŸ“‹ Commandes Ã  exÃ©cuter" avec toutes les commandes nÃ©cessaires

Exemple:

```
ğŸ“‹ Commandes Ã  exÃ©cuter:

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer l'application
streamlit run app.py

# (Optionnel) Tester l'import des modules
python -c "from src.tfidf_engine import TFIDFEngine; print('OK')"
```

---

## ğŸš€ C'EST PARTI!

Commence par crÃ©er la structure de base du projet avec `app.py` et `requirements.txt`.
ImplÃ©mente d'abord le Tab "Introduction" et la structure gÃ©nÃ©rale.

Fais-moi un premier jet fonctionnel, mÃªme si les datasets ne sont pas encore tÃ©lÃ©chargÃ©s.
On itÃ©rera ensuite sur les dÃ©tails.

**Objectif:** Une application Streamlit qui tourne et affiche au moins la structure des tabs.
